{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169b0453-bbef-4258-b790-9dd37a63daef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:49.561401Z",
     "iopub.status.busy": "2021-08-27T04:01:49.561243Z",
     "iopub.status.idle": "2021-08-27T04:01:51.386695Z",
     "shell.execute_reply": "2021-08-27T04:01:51.385775Z",
     "shell.execute_reply.started": "2021-08-27T04:01:49.561356Z"
    },
    "id": "169b0453-bbef-4258-b790-9dd37a63daef",
    "outputId": "7980bc0d-4edd-472b-86d8-e43bbb473105",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import datetime \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the autocorrelation function (ACF) plot.\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# We are required to do this in order to avoid \"FutureWarning\" issues.\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "#from skopt import BayesSearchCV\n",
    "#from skopt.space import Real, Categorical, Integer\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, GRU\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Import Bagging Classifier.\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60293d41-28f7-4e8e-8acf-d3873b8184df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.389225Z",
     "iopub.status.busy": "2021-08-27T04:01:51.389041Z",
     "iopub.status.idle": "2021-08-27T04:01:51.400409Z",
     "shell.execute_reply": "2021-08-27T04:01:51.399648Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.389208Z"
    },
    "id": "60293d41-28f7-4e8e-8acf-d3873b8184df",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "data = pd.read_csv('clean_daily_oc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "253a9740-ce21-4a99-b66a-b98e5718d5b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.401624Z",
     "iopub.status.busy": "2021-08-27T04:01:51.401283Z",
     "iopub.status.idle": "2021-08-27T04:01:51.407259Z",
     "shell.execute_reply": "2021-08-27T04:01:51.406635Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.401607Z"
    },
    "id": "253a9740-ce21-4a99-b66a-b98e5718d5b6",
    "outputId": "22443591-4da5-4bd0-e6bc-da478ef9ee40",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3651, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "-zEGI5tjIEvN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.408047Z",
     "iopub.status.busy": "2021-08-27T04:01:51.407920Z",
     "iopub.status.idle": "2021-08-27T04:01:51.419597Z",
     "shell.execute_reply": "2021-08-27T04:01:51.418649Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.408031Z"
    },
    "id": "-zEGI5tjIEvN",
    "outputId": "25049370-3e6b-450d-d8ac-0fd233110348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3651 entries, 0 to 3650\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   date            3651 non-null   object \n",
      " 1   day_of_week_1   3651 non-null   int64  \n",
      " 2   day_of_week_2   3651 non-null   int64  \n",
      " 3   day_of_week_3   3651 non-null   int64  \n",
      " 4   day_of_week_4   3651 non-null   int64  \n",
      " 5   day_of_week_5   3651 non-null   int64  \n",
      " 6   day_of_week_6   3651 non-null   int64  \n",
      " 7   is_holiday_1    3651 non-null   int64  \n",
      " 8   Open_pct        3651 non-null   float64\n",
      " 9   Close_pct       3651 non-null   float64\n",
      " 10  Volume_diff     3651 non-null   float64\n",
      " 11  Open_pct_l1     3651 non-null   float64\n",
      " 12  Close_pct_l1    3651 non-null   float64\n",
      " 13  Volume_diff_l1  3651 non-null   float64\n",
      " 14  direction       3651 non-null   object \n",
      "dtypes: float64(6), int64(7), object(2)\n",
      "memory usage: 428.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614Omlo8IBLm",
   "metadata": {
    "id": "614Omlo8IBLm"
   },
   "source": [
    "#Preprocessing \n",
    "\n",
    "need to run dates from here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb92257-6ade-4105-ad50-aa0c43b8ddb4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.421144Z",
     "iopub.status.busy": "2021-08-27T04:01:51.420866Z",
     "iopub.status.idle": "2021-08-27T04:01:51.426322Z",
     "shell.execute_reply": "2021-08-27T04:01:51.425664Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.421123Z"
    },
    "id": "2eb92257-6ade-4105-ad50-aa0c43b8ddb4",
    "outputId": "13cf4476-5598-4db4-ca6e-89f5b0b9cff4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'day_of_week_1', 'day_of_week_2', 'day_of_week_3',\n",
       "       'day_of_week_4', 'day_of_week_5', 'day_of_week_6', 'is_holiday_1',\n",
       "       'Open_pct', 'Close_pct', 'Volume_diff', 'Open_pct_l1', 'Close_pct_l1',\n",
       "       'Volume_diff_l1', 'direction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d3c5184-e232-45f1-9d55-f6ca6aad4eea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.427351Z",
     "iopub.status.busy": "2021-08-27T04:01:51.427189Z",
     "iopub.status.idle": "2021-08-27T04:01:51.430100Z",
     "shell.execute_reply": "2021-08-27T04:01:51.429398Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.427335Z"
    },
    "id": "8d3c5184-e232-45f1-9d55-f6ca6aad4eea",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop text column \n",
    "#data.drop(columns='text',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5c9b04-0f1d-459b-94c6-a9053b51156c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.431612Z",
     "iopub.status.busy": "2021-08-27T04:01:51.431468Z",
     "iopub.status.idle": "2021-08-27T04:01:51.436328Z",
     "shell.execute_reply": "2021-08-27T04:01:51.435639Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.431597Z"
    },
    "id": "ab5c9b04-0f1d-459b-94c6-a9053b51156c",
    "outputId": "1a1393c3-a491-491f-a72b-e1c483a4ebdf",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if date is datetime object \n",
    "type(data.loc[0,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81656ddc-9c37-425c-8807-78e7713bace2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.437368Z",
     "iopub.status.busy": "2021-08-27T04:01:51.437242Z",
     "iopub.status.idle": "2021-08-27T04:01:51.441217Z",
     "shell.execute_reply": "2021-08-27T04:01:51.440632Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.437354Z"
    },
    "id": "81656ddc-9c37-425c-8807-78e7713bace2",
    "outputId": "9b021510-ecce-46dd-887b-4f3c503db51b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2011-07-31'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check format of date \n",
    "data['date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dce4173-7424-4c93-9a3c-642260f16b03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.442082Z",
     "iopub.status.busy": "2021-08-27T04:01:51.441933Z",
     "iopub.status.idle": "2021-08-27T04:01:51.447277Z",
     "shell.execute_reply": "2021-08-27T04:01:51.446647Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.442065Z"
    },
    "id": "4dce4173-7424-4c93-9a3c-642260f16b03",
    "outputId": "5b9c92e4-d096-4974-f103-e984579136fd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2011, 7, 29)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert str to date time \n",
    "datetime.datetime.strptime('2011-07-29','%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551351c4-20f9-4f8c-abc8-3363f9010bab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.448338Z",
     "iopub.status.busy": "2021-08-27T04:01:51.448161Z",
     "iopub.status.idle": "2021-08-27T04:01:51.472400Z",
     "shell.execute_reply": "2021-08-27T04:01:51.471667Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.448322Z"
    },
    "id": "551351c4-20f9-4f8c-abc8-3363f9010bab",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# convert all dates to datetime objects \n",
    "data['date']= data['date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').date() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49bfe791-74c4-40fd-99c2-3b861ce34602",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.473352Z",
     "iopub.status.busy": "2021-08-27T04:01:51.473209Z",
     "iopub.status.idle": "2021-08-27T04:01:51.478426Z",
     "shell.execute_reply": "2021-08-27T04:01:51.477708Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.473336Z"
    },
    "id": "49bfe791-74c4-40fd-99c2-3b861ce34602",
    "outputId": "b6fb7fb7-066e-448e-b304-9517094f2764",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm results\n",
    "type(data.loc[0,'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ea33f60-2842-4117-af5a-e29e831cf454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.479239Z",
     "iopub.status.busy": "2021-08-27T04:01:51.479103Z",
     "iopub.status.idle": "2021-08-27T04:01:51.482549Z",
     "shell.execute_reply": "2021-08-27T04:01:51.481808Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.479225Z"
    },
    "id": "0ea33f60-2842-4117-af5a-e29e831cf454",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make date index \n",
    "data.set_index('date',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0bb1333-726a-41d1-bbb6-0b2954e4af84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.483389Z",
     "iopub.status.busy": "2021-08-27T04:01:51.483261Z",
     "iopub.status.idle": "2021-08-27T04:01:51.488322Z",
     "shell.execute_reply": "2021-08-27T04:01:51.487669Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.483373Z"
    },
    "id": "d0bb1333-726a-41d1-bbb6-0b2954e4af84",
    "outputId": "5888c9c6-a9b3-4514-de0e-9901f87f2254",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([2011-07-31, 2011-08-01, 2011-08-02, 2011-08-03, 2011-08-04, 2011-08-05,\n",
       "       2011-08-06, 2011-08-07, 2011-08-08, 2011-08-09,\n",
       "       ...\n",
       "       2021-08-08, 2021-08-09, 2021-08-10, 2021-08-11, 2021-08-12, 2021-08-13,\n",
       "       2021-08-14, 2021-08-15, 2021-08-16, 2021-08-17],\n",
       "      dtype='object', name='date', length=3651)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confirm results\n",
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8da55097-7286-4514-86b0-a85e17ba2f89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.489141Z",
     "iopub.status.busy": "2021-08-27T04:01:51.489008Z",
     "iopub.status.idle": "2021-08-27T04:01:51.498406Z",
     "shell.execute_reply": "2021-08-27T04:01:51.497709Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.489126Z"
    },
    "id": "8da55097-7286-4514-86b0-a85e17ba2f89",
    "outputId": "9029e952-7ecd-49eb-94b7-23cb2c35dfee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3651 entries, 2011-07-31 to 2021-08-17\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   day_of_week_1   3651 non-null   int64  \n",
      " 1   day_of_week_2   3651 non-null   int64  \n",
      " 2   day_of_week_3   3651 non-null   int64  \n",
      " 3   day_of_week_4   3651 non-null   int64  \n",
      " 4   day_of_week_5   3651 non-null   int64  \n",
      " 5   day_of_week_6   3651 non-null   int64  \n",
      " 6   is_holiday_1    3651 non-null   int64  \n",
      " 7   Open_pct        3651 non-null   float64\n",
      " 8   Close_pct       3651 non-null   float64\n",
      " 9   Volume_diff     3651 non-null   float64\n",
      " 10  Open_pct_l1     3651 non-null   float64\n",
      " 11  Close_pct_l1    3651 non-null   float64\n",
      " 12  Volume_diff_l1  3651 non-null   float64\n",
      " 13  direction       3651 non-null   object \n",
      "dtypes: float64(6), int64(7), object(1)\n",
      "memory usage: 427.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# look at data types and check for nulls\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a493fd-3ddb-4fc0-a153-aa55caa63e19",
   "metadata": {
    "id": "a3a493fd-3ddb-4fc0-a153-aa55caa63e19"
   },
   "source": [
    "- No nulls \n",
    "\n",
    "- day_of_week and is_holiday should be dummified \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68086534-c6d1-4596-a537-432bb45a3570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.499405Z",
     "iopub.status.busy": "2021-08-27T04:01:51.499221Z",
     "iopub.status.idle": "2021-08-27T04:01:51.502057Z",
     "shell.execute_reply": "2021-08-27T04:01:51.501265Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.499387Z"
    },
    "id": "68086534-c6d1-4596-a537-432bb45a3570",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dummify day_of_week and is_holiday\n",
    "#data= pd.get_dummies(data,columns=['day_of_week','is_holiday'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd362f48-4b08-4411-8242-f4059ccafc22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.502843Z",
     "iopub.status.busy": "2021-08-27T04:01:51.502715Z",
     "iopub.status.idle": "2021-08-27T04:01:51.505456Z",
     "shell.execute_reply": "2021-08-27T04:01:51.504778Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.502829Z"
    },
    "id": "bd362f48-4b08-4411-8242-f4059ccafc22",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check results\n",
    "#data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fb5afdf-fe11-481d-a3a6-4e4ed38f1c75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.506058Z",
     "iopub.status.busy": "2021-08-27T04:01:51.505940Z",
     "iopub.status.idle": "2021-08-27T04:01:51.508455Z",
     "shell.execute_reply": "2021-08-27T04:01:51.507780Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.506045Z"
    },
    "id": "3fb5afdf-fe11-481d-a3a6-4e4ed38f1c75",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at open,close, and volume columns \n",
    "#data[['Open','Close','Volume']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6501a1f4-0682-48e2-ba3b-fd4c0af1a4e1",
   "metadata": {
    "id": "6501a1f4-0682-48e2-ba3b-fd4c0af1a4e1"
   },
   "source": [
    "- Change from actual value to change to percent change from the day before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ed5cade-5e66-4076-a8da-7fc03873f94d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.509070Z",
     "iopub.status.busy": "2021-08-27T04:01:51.508943Z",
     "iopub.status.idle": "2021-08-27T04:01:51.512232Z",
     "shell.execute_reply": "2021-08-27T04:01:51.511644Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.509056Z"
    },
    "id": "1ed5cade-5e66-4076-a8da-7fc03873f94d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# change from values to percent change from previous day \n",
    "#data['Open_pct']= data['Open'].pct_change()\n",
    "#data['Close_pct']= data['Close'].pct_change()\n",
    "#data['Volume_diff']= data['Volume'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc1097a1-f787-43e4-8d9d-80959014fe43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.512952Z",
     "iopub.status.busy": "2021-08-27T04:01:51.512823Z",
     "iopub.status.idle": "2021-08-27T04:01:51.515842Z",
     "shell.execute_reply": "2021-08-27T04:01:51.514747Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.512938Z"
    },
    "id": "cc1097a1-f787-43e4-8d9d-80959014fe43",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check results \n",
    "#ata[['Open_pct','Close_pct','Volume_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f30d498a-dde6-4927-8c1d-123b297fcc6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.516770Z",
     "iopub.status.busy": "2021-08-27T04:01:51.516630Z",
     "iopub.status.idle": "2021-08-27T04:01:51.519306Z",
     "shell.execute_reply": "2021-08-27T04:01:51.518687Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.516754Z"
    },
    "id": "f30d498a-dde6-4927-8c1d-123b297fcc6d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check how many nulls introduced \n",
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ca3de7f-404f-4d12-9cae-cab87f842e92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.520087Z",
     "iopub.status.busy": "2021-08-27T04:01:51.519966Z",
     "iopub.status.idle": "2021-08-27T04:01:51.523235Z",
     "shell.execute_reply": "2021-08-27T04:01:51.522646Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.520073Z"
    },
    "id": "6ca3de7f-404f-4d12-9cae-cab87f842e92",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop first row \n",
    "#data= data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e419f127-365b-4370-b24f-f4092d96aed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.524056Z",
     "iopub.status.busy": "2021-08-27T04:01:51.523921Z",
     "iopub.status.idle": "2021-08-27T04:01:51.526519Z",
     "shell.execute_reply": "2021-08-27T04:01:51.525814Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.524040Z"
    },
    "id": "e419f127-365b-4370-b24f-f4092d96aed3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confirm results\n",
    "#data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec3ded-4b71-498e-b6d2-b437b2de1ad4",
   "metadata": {
    "id": "a2ec3ded-4b71-498e-b6d2-b437b2de1ad4"
   },
   "source": [
    "- Remove Open, Close, and Volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "283fdaa5-7f90-4c12-a3f4-2be9a6a65469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.527289Z",
     "iopub.status.busy": "2021-08-27T04:01:51.527163Z",
     "iopub.status.idle": "2021-08-27T04:01:51.530354Z",
     "shell.execute_reply": "2021-08-27T04:01:51.529732Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.527275Z"
    },
    "id": "283fdaa5-7f90-4c12-a3f4-2be9a6a65469",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data.drop(columns=['Open','Close','Volume'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b314f13d-9ff5-423f-97f1-bee7e94c4b4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.531136Z",
     "iopub.status.busy": "2021-08-27T04:01:51.531009Z",
     "iopub.status.idle": "2021-08-27T04:01:51.540306Z",
     "shell.execute_reply": "2021-08-27T04:01:51.539668Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.531121Z"
    },
    "id": "b314f13d-9ff5-423f-97f1-bee7e94c4b4d",
    "outputId": "5e969f32-a28e-4d71-9b2e-6b652cda0c4c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3651 entries, 2011-07-31 to 2021-08-17\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   day_of_week_1   3651 non-null   int64  \n",
      " 1   day_of_week_2   3651 non-null   int64  \n",
      " 2   day_of_week_3   3651 non-null   int64  \n",
      " 3   day_of_week_4   3651 non-null   int64  \n",
      " 4   day_of_week_5   3651 non-null   int64  \n",
      " 5   day_of_week_6   3651 non-null   int64  \n",
      " 6   is_holiday_1    3651 non-null   int64  \n",
      " 7   Open_pct        3651 non-null   float64\n",
      " 8   Close_pct       3651 non-null   float64\n",
      " 9   Volume_diff     3651 non-null   float64\n",
      " 10  Open_pct_l1     3651 non-null   float64\n",
      " 11  Close_pct_l1    3651 non-null   float64\n",
      " 12  Volume_diff_l1  3651 non-null   float64\n",
      " 13  direction       3651 non-null   object \n",
      "dtypes: float64(6), int64(7), object(1)\n",
      "memory usage: 427.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# confirm results\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862544a-5f8d-41f2-a92f-88d3fce71878",
   "metadata": {
    "id": "1862544a-5f8d-41f2-a92f-88d3fce71878"
   },
   "source": [
    "- Trying to predict Open_pct \n",
    "\n",
    "- Cannot use open_pct, Close_pct, and Volume_diff for the day being predicted because those will not be known in advance as we trying to predict how the market will change from closing the day before. \n",
    "\n",
    "- We will know the price from yesterday so we can add a lag for that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80378473-5f5a-4bc2-89fb-65141120f190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.543520Z",
     "iopub.status.busy": "2021-08-27T04:01:51.543372Z",
     "iopub.status.idle": "2021-08-27T04:01:51.547576Z",
     "shell.execute_reply": "2021-08-27T04:01:51.546675Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.543504Z"
    },
    "id": "80378473-5f5a-4bc2-89fb-65141120f190",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add columns for previous days price info \n",
    "#data['Open_pct_l1']=data['Open_pct'].shift(1)\n",
    "#data['Close_pct_l1']=data['Close_pct'].shift(1)\n",
    "#data['Volume_diff_l1']=data['Volume_diff'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "097a9a61-21a2-47da-91b1-d0947cac410b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.549273Z",
     "iopub.status.busy": "2021-08-27T04:01:51.549133Z",
     "iopub.status.idle": "2021-08-27T04:01:51.552450Z",
     "shell.execute_reply": "2021-08-27T04:01:51.551496Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.549255Z"
    },
    "id": "097a9a61-21a2-47da-91b1-d0947cac410b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop first row since added lag \n",
    "#data= data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "735788e2-cad0-44e9-9614-61fdf9d77566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.553471Z",
     "iopub.status.busy": "2021-08-27T04:01:51.553324Z",
     "iopub.status.idle": "2021-08-27T04:01:51.556336Z",
     "shell.execute_reply": "2021-08-27T04:01:51.555675Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.553455Z"
    },
    "id": "735788e2-cad0-44e9-9614-61fdf9d77566",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make sure no nulls left \n",
    "#data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd3fd0-9fa5-457b-8cc3-808f7a728d9c",
   "metadata": {
    "id": "9ccd3fd0-9fa5-457b-8cc3-808f7a728d9c"
   },
   "source": [
    "For classification add column for price going up,down, or same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a3b9aedf-349b-4ac9-a192-f83c26cfae3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.557302Z",
     "iopub.status.busy": "2021-08-27T04:01:51.557061Z",
     "iopub.status.idle": "2021-08-27T04:01:51.560543Z",
     "shell.execute_reply": "2021-08-27T04:01:51.559679Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.557285Z"
    },
    "id": "a3b9aedf-349b-4ac9-a192-f83c26cfae3d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def get_direction(value):\n",
    "#    if value>0: return 'up'\n",
    "#    elif value<0: return 'down'\n",
    "#    else: return 'same'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79964e50-1177-4cfc-bb00-04a88cc6695a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.561496Z",
     "iopub.status.busy": "2021-08-27T04:01:51.561356Z",
     "iopub.status.idle": "2021-08-27T04:01:51.564324Z",
     "shell.execute_reply": "2021-08-27T04:01:51.563598Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.561480Z"
    },
    "id": "79964e50-1177-4cfc-bb00-04a88cc6695a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data['direction']=data['Open_pct'].apply(get_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05b41254-0894-4887-8d87-c0f36d5205ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.565268Z",
     "iopub.status.busy": "2021-08-27T04:01:51.565085Z",
     "iopub.status.idle": "2021-08-27T04:01:51.568709Z",
     "shell.execute_reply": "2021-08-27T04:01:51.567727Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.565248Z"
    },
    "id": "05b41254-0894-4887-8d87-c0f36d5205ee",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data['direction'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e635bb19-648e-4d96-b19c-609c331ba4ed",
   "metadata": {
    "id": "e635bb19-648e-4d96-b19c-609c331ba4ed"
   },
   "source": [
    "Market has been going up so makes sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32687e1b-51ab-4b95-86fa-d8db330e9bff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.569779Z",
     "iopub.status.busy": "2021-08-27T04:01:51.569640Z",
     "iopub.status.idle": "2021-08-27T04:01:51.579523Z",
     "shell.execute_reply": "2021-08-27T04:01:51.578715Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.569762Z"
    },
    "id": "32687e1b-51ab-4b95-86fa-d8db330e9bff",
    "outputId": "08fd1166-245c-4392-a100-d1b3de246a1a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3651 entries, 2011-07-31 to 2021-08-17\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   day_of_week_1   3651 non-null   int64  \n",
      " 1   day_of_week_2   3651 non-null   int64  \n",
      " 2   day_of_week_3   3651 non-null   int64  \n",
      " 3   day_of_week_4   3651 non-null   int64  \n",
      " 4   day_of_week_5   3651 non-null   int64  \n",
      " 5   day_of_week_6   3651 non-null   int64  \n",
      " 6   is_holiday_1    3651 non-null   int64  \n",
      " 7   Open_pct        3651 non-null   float64\n",
      " 8   Close_pct       3651 non-null   float64\n",
      " 9   Volume_diff     3651 non-null   float64\n",
      " 10  Open_pct_l1     3651 non-null   float64\n",
      " 11  Close_pct_l1    3651 non-null   float64\n",
      " 12  Volume_diff_l1  3651 non-null   float64\n",
      " 13  direction       3651 non-null   object \n",
      "dtypes: float64(6), int64(7), object(1)\n",
      "memory usage: 427.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c2470b-dc40-40e9-a130-9fb8a02cefbd",
   "metadata": {
    "id": "c1c2470b-dc40-40e9-a130-9fb8a02cefbd"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7d4833-be01-4e7d-9064-aa29f1a33a14",
   "metadata": {
    "id": "bc7d4833-be01-4e7d-9064-aa29f1a33a14"
   },
   "source": [
    "# Classification models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2254ea6-1ac3-47a3-b8ad-cf67f6c1b94b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.580377Z",
     "iopub.status.busy": "2021-08-27T04:01:51.580247Z",
     "iopub.status.idle": "2021-08-27T04:01:51.584702Z",
     "shell.execute_reply": "2021-08-27T04:01:51.583848Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.580361Z"
    },
    "id": "c2254ea6-1ac3-47a3-b8ad-cf67f6c1b94b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define X and y \n",
    "X= data.drop(columns=['Open_pct','Close_pct','Volume_diff','direction'])\n",
    "y=data['direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6590a0c-720c-4968-af43-2cc0bb25fcb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.585600Z",
     "iopub.status.busy": "2021-08-27T04:01:51.585466Z",
     "iopub.status.idle": "2021-08-27T04:01:51.591816Z",
     "shell.execute_reply": "2021-08-27T04:01:51.590745Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.585584Z"
    },
    "id": "e6590a0c-720c-4968-af43-2cc0bb25fcb3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train test split \n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb6af3-40e0-46d7-a800-d76765506172",
   "metadata": {
    "id": "eeeb6af3-40e0-46d7-a800-d76765506172"
   },
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b769d33-14f7-49ea-9de0-a995eab857fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.593106Z",
     "iopub.status.busy": "2021-08-27T04:01:51.592950Z",
     "iopub.status.idle": "2021-08-27T04:01:51.626522Z",
     "shell.execute_reply": "2021-08-27T04:01:51.625768Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.593087Z"
    },
    "id": "2b769d33-14f7-49ea-9de0-a995eab857fd",
    "outputId": "cae45ed8-0f23-4895-963f-94ffa69f1a18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none', random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='none',random_state=42,)\n",
    "\n",
    "# fit model \n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2f9d4ce-4612-4403-99cd-8bffb8d930f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.627412Z",
     "iopub.status.busy": "2021-08-27T04:01:51.627276Z",
     "iopub.status.idle": "2021-08-27T04:01:51.635388Z",
     "shell.execute_reply": "2021-08-27T04:01:51.634702Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.627397Z"
    },
    "id": "b2f9d4ce-4612-4403-99cd-8bffb8d930f8",
    "outputId": "62084785-ec68-4f9b-caa7-4c68de90bb58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43938356164383563"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get accuracy scores \n",
    "accuracy_score(y_train,logreg.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8509cf3e-531b-454c-afcc-a69edde38766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.636179Z",
     "iopub.status.busy": "2021-08-27T04:01:51.636051Z",
     "iopub.status.idle": "2021-08-27T04:01:51.642321Z",
     "shell.execute_reply": "2021-08-27T04:01:51.641701Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.636164Z"
    },
    "id": "8509cf3e-531b-454c-afcc-a69edde38766",
    "outputId": "ebdfac1f-44b1-4913-c3ac-016de7ad4cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43912448700410395"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,logreg.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc8ac535-68cf-440b-9f0d-3442d2bb0de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.643143Z",
     "iopub.status.busy": "2021-08-27T04:01:51.643011Z",
     "iopub.status.idle": "2021-08-27T04:01:51.645883Z",
     "shell.execute_reply": "2021-08-27T04:01:51.645173Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.643128Z"
    },
    "id": "dc8ac535-68cf-440b-9f0d-3442d2bb0de7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for use with get_acc function \n",
    "# defines train/test split X and y for getting accuracy\n",
    "vars_list1 = [X_train,X_test,y_train,y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d57e9b9-472e-4ab9-b323-6a5f378b47cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.646739Z",
     "iopub.status.busy": "2021-08-27T04:01:51.646586Z",
     "iopub.status.idle": "2021-08-27T04:01:51.650240Z",
     "shell.execute_reply": "2021-08-27T04:01:51.649381Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.646723Z"
    },
    "id": "5d57e9b9-472e-4ab9-b323-6a5f378b47cf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to get accuracy for model\n",
    "def get_acc(model,vars_list):\n",
    "    'given fitted model and [X_train,X_test,y_train,y_test] returns test and train accuracy'\n",
    "    print(f'Train Accuracy: {accuracy_score(vars_list[2],model.predict(vars_list[0]))}')\n",
    "    print(f'Test Accuracy: {accuracy_score(vars_list[3],model.predict(vars_list[1]))}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52c0a155-6765-487d-9e04-c61e40f647b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.651065Z",
     "iopub.status.busy": "2021-08-27T04:01:51.650932Z",
     "iopub.status.idle": "2021-08-27T04:01:51.660362Z",
     "shell.execute_reply": "2021-08-27T04:01:51.659703Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.651049Z"
    },
    "id": "52c0a155-6765-487d-9e04-c61e40f647b4",
    "outputId": "cd69b22e-964a-4aa6-cf2d-e34bdeda5480"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.43938356164383563\n",
      "Test Accuracy: 0.43912448700410395\n"
     ]
    }
   ],
   "source": [
    "get_acc(logreg,vars_list1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340decf-54ec-44b5-98e5-012be3d8db6f",
   "metadata": {
    "id": "5340decf-54ec-44b5-98e5-012be3d8db6f"
   },
   "source": [
    "## KNN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5cb663e-15f6-4d48-9489-d6caec24d51c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.661275Z",
     "iopub.status.busy": "2021-08-27T04:01:51.661122Z",
     "iopub.status.idle": "2021-08-27T04:01:51.670553Z",
     "shell.execute_reply": "2021-08-27T04:01:51.669732Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.661260Z"
    },
    "id": "a5cb663e-15f6-4d48-9489-d6caec24d51c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scale data for KNN model \n",
    "ss= StandardScaler()\n",
    "\n",
    "Xs_train = ss.fit_transform(X_train)\n",
    "Xs_test = ss.transform(X_test)\n",
    "\n",
    "# make vars list for metrics later \n",
    "vars_list_ss = [Xs_train,Xs_test,y_train,y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d353a3ce-987e-4105-8848-791bd290c6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.671627Z",
     "iopub.status.busy": "2021-08-27T04:01:51.671477Z",
     "iopub.status.idle": "2021-08-27T04:01:51.675401Z",
     "shell.execute_reply": "2021-08-27T04:01:51.674537Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.671608Z"
    },
    "id": "d353a3ce-987e-4105-8848-791bd290c6f0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define params for gridsearch \n",
    "knn_params= {\n",
    "    'n_neighbors':[3,5,7,9],\n",
    "    'weights':['uniform','distance'],\n",
    "    'p':[1,2]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50556327-4fae-4fdf-b1c5-043542499bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.676179Z",
     "iopub.status.busy": "2021-08-27T04:01:51.676046Z",
     "iopub.status.idle": "2021-08-27T04:01:51.679232Z",
     "shell.execute_reply": "2021-08-27T04:01:51.678449Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.676165Z"
    },
    "id": "50556327-4fae-4fdf-b1c5-043542499bce",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate knn_gs \n",
    "knn_gs = GridSearchCV(KNeighborsClassifier(n_jobs=-1),knn_params,n_jobs=-1,cv=3,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4fcb0849-f6b1-4257-bd3a-823b3f6b67be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:51.680079Z",
     "iopub.status.busy": "2021-08-27T04:01:51.679952Z",
     "iopub.status.idle": "2021-08-27T04:01:53.155678Z",
     "shell.execute_reply": "2021-08-27T04:01:53.154793Z",
     "shell.execute_reply.started": "2021-08-27T04:01:51.680063Z"
    },
    "id": "4fcb0849-f6b1-4257-bd3a-823b3f6b67be",
    "outputId": "675c88b5-0ff7-4399-d323-326248c2d8a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=KNeighborsClassifier(n_jobs=-1), n_jobs=-1,\n",
       "             param_grid={'n_neighbors': [3, 5, 7, 9], 'p': [1, 2],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit knn_gs\n",
    "knn_gs.fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c89f6e9-0127-4905-b40e-563b55d2643f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.156736Z",
     "iopub.status.busy": "2021-08-27T04:01:53.156582Z",
     "iopub.status.idle": "2021-08-27T04:01:53.161293Z",
     "shell.execute_reply": "2021-08-27T04:01:53.160627Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.156716Z"
    },
    "id": "0c89f6e9-0127-4905-b40e-563b55d2643f",
    "outputId": "92b0988f-9a48-445c-f7e2-870ce8b95b50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9, 'p': 2, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ecb2892-c5ec-41cf-b4f6-f450e753d344",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.162142Z",
     "iopub.status.busy": "2021-08-27T04:01:53.162009Z",
     "iopub.status.idle": "2021-08-27T04:01:53.169331Z",
     "shell.execute_reply": "2021-08-27T04:01:53.168629Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.162126Z"
    },
    "id": "0ecb2892-c5ec-41cf-b4f6-f450e753d344",
    "outputId": "0ef6227f-2365-492d-a5a5-8c3fdb54e9c3",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_n_neighbors', 'param_p', 'param_weights', 'params',\n",
       "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'mean_test_score', 'std_test_score', 'rank_test_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_gs.cv_results_).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "efabbaa5-44ae-4b88-8359-0e03b0c49531",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.170146Z",
     "iopub.status.busy": "2021-08-27T04:01:53.170013Z",
     "iopub.status.idle": "2021-08-27T04:01:53.182489Z",
     "shell.execute_reply": "2021-08-27T04:01:53.181703Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.170131Z"
    },
    "id": "efabbaa5-44ae-4b88-8359-0e03b0c49531",
    "outputId": "07d02246-29fc-4846-bdea-e1b56d0912ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_p</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.801021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.797254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.796226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.793145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.803073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.797592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.801018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.798278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.799989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.796907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.802731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.802388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.803073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.800333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>uniform</td>\n",
       "      <td>0.803076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>distance</td>\n",
       "      <td>0.801361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_neighbors param_p param_weights  mean_test_score\n",
       "0                  3       1       uniform         0.801021\n",
       "1                  3       1      distance         0.797254\n",
       "2                  3       2       uniform         0.796226\n",
       "3                  3       2      distance         0.793145\n",
       "4                  5       1       uniform         0.803073\n",
       "5                  5       1      distance         0.797592\n",
       "6                  5       2       uniform         0.801018\n",
       "7                  5       2      distance         0.798278\n",
       "8                  7       1       uniform         0.799989\n",
       "9                  7       1      distance         0.796907\n",
       "10                 7       2       uniform         0.802731\n",
       "11                 7       2      distance         0.802388\n",
       "12                 9       1       uniform         0.803073\n",
       "13                 9       1      distance         0.800333\n",
       "14                 9       2       uniform         0.803076\n",
       "15                 9       2      distance         0.801361"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(knn_gs.cv_results_)[['param_n_neighbors', 'param_p', 'param_weights','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a1981a2-031c-405b-a0bf-b60f776751c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.183488Z",
     "iopub.status.busy": "2021-08-27T04:01:53.183282Z",
     "iopub.status.idle": "2021-08-27T04:01:53.309397Z",
     "shell.execute_reply": "2021-08-27T04:01:53.308678Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.183472Z"
    },
    "id": "9a1981a2-031c-405b-a0bf-b60f776751c8",
    "outputId": "9f5c5090-8f61-4f03-ca64-fc678d832d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8359589041095891\n",
      "Test Accuracy: 0.771545827633379\n"
     ]
    }
   ],
   "source": [
    "get_acc(knn_gs,vars_list_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd72b76-8413-4f93-943d-2cc57f0cebea",
   "metadata": {
    "id": "5dd72b76-8413-4f93-943d-2cc57f0cebea"
   },
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f05e3690-b026-4503-9266-4500db7a026c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.310237Z",
     "iopub.status.busy": "2021-08-27T04:01:53.310083Z",
     "iopub.status.idle": "2021-08-27T04:01:53.324374Z",
     "shell.execute_reply": "2021-08-27T04:01:53.323646Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.310217Z"
    },
    "id": "f05e3690-b026-4503-9266-4500db7a026c",
    "outputId": "87ec952f-01ad-4cb0-862e-03d69cf4cdc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model with random_state = 42.\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "dt.fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66209d10-9495-4717-89a6-fbe1e589b63c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.325330Z",
     "iopub.status.busy": "2021-08-27T04:01:53.325189Z",
     "iopub.status.idle": "2021-08-27T04:01:53.332395Z",
     "shell.execute_reply": "2021-08-27T04:01:53.331719Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.325314Z"
    },
    "id": "66209d10-9495-4717-89a6-fbe1e589b63c",
    "outputId": "b14f0778-fc95-4e2d-99b0-38544f668c8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.927054794520548\n",
      "Test Accuracy: 0.7838577291381669\n"
     ]
    }
   ],
   "source": [
    "get_acc(dt,vars_list_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1ec3c-8c07-4144-9d93-f6c6d555155f",
   "metadata": {
    "id": "92a1ec3c-8c07-4144-9d93-f6c6d555155f"
   },
   "source": [
    "## Bagging Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ae76e3df-9c55-4a4d-9499-1ef86d8f02d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T10:52:10.791171Z",
     "iopub.status.busy": "2021-08-27T10:52:10.790975Z",
     "iopub.status.idle": "2021-08-27T10:52:10.848546Z",
     "shell.execute_reply": "2021-08-27T10:52:10.847850Z",
     "shell.execute_reply.started": "2021-08-27T10:52:10.791154Z"
    },
    "id": "ae76e3df-9c55-4a4d-9499-1ef86d8f02d0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate and fit model \n",
    "bag = BaggingClassifier(random_state=42,bootstrap_features=True).fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a4c4e547-1e3f-4cef-b65a-8df8570a2ce2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T10:52:11.506122Z",
     "iopub.status.busy": "2021-08-27T10:52:11.505930Z",
     "iopub.status.idle": "2021-08-27T10:52:11.520401Z",
     "shell.execute_reply": "2021-08-27T10:52:11.519728Z",
     "shell.execute_reply.started": "2021-08-27T10:52:11.506105Z"
    },
    "id": "a4c4e547-1e3f-4cef-b65a-8df8570a2ce2",
    "outputId": "6fdeb50f-9bf6-40b0-8ddd-a389803d7dc8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9198630136986301\n",
      "Test Accuracy: 0.7852257181942545\n"
     ]
    }
   ],
   "source": [
    "# get metrics \n",
    "get_acc(bag,vars_list_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede6b2b-68f7-4cf7-a303-c844b70c5dca",
   "metadata": {
    "id": "bede6b2b-68f7-4cf7-a303-c844b70c5dca"
   },
   "source": [
    "## Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10a1324a-1aeb-489a-b9ac-5ed49f8fd4bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.401255Z",
     "iopub.status.busy": "2021-08-27T04:01:53.401098Z",
     "iopub.status.idle": "2021-08-27T04:01:53.638352Z",
     "shell.execute_reply": "2021-08-27T04:01:53.637306Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.401239Z"
    },
    "id": "10a1324a-1aeb-489a-b9ac-5ed49f8fd4bf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate and fit model \n",
    "randfor = RandomForestClassifier(random_state=42,).fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53089889-562d-4747-820b-8a380b2c2ba9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.639211Z",
     "iopub.status.busy": "2021-08-27T04:01:53.639065Z",
     "iopub.status.idle": "2021-08-27T04:01:53.686946Z",
     "shell.execute_reply": "2021-08-27T04:01:53.686243Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.639195Z"
    },
    "id": "53089889-562d-4747-820b-8a380b2c2ba9",
    "outputId": "16e4213d-abd8-4aad-ecdc-b4f1a02356b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.927054794520548\n",
      "Test Accuracy: 0.8071135430916553\n"
     ]
    }
   ],
   "source": [
    "# check metrics \n",
    "get_acc(randfor,vars_list_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twSbwTs6yZBt",
   "metadata": {
    "id": "twSbwTs6yZBt"
   },
   "source": [
    "# Searches \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "86829ecf-5f42-41c1-a06a-8f9e8fac1054",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:37:33.511681Z",
     "iopub.status.busy": "2021-08-27T11:37:33.511494Z",
     "iopub.status.idle": "2021-08-27T11:37:36.144321Z",
     "shell.execute_reply": "2021-08-27T11:37:36.143468Z",
     "shell.execute_reply.started": "2021-08-27T11:37:33.511664Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranfor_params ={\n",
    "    'ccp_alpha':[0.0001,0.001,0.01,0.1,0.2,0.3,0.6]\n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(RandomForestClassifier(random_state=42),ranfor_params,cv=2,).fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cb5a5ab7-a6e6-4ca4-9cdc-52b8688cfa08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:49:17.735167Z",
     "iopub.status.busy": "2021-08-27T11:49:17.734891Z",
     "iopub.status.idle": "2021-08-27T11:49:17.775462Z",
     "shell.execute_reply": "2021-08-27T11:49:17.774813Z",
     "shell.execute_reply.started": "2021-08-27T11:49:17.735148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8356164383561644\n",
      "Test Accuracy: 0.7838577291381669\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'ccp_alpha': 0.01}</td>\n",
       "      <td>0.835274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'ccp_alpha': 0.001}</td>\n",
       "      <td>0.818836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'ccp_alpha': 0.1}</td>\n",
       "      <td>0.818836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'ccp_alpha': 0.0001}</td>\n",
       "      <td>0.817466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'ccp_alpha': 0.2}</td>\n",
       "      <td>0.542123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'ccp_alpha': 0.3}</td>\n",
       "      <td>0.460616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'ccp_alpha': 0.6}</td>\n",
       "      <td>0.460616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  params  mean_test_score\n",
       "2    {'ccp_alpha': 0.01}         0.835274\n",
       "1   {'ccp_alpha': 0.001}         0.818836\n",
       "3     {'ccp_alpha': 0.1}         0.818836\n",
       "0  {'ccp_alpha': 0.0001}         0.817466\n",
       "4     {'ccp_alpha': 0.2}         0.542123\n",
       "5     {'ccp_alpha': 0.3}         0.460616\n",
       "6     {'ccp_alpha': 0.6}         0.460616"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_acc(rf_gs,vars_list_ss))\n",
    "gs_results(rf_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4729ee09-97b2-4ab9-8245-44d58ad92289",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:41:26.112287Z",
     "iopub.status.busy": "2021-08-27T11:41:26.112088Z",
     "iopub.status.idle": "2021-08-27T11:41:28.778134Z",
     "shell.execute_reply": "2021-08-27T11:41:28.777298Z",
     "shell.execute_reply.started": "2021-08-27T11:41:26.112269Z"
    }
   },
   "outputs": [],
   "source": [
    "ranfor_params2 ={\n",
    "    #'ccp_alpha':[0.0001,0.001,0.01,0.1,0.2,0.3,0.6] 0.01 best \n",
    "    'max_depth': [3,6,12,24,48,100,200,300]\n",
    "}\n",
    "\n",
    "rf_gs2 = GridSearchCV(RandomForestClassifier(random_state=42),ranfor_params2,cv=2,).fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f9ed7694-f37a-42c9-8541-a5eb03664253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:42:03.576249Z",
     "iopub.status.busy": "2021-08-27T11:42:03.576061Z",
     "iopub.status.idle": "2021-08-27T11:42:03.620473Z",
     "shell.execute_reply": "2021-08-27T11:42:03.619795Z",
     "shell.execute_reply.started": "2021-08-27T11:42:03.576232Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8472602739726027\n",
      "Test Accuracy: 0.8002735978112175\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>0.836986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>0.825685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>0.819863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 48}</td>\n",
       "      <td>0.817466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "      <td>0.817466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 200}</td>\n",
       "      <td>0.817466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 300}</td>\n",
       "      <td>0.817466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 24}</td>\n",
       "      <td>0.817123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               params  mean_test_score\n",
       "1    {'max_depth': 6}         0.836986\n",
       "0    {'max_depth': 3}         0.825685\n",
       "2   {'max_depth': 12}         0.819863\n",
       "4   {'max_depth': 48}         0.817466\n",
       "5  {'max_depth': 100}         0.817466\n",
       "6  {'max_depth': 200}         0.817466\n",
       "7  {'max_depth': 300}         0.817466\n",
       "3   {'max_depth': 24}         0.817123"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_acc(rf_gs2,vars_list_ss))\n",
    "gs_results(rf_gs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "14bd13e8-efac-4067-b2a2-cfecf7dbec3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T14:42:05.886233Z",
     "iopub.status.busy": "2021-08-27T14:42:05.886032Z",
     "iopub.status.idle": "2021-08-27T14:42:06.013902Z",
     "shell.execute_reply": "2021-08-27T14:42:06.012992Z",
     "shell.execute_reply.started": "2021-08-27T14:42:05.886216Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10));\n",
    "plot_confusion_matrix(rf_gs2,Xs_test,y_test);\n",
    "plt.title('Random Forest Classifier');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2fdf6-4150-4cf3-b54c-4893fab8b2d8",
   "metadata": {},
   "source": [
    "## Confusion matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "302e4b53-fb5c-42c3-a9cb-a20d8145f71a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:47:48.325934Z",
     "iopub.status.busy": "2021-08-27T11:47:48.325737Z",
     "iopub.status.idle": "2021-08-27T11:48:02.325304Z",
     "shell.execute_reply": "2021-08-27T11:48:02.324428Z",
     "shell.execute_reply.started": "2021-08-27T11:47:48.325916Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranfor_params3 ={\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_features':['auto','sqrt','log2'],\n",
    "    'bootstrap':[True,False],\n",
    "    'class_weight': ['balanced','balanced_subsample',None]}\n",
    "\n",
    "rf_gs3 = GridSearchCV(RandomForestClassifier(random_state=42),ranfor_params3,cv=2,).fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c57b6be9-b454-427e-b01f-e03eb1a3b71b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:48:02.327115Z",
     "iopub.status.busy": "2021-08-27T11:48:02.326940Z",
     "iopub.status.idle": "2021-08-27T11:48:02.390256Z",
     "shell.execute_reply": "2021-08-27T11:48:02.389479Z",
     "shell.execute_reply.started": "2021-08-27T11:48:02.327097Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.927054794520548\n",
      "Test Accuracy: 0.8071135430916553\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'auto'}</td>\n",
       "      <td>0.817466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.817466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'log2'}</td>\n",
       "      <td>0.817466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'auto'}</td>\n",
       "      <td>0.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'log2'}</td>\n",
       "      <td>0.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'auto'}</td>\n",
       "      <td>0.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'log2'}</td>\n",
       "      <td>0.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'auto'}</td>\n",
       "      <td>0.815411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.815411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'log2'}</td>\n",
       "      <td>0.815411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'auto'}</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'log2'}</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'log2'}</td>\n",
       "      <td>0.809589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.809589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'auto'}</td>\n",
       "      <td>0.809589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.809589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'log2'}</td>\n",
       "      <td>0.809589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'auto'}</td>\n",
       "      <td>0.809589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'max_features': 'log2'}</td>\n",
       "      <td>0.808904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.808904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'max_features': 'auto'}</td>\n",
       "      <td>0.808904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'log2'}</td>\n",
       "      <td>0.808562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'auto'}</td>\n",
       "      <td>0.808562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.808562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'auto'}</td>\n",
       "      <td>0.808562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'log2'}</td>\n",
       "      <td>0.808562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.808562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'log2'}</td>\n",
       "      <td>0.807192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.807192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'auto'}</td>\n",
       "      <td>0.807192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'auto'}</td>\n",
       "      <td>0.805822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'sqrt'}</td>\n",
       "      <td>0.805822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'bootstrap': False, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'log2'}</td>\n",
       "      <td>0.805822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        params  \\\n",
       "12                      {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'auto'}   \n",
       "13                      {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt'}   \n",
       "14                      {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_features': 'log2'}   \n",
       "3              {'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'auto'}   \n",
       "4              {'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'sqrt'}   \n",
       "5              {'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'log2'}   \n",
       "6       {'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'auto'}   \n",
       "7       {'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'sqrt'}   \n",
       "8       {'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'log2'}   \n",
       "9    {'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'auto'}   \n",
       "10   {'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'sqrt'}   \n",
       "11   {'bootstrap': True, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'log2'}   \n",
       "1                 {'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'sqrt'}   \n",
       "0                 {'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'auto'}   \n",
       "2                 {'bootstrap': True, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'log2'}   \n",
       "29  {'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'log2'}   \n",
       "28  {'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'sqrt'}   \n",
       "21            {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'auto'}   \n",
       "22            {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'sqrt'}   \n",
       "23            {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_features': 'log2'}   \n",
       "27  {'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_features': 'auto'}   \n",
       "32                     {'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'max_features': 'log2'}   \n",
       "31                     {'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt'}   \n",
       "30                     {'bootstrap': False, 'class_weight': None, 'criterion': 'gini', 'max_features': 'auto'}   \n",
       "26     {'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'log2'}   \n",
       "18               {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'auto'}   \n",
       "25     {'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'sqrt'}   \n",
       "24     {'bootstrap': False, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_features': 'auto'}   \n",
       "20               {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'log2'}   \n",
       "19               {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'gini', 'max_features': 'sqrt'}   \n",
       "17                   {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'log2'}   \n",
       "16                   {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'sqrt'}   \n",
       "15                   {'bootstrap': True, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'auto'}   \n",
       "33                  {'bootstrap': False, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'auto'}   \n",
       "34                  {'bootstrap': False, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'sqrt'}   \n",
       "35                  {'bootstrap': False, 'class_weight': None, 'criterion': 'entropy', 'max_features': 'log2'}   \n",
       "\n",
       "    mean_test_score  \n",
       "12         0.817466  \n",
       "13         0.817466  \n",
       "14         0.817466  \n",
       "3          0.815753  \n",
       "4          0.815753  \n",
       "5          0.815753  \n",
       "6          0.815753  \n",
       "7          0.815753  \n",
       "8          0.815753  \n",
       "9          0.815411  \n",
       "10         0.815411  \n",
       "11         0.815411  \n",
       "1          0.815068  \n",
       "0          0.815068  \n",
       "2          0.815068  \n",
       "29         0.809589  \n",
       "28         0.809589  \n",
       "21         0.809589  \n",
       "22         0.809589  \n",
       "23         0.809589  \n",
       "27         0.809589  \n",
       "32         0.808904  \n",
       "31         0.808904  \n",
       "30         0.808904  \n",
       "26         0.808562  \n",
       "18         0.808562  \n",
       "25         0.808562  \n",
       "24         0.808562  \n",
       "20         0.808562  \n",
       "19         0.808562  \n",
       "17         0.807192  \n",
       "16         0.807192  \n",
       "15         0.807192  \n",
       "33         0.805822  \n",
       "34         0.805822  \n",
       "35         0.805822  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_acc(rf_gs3,vars_list_ss))\n",
    "gs_results(rf_gs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e84ef-af30-4fa9-bb79-5bb435cb6322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc9cfe7d-ae7c-4b3d-9ef0-60726f241a9e",
   "metadata": {
    "id": "cc9cfe7d-ae7c-4b3d-9ef0-60726f241a9e"
   },
   "source": [
    "## Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8cdd57b-e14a-4e33-aa1e-93682e8f984c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:53.687853Z",
     "iopub.status.busy": "2021-08-27T04:01:53.687720Z",
     "iopub.status.idle": "2021-08-27T04:01:54.516250Z",
     "shell.execute_reply": "2021-08-27T04:01:54.515193Z",
     "shell.execute_reply.started": "2021-08-27T04:01:53.687837Z"
    },
    "id": "c8cdd57b-e14a-4e33-aa1e-93682e8f984c"
   },
   "outputs": [],
   "source": [
    "# instantiate and fit gradient boosting model \n",
    "gradboost= GradientBoostingClassifier(random_state=42,).fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2207b53-3a61-49cd-aa4c-4cbc96671fc4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:54.517241Z",
     "iopub.status.busy": "2021-08-27T04:01:54.517092Z",
     "iopub.status.idle": "2021-08-27T04:01:54.536130Z",
     "shell.execute_reply": "2021-08-27T04:01:54.535424Z",
     "shell.execute_reply.started": "2021-08-27T04:01:54.517225Z"
    },
    "id": "f2207b53-3a61-49cd-aa4c-4cbc96671fc4",
    "outputId": "a675ae3b-23e8-49f3-93bd-7e77470dcb33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.861986301369863\n",
      "Test Accuracy: 0.8002735978112175\n"
     ]
    }
   ],
   "source": [
    "get_acc(gradboost,vars_list_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hC53vD2fydt8",
   "metadata": {
    "id": "hC53vD2fydt8"
   },
   "source": [
    "Tune Hyperparamters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "NwEB0Un419tD",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:54.536986Z",
     "iopub.status.busy": "2021-08-27T04:01:54.536847Z",
     "iopub.status.idle": "2021-08-27T04:01:54.541028Z",
     "shell.execute_reply": "2021-08-27T04:01:54.540438Z",
     "shell.execute_reply.started": "2021-08-27T04:01:54.536970Z"
    },
    "id": "NwEB0Un419tD"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint,uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c109bf2-d9d0-4a35-9122-8cc46a81d486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:54.541812Z",
     "iopub.status.busy": "2021-08-27T04:01:54.541688Z",
     "iopub.status.idle": "2021-08-27T04:01:54.544657Z",
     "shell.execute_reply": "2021-08-27T04:01:54.543993Z",
     "shell.execute_reply.started": "2021-08-27T04:01:54.541798Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4XqfRd2MynIJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:01:54.545359Z",
     "iopub.status.busy": "2021-08-27T04:01:54.545221Z",
     "iopub.status.idle": "2021-08-27T04:02:23.239850Z",
     "shell.execute_reply": "2021-08-27T04:02:23.239235Z",
     "shell.execute_reply.started": "2021-08-27T04:01:54.545328Z"
    },
    "id": "4XqfRd2MynIJ",
    "outputId": "37cceea8-f627-440d-ce59-bf10ad760dd0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 441, in fit\n",
      "    self._check_params()\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\", line 248, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"/home/tanveer/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb_losses.py\", line 790, in __init__\n",
      "    raise ValueError(\"{0:s} requires 2 classes; got {1:d} class(es)\"\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=42),\n",
       "                   param_distributions={'loss': ['deviance', 'exponential'],\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e38c27f70>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e38c27ee0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e38c27b50>},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params to search \n",
    "params_grad_boost1= {\n",
    "    'loss':['deviance', 'exponential'],\n",
    "    #'learning_rate':randint(0.001,0.4),\n",
    "    'n_estimators' : randint(100,500),\n",
    "    'min_samples_split':randint(2,10),\n",
    "    'min_samples_leaf':randint(1,10),\n",
    "}\n",
    "\n",
    "gb1_rs1 = RandomizedSearchCV(GradientBoostingClassifier(random_state=42,),params_grad_boost1,n_iter=10,random_state=42,verbose=1,cv=3)\n",
    "\n",
    "gb1_rs1.fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0da8fdd-b996-4b0f-a457-61c85d9a56f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:02:23.241029Z",
     "iopub.status.busy": "2021-08-27T04:02:23.240838Z",
     "iopub.status.idle": "2021-08-27T04:02:23.245007Z",
     "shell.execute_reply": "2021-08-27T04:02:23.244249Z",
     "shell.execute_reply.started": "2021-08-27T04:02:23.241012Z"
    }
   },
   "outputs": [],
   "source": [
    "def gs_results(gs):\n",
    "    return pd.DataFrame(gs.cv_results_)[['params','mean_test_score']].sort_values(by='mean_test_score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0kXnOktbz5Uv",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:02:23.246081Z",
     "iopub.status.busy": "2021-08-27T04:02:23.245916Z",
     "iopub.status.idle": "2021-08-27T04:02:23.257892Z",
     "shell.execute_reply": "2021-08-27T04:02:23.257261Z",
     "shell.execute_reply.started": "2021-08-27T04:02:23.246064Z"
    },
    "id": "0kXnOktbz5Uv",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'loss': 'deviance', 'min_samples_leaf': 8, 'm...</td>\n",
       "      <td>0.823619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'loss': 'deviance', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.820193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'loss': 'deviance', 'min_samples_leaf': 8, 'm...</td>\n",
       "      <td>0.819852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'loss': 'deviance', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.817454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'loss': 'deviance', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.812319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'loss': 'deviance', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.811293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'loss': 'exponential', 'min_samples_leaf': 8,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'loss': 'exponential', 'min_samples_leaf': 5,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'loss': 'exponential', 'min_samples_leaf': 9,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'loss': 'exponential', 'min_samples_leaf': 9,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              params  mean_test_score\n",
       "1  {'loss': 'deviance', 'min_samples_leaf': 8, 'm...         0.823619\n",
       "8  {'loss': 'deviance', 'min_samples_leaf': 3, 'm...         0.820193\n",
       "3  {'loss': 'deviance', 'min_samples_leaf': 8, 'm...         0.819852\n",
       "5  {'loss': 'deviance', 'min_samples_leaf': 2, 'm...         0.817454\n",
       "2  {'loss': 'deviance', 'min_samples_leaf': 3, 'm...         0.812319\n",
       "0  {'loss': 'deviance', 'min_samples_leaf': 4, 'm...         0.811293\n",
       "4  {'loss': 'exponential', 'min_samples_leaf': 8,...              NaN\n",
       "6  {'loss': 'exponential', 'min_samples_leaf': 5,...              NaN\n",
       "7  {'loss': 'exponential', 'min_samples_leaf': 9,...              NaN\n",
       "9  {'loss': 'exponential', 'min_samples_leaf': 9,...              NaN"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results(gb1_rs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2QeOlKR3QWK",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:02:23.258775Z",
     "iopub.status.busy": "2021-08-27T04:02:23.258640Z",
     "iopub.status.idle": "2021-08-27T04:02:23.276816Z",
     "shell.execute_reply": "2021-08-27T04:02:23.276229Z",
     "shell.execute_reply.started": "2021-08-27T04:02:23.258759Z"
    },
    "id": "e2QeOlKR3QWK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8657534246575342\n",
      "Test Accuracy: 0.8057455540355677\n"
     ]
    }
   ],
   "source": [
    "get_acc(gb1_rs1,vars_list_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "q1HLTCks3p6i",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:02:23.277562Z",
     "iopub.status.busy": "2021-08-27T04:02:23.277439Z",
     "iopub.status.idle": "2021-08-27T04:05:28.507996Z",
     "shell.execute_reply": "2021-08-27T04:05:28.507370Z",
     "shell.execute_reply.started": "2021-08-27T04:02:23.277547Z"
    },
    "id": "q1HLTCks3p6i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 35 candidates, totalling 105 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 105 out of 105 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=42),\n",
       "                   n_iter=35,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e38c29340>,\n",
       "                                        'loss': ['deviance'],\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e38c29430>,\n",
       "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e38c31d90>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1e38c32040>},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params to search \n",
    "params_grad_boost2= {\n",
    "    'loss':['deviance',],\n",
    "    'learning_rate':uniform(0.001,0.4),\n",
    "    'n_estimators' : randint(100,500),\n",
    "    'min_samples_split':randint(3,30),\n",
    "    'min_samples_leaf':randint(3,30),\n",
    "}\n",
    "\n",
    "gb1_rs2 = RandomizedSearchCV(GradientBoostingClassifier(random_state=42,),params_grad_boost2,n_iter=35,random_state=42,verbose=1,cv=3)\n",
    "\n",
    "gb1_rs2.fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "g1ExUnfj6WgT",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:28.508959Z",
     "iopub.status.busy": "2021-08-27T04:05:28.508792Z",
     "iopub.status.idle": "2021-08-27T04:05:28.538094Z",
     "shell.execute_reply": "2021-08-27T04:05:28.537394Z",
     "shell.execute_reply.started": "2021-08-27T04:05:28.508913Z"
    },
    "id": "g1ExUnfj6WgT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8414383561643836\n",
      "Test Accuracy: 0.8030095759233926\n"
     ]
    }
   ],
   "source": [
    "get_acc(gb1_rs2,vars_list_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "17896835-823f-4609-9dc4-275b0ae8859a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T10:54:30.878577Z",
     "iopub.status.busy": "2021-08-27T10:54:30.878389Z",
     "iopub.status.idle": "2021-08-27T10:54:30.883545Z",
     "shell.execute_reply": "2021-08-27T10:54:30.882937Z",
     "shell.execute_reply.started": "2021-08-27T10:54:30.878561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.007386500888085678,\n",
       " 'loss': 'deviance',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 22,\n",
       " 'n_estimators': 191}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb1_rs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "nH83CzZO6bZd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T10:56:12.992713Z",
     "iopub.status.busy": "2021-08-27T10:56:12.992523Z",
     "iopub.status.idle": "2021-08-27T10:56:13.010747Z",
     "shell.execute_reply": "2021-08-27T10:56:13.010070Z",
     "shell.execute_reply.started": "2021-08-27T10:56:12.992696Z"
    },
    "id": "nH83CzZO6bZd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'learning_rate': 0.007386500888085678, 'loss': 'deviance', 'min_samples_leaf': 4, 'min_samples_split': 22, 'n_estimators': 191}</td>\n",
       "      <td>0.834918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'learning_rate': 0.030617860693636145, 'loss': 'deviance', 'min_samples_leaf': 9, 'min_samples_split': 28, 'n_estimators': 140}</td>\n",
       "      <td>0.834234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'learning_rate': 0.011167650697638077, 'loss': 'deviance', 'min_samples_leaf': 15, 'min_samples_split': 21, 'n_estimators': 162}</td>\n",
       "      <td>0.832862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'learning_rate': 0.014755408446087359, 'loss': 'deviance', 'min_samples_leaf': 16, 'min_samples_split': 19, 'n_estimators': 149}</td>\n",
       "      <td>0.832177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'learning_rate': 0.00320884684944096, 'loss': 'deviance', 'min_samples_leaf': 13, 'min_samples_split': 21, 'n_estimators': 180}</td>\n",
       "      <td>0.830127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.024233444867279786, 'loss': 'deviance', 'min_samples_leaf': 26, 'min_samples_split': 23, 'n_estimators': 199}</td>\n",
       "      <td>0.830124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'learning_rate': 0.01717343581537254, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 17, 'n_estimators': 445}</td>\n",
       "      <td>0.825672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'learning_rate': 0.13335920994105968, 'loss': 'deviance', 'min_samples_leaf': 18, 'min_samples_split': 25, 'n_estimators': 161}</td>\n",
       "      <td>0.816768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.058146727168776315, 'loss': 'deviance', 'min_samples_leaf': 5, 'min_samples_split': 24, 'n_estimators': 408}</td>\n",
       "      <td>0.816429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'learning_rate': 0.04883769837532068, 'loss': 'deviance', 'min_samples_leaf': 16, 'min_samples_split': 5, 'n_estimators': 356}</td>\n",
       "      <td>0.816425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.150816047538945, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 13, 'n_estimators': 171}</td>\n",
       "      <td>0.814715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.07372998688284026, 'loss': 'deviance', 'min_samples_leaf': 23, 'min_samples_split': 3, 'n_estimators': 413}</td>\n",
       "      <td>0.813344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 0.21090257265289514, 'loss': 'deviance', 'min_samples_leaf': 14, 'min_samples_split': 27, 'n_estimators': 148}</td>\n",
       "      <td>0.812661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'learning_rate': 0.18090165334790628, 'loss': 'deviance', 'min_samples_leaf': 12, 'min_samples_split': 6, 'n_estimators': 369}</td>\n",
       "      <td>0.812320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'learning_rate': 0.17036059228254785, 'loss': 'deviance', 'min_samples_leaf': 3, 'min_samples_split': 14, 'n_estimators': 235}</td>\n",
       "      <td>0.812319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'learning_rate': 0.17706099749584053, 'loss': 'deviance', 'min_samples_leaf': 9, 'min_samples_split': 14, 'n_estimators': 363}</td>\n",
       "      <td>0.811637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'learning_rate': 0.2660089137415928, 'loss': 'deviance', 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 153}</td>\n",
       "      <td>0.811294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'learning_rate': 0.11088871719602567, 'loss': 'deviance', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 326}</td>\n",
       "      <td>0.810610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.24046339367881464, 'loss': 'deviance', 'min_samples_leaf': 9, 'min_samples_split': 28, 'n_estimators': 314}</td>\n",
       "      <td>0.810608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'learning_rate': 0.1834279936868144, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 21, 'n_estimators': 463}</td>\n",
       "      <td>0.810264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'learning_rate': 0.1437013306774357, 'loss': 'deviance', 'min_samples_leaf': 15, 'min_samples_split': 11, 'n_estimators': 256}</td>\n",
       "      <td>0.809919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'learning_rate': 0.13107332881069883, 'loss': 'deviance', 'min_samples_leaf': 5, 'min_samples_split': 14, 'n_estimators': 459}</td>\n",
       "      <td>0.809580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 0.21090986410335566, 'loss': 'deviance', 'min_samples_leaf': 12, 'min_samples_split': 18, 'n_estimators': 370}</td>\n",
       "      <td>0.808896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'learning_rate': 0.32187879230161587, 'loss': 'deviance', 'min_samples_leaf': 3, 'min_samples_split': 27, 'n_estimators': 426}</td>\n",
       "      <td>0.807869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'learning_rate': 0.20933370401032947, 'loss': 'deviance', 'min_samples_leaf': 10, 'min_samples_split': 23, 'n_estimators': 307}</td>\n",
       "      <td>0.807530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'learning_rate': 0.2999280440549524, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 23, 'n_estimators': 379}</td>\n",
       "      <td>0.806157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'learning_rate': 0.2919087983425684, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 10, 'n_estimators': 314}</td>\n",
       "      <td>0.805813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'learning_rate': 0.21968411173731187, 'loss': 'deviance', 'min_samples_leaf': 24, 'min_samples_split': 20, 'n_estimators': 317}</td>\n",
       "      <td>0.804101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'learning_rate': 0.36698387021751233, 'loss': 'deviance', 'min_samples_leaf': 11, 'min_samples_split': 10, 'n_estimators': 367}</td>\n",
       "      <td>0.804100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'learning_rate': 0.2896918084659493, 'loss': 'deviance', 'min_samples_leaf': 25, 'min_samples_split': 16, 'n_estimators': 458}</td>\n",
       "      <td>0.803416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'learning_rate': 0.20669377536544464, 'loss': 'deviance', 'min_samples_leaf': 27, 'min_samples_split': 5, 'n_estimators': 406}</td>\n",
       "      <td>0.803416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'learning_rate': 0.2731230154351119, 'loss': 'deviance', 'min_samples_leaf': 11, 'min_samples_split': 9, 'n_estimators': 373}</td>\n",
       "      <td>0.803074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'learning_rate': 0.38055421490133334, 'loss': 'deviance', 'min_samples_leaf': 16, 'min_samples_split': 20, 'n_estimators': 364}</td>\n",
       "      <td>0.802730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'learning_rate': 0.28553678109946, 'loss': 'deviance', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 478}</td>\n",
       "      <td>0.801363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.38896394086479774, 'loss': 'deviance', 'min_samples_leaf': 14, 'min_samples_split': 8, 'n_estimators': 485}</td>\n",
       "      <td>0.799649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                               params  \\\n",
       "12   {'learning_rate': 0.007386500888085678, 'loss': 'deviance', 'min_samples_leaf': 4, 'min_samples_split': 22, 'n_estimators': 191}   \n",
       "26   {'learning_rate': 0.030617860693636145, 'loss': 'deviance', 'min_samples_leaf': 9, 'min_samples_split': 28, 'n_estimators': 140}   \n",
       "34  {'learning_rate': 0.011167650697638077, 'loss': 'deviance', 'min_samples_leaf': 15, 'min_samples_split': 21, 'n_estimators': 162}   \n",
       "14  {'learning_rate': 0.014755408446087359, 'loss': 'deviance', 'min_samples_leaf': 16, 'min_samples_split': 19, 'n_estimators': 149}   \n",
       "24   {'learning_rate': 0.00320884684944096, 'loss': 'deviance', 'min_samples_leaf': 13, 'min_samples_split': 21, 'n_estimators': 180}   \n",
       "2   {'learning_rate': 0.024233444867279786, 'loss': 'deviance', 'min_samples_leaf': 26, 'min_samples_split': 23, 'n_estimators': 199}   \n",
       "33   {'learning_rate': 0.01717343581537254, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 17, 'n_estimators': 445}   \n",
       "28   {'learning_rate': 0.13335920994105968, 'loss': 'deviance', 'min_samples_leaf': 18, 'min_samples_split': 25, 'n_estimators': 161}   \n",
       "3    {'learning_rate': 0.058146727168776315, 'loss': 'deviance', 'min_samples_leaf': 5, 'min_samples_split': 24, 'n_estimators': 408}   \n",
       "31    {'learning_rate': 0.04883769837532068, 'loss': 'deviance', 'min_samples_leaf': 16, 'min_samples_split': 5, 'n_estimators': 356}   \n",
       "0      {'learning_rate': 0.150816047538945, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 13, 'n_estimators': 171}   \n",
       "5     {'learning_rate': 0.07372998688284026, 'loss': 'deviance', 'min_samples_leaf': 23, 'min_samples_split': 3, 'n_estimators': 413}   \n",
       "6    {'learning_rate': 0.21090257265289514, 'loss': 'deviance', 'min_samples_leaf': 14, 'min_samples_split': 27, 'n_estimators': 148}   \n",
       "17    {'learning_rate': 0.18090165334790628, 'loss': 'deviance', 'min_samples_leaf': 12, 'min_samples_split': 6, 'n_estimators': 369}   \n",
       "23    {'learning_rate': 0.17036059228254785, 'loss': 'deviance', 'min_samples_leaf': 3, 'min_samples_split': 14, 'n_estimators': 235}   \n",
       "13    {'learning_rate': 0.17706099749584053, 'loss': 'deviance', 'min_samples_leaf': 9, 'min_samples_split': 14, 'n_estimators': 363}   \n",
       "15      {'learning_rate': 0.2660089137415928, 'loss': 'deviance', 'min_samples_leaf': 4, 'min_samples_split': 8, 'n_estimators': 153}   \n",
       "30     {'learning_rate': 0.11088871719602567, 'loss': 'deviance', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 326}   \n",
       "1     {'learning_rate': 0.24046339367881464, 'loss': 'deviance', 'min_samples_leaf': 9, 'min_samples_split': 28, 'n_estimators': 314}   \n",
       "8     {'learning_rate': 0.1834279936868144, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 21, 'n_estimators': 463}   \n",
       "21    {'learning_rate': 0.1437013306774357, 'loss': 'deviance', 'min_samples_leaf': 15, 'min_samples_split': 11, 'n_estimators': 256}   \n",
       "29    {'learning_rate': 0.13107332881069883, 'loss': 'deviance', 'min_samples_leaf': 5, 'min_samples_split': 14, 'n_estimators': 459}   \n",
       "7    {'learning_rate': 0.21090986410335566, 'loss': 'deviance', 'min_samples_leaf': 12, 'min_samples_split': 18, 'n_estimators': 370}   \n",
       "22    {'learning_rate': 0.32187879230161587, 'loss': 'deviance', 'min_samples_leaf': 3, 'min_samples_split': 27, 'n_estimators': 426}   \n",
       "19   {'learning_rate': 0.20933370401032947, 'loss': 'deviance', 'min_samples_leaf': 10, 'min_samples_split': 23, 'n_estimators': 307}   \n",
       "20    {'learning_rate': 0.2999280440549524, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 23, 'n_estimators': 379}   \n",
       "18    {'learning_rate': 0.2919087983425684, 'loss': 'deviance', 'min_samples_leaf': 17, 'min_samples_split': 10, 'n_estimators': 314}   \n",
       "16   {'learning_rate': 0.21968411173731187, 'loss': 'deviance', 'min_samples_leaf': 24, 'min_samples_split': 20, 'n_estimators': 317}   \n",
       "27   {'learning_rate': 0.36698387021751233, 'loss': 'deviance', 'min_samples_leaf': 11, 'min_samples_split': 10, 'n_estimators': 367}   \n",
       "32    {'learning_rate': 0.2896918084659493, 'loss': 'deviance', 'min_samples_leaf': 25, 'min_samples_split': 16, 'n_estimators': 458}   \n",
       "9     {'learning_rate': 0.20669377536544464, 'loss': 'deviance', 'min_samples_leaf': 27, 'min_samples_split': 5, 'n_estimators': 406}   \n",
       "10     {'learning_rate': 0.2731230154351119, 'loss': 'deviance', 'min_samples_leaf': 11, 'min_samples_split': 9, 'n_estimators': 373}   \n",
       "11   {'learning_rate': 0.38055421490133334, 'loss': 'deviance', 'min_samples_leaf': 16, 'min_samples_split': 20, 'n_estimators': 364}   \n",
       "25        {'learning_rate': 0.28553678109946, 'loss': 'deviance', 'min_samples_leaf': 5, 'min_samples_split': 3, 'n_estimators': 478}   \n",
       "4     {'learning_rate': 0.38896394086479774, 'loss': 'deviance', 'min_samples_leaf': 14, 'min_samples_split': 8, 'n_estimators': 485}   \n",
       "\n",
       "    mean_test_score  \n",
       "12         0.834918  \n",
       "26         0.834234  \n",
       "34         0.832862  \n",
       "14         0.832177  \n",
       "24         0.830127  \n",
       "2          0.830124  \n",
       "33         0.825672  \n",
       "28         0.816768  \n",
       "3          0.816429  \n",
       "31         0.816425  \n",
       "0          0.814715  \n",
       "5          0.813344  \n",
       "6          0.812661  \n",
       "17         0.812320  \n",
       "23         0.812319  \n",
       "13         0.811637  \n",
       "15         0.811294  \n",
       "30         0.810610  \n",
       "1          0.810608  \n",
       "8          0.810264  \n",
       "21         0.809919  \n",
       "29         0.809580  \n",
       "7          0.808896  \n",
       "22         0.807869  \n",
       "19         0.807530  \n",
       "20         0.806157  \n",
       "18         0.805813  \n",
       "16         0.804101  \n",
       "27         0.804100  \n",
       "32         0.803416  \n",
       "9          0.803416  \n",
       "10         0.803074  \n",
       "11         0.802730  \n",
       "25         0.801363  \n",
       "4          0.799649  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth',None)\n",
    "gs_results(gb1_rs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1fb63b36-0fcc-4749-bc5a-ca4594364578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:21:51.196808Z",
     "iopub.status.busy": "2021-08-27T11:21:51.196616Z",
     "iopub.status.idle": "2021-08-27T11:23:22.352558Z",
     "shell.execute_reply": "2021-08-27T11:23:22.351621Z",
     "shell.execute_reply.started": "2021-08-27T11:21:51.196790Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(random_state=42),\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1c816344f0>},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params to search \n",
    "params_grad_boost3= {\n",
    "    #'loss':['deviance',],\n",
    "    #'learning_rate':uniform(0.00001,0.4),\n",
    "    #'n_estimators' : randint(100,500),\n",
    "    #'min_samples_split':randint(2,30),\n",
    "    'min_samples_leaf':randint(1,30),\n",
    "    # 'max_depth':randint(3,30) tested 3 is best \n",
    "}\n",
    "\n",
    "gb1_rs3 = RandomizedSearchCV(GradientBoostingClassifier(random_state=42,),params_grad_boost3,n_iter=50,random_state=42,verbose=1,cv=3)\n",
    "\n",
    "gb1_rs3.fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bcf28524-59da-4b3e-b988-490d65662fa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:23:22.353720Z",
     "iopub.status.busy": "2021-08-27T11:23:22.353582Z",
     "iopub.status.idle": "2021-08-27T11:23:22.372799Z",
     "shell.execute_reply": "2021-08-27T11:23:22.371604Z",
     "shell.execute_reply.started": "2021-08-27T11:23:22.353703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'min_samples_leaf': 11}</td>\n",
       "      <td>0.827042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'min_samples_leaf': 11}</td>\n",
       "      <td>0.827042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'min_samples_leaf': 11}</td>\n",
       "      <td>0.827042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'min_samples_leaf': 1}</td>\n",
       "      <td>0.826358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'min_samples_leaf': 3}</td>\n",
       "      <td>0.826016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'min_samples_leaf': 12}</td>\n",
       "      <td>0.826016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'min_samples_leaf': 12}</td>\n",
       "      <td>0.826016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'min_samples_leaf': 12}</td>\n",
       "      <td>0.826016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'min_samples_leaf': 12}</td>\n",
       "      <td>0.826016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'min_samples_leaf': 8}</td>\n",
       "      <td>0.825673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'min_samples_leaf': 8}</td>\n",
       "      <td>0.825673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'min_samples_leaf': 20}</td>\n",
       "      <td>0.825332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'min_samples_leaf': 20}</td>\n",
       "      <td>0.825332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'min_samples_leaf': 4}</td>\n",
       "      <td>0.825332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'min_samples_leaf': 2}</td>\n",
       "      <td>0.825331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'min_samples_leaf': 2}</td>\n",
       "      <td>0.825331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'min_samples_leaf': 15}</td>\n",
       "      <td>0.824988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'min_samples_leaf': 15}</td>\n",
       "      <td>0.824988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'min_samples_leaf': 15}</td>\n",
       "      <td>0.824988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'min_samples_leaf': 7}</td>\n",
       "      <td>0.824647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'min_samples_leaf': 7}</td>\n",
       "      <td>0.824647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'min_samples_leaf': 22}</td>\n",
       "      <td>0.824646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'min_samples_leaf': 22}</td>\n",
       "      <td>0.824646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'min_samples_leaf': 17}</td>\n",
       "      <td>0.824645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'min_samples_leaf': 23}</td>\n",
       "      <td>0.824304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'min_samples_leaf': 23}</td>\n",
       "      <td>0.824304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'min_samples_leaf': 24}</td>\n",
       "      <td>0.823962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'min_samples_leaf': 24}</td>\n",
       "      <td>0.823962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'min_samples_leaf': 24}</td>\n",
       "      <td>0.823962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'min_samples_leaf': 29}</td>\n",
       "      <td>0.823620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'min_samples_leaf': 29}</td>\n",
       "      <td>0.823620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'min_samples_leaf': 29}</td>\n",
       "      <td>0.823620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'min_samples_leaf': 25}</td>\n",
       "      <td>0.823620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'min_samples_leaf': 25}</td>\n",
       "      <td>0.823620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'min_samples_leaf': 6}</td>\n",
       "      <td>0.823618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'min_samples_leaf': 16}</td>\n",
       "      <td>0.823618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'min_samples_leaf': 27}</td>\n",
       "      <td>0.823277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'min_samples_leaf': 27}</td>\n",
       "      <td>0.823277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'min_samples_leaf': 28}</td>\n",
       "      <td>0.823277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'min_samples_leaf': 28}</td>\n",
       "      <td>0.823277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'min_samples_leaf': 28}</td>\n",
       "      <td>0.823277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'min_samples_leaf': 10}</td>\n",
       "      <td>0.822934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'min_samples_leaf': 21}</td>\n",
       "      <td>0.822592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'min_samples_leaf': 21}</td>\n",
       "      <td>0.822592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'min_samples_leaf': 21}</td>\n",
       "      <td>0.822592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'min_samples_leaf': 21}</td>\n",
       "      <td>0.822592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'min_samples_leaf': 19}</td>\n",
       "      <td>0.822251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'min_samples_leaf': 19}</td>\n",
       "      <td>0.822251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'min_samples_leaf': 26}</td>\n",
       "      <td>0.820194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'min_samples_leaf': 26}</td>\n",
       "      <td>0.820194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      params  mean_test_score\n",
       "4   {'min_samples_leaf': 11}         0.827042\n",
       "12  {'min_samples_leaf': 11}         0.827042\n",
       "13  {'min_samples_leaf': 11}         0.827042\n",
       "29   {'min_samples_leaf': 1}         0.826358\n",
       "19   {'min_samples_leaf': 3}         0.826016\n",
       "34  {'min_samples_leaf': 12}         0.826016\n",
       "30  {'min_samples_leaf': 12}         0.826016\n",
       "46  {'min_samples_leaf': 12}         0.826016\n",
       "24  {'min_samples_leaf': 12}         0.826016\n",
       "17   {'min_samples_leaf': 8}         0.825673\n",
       "5    {'min_samples_leaf': 8}         0.825673\n",
       "48  {'min_samples_leaf': 20}         0.825332\n",
       "1   {'min_samples_leaf': 20}         0.825332\n",
       "16   {'min_samples_leaf': 4}         0.825332\n",
       "22   {'min_samples_leaf': 2}         0.825331\n",
       "26   {'min_samples_leaf': 2}         0.825331\n",
       "44  {'min_samples_leaf': 15}         0.824988\n",
       "3   {'min_samples_leaf': 15}         0.824988\n",
       "43  {'min_samples_leaf': 15}         0.824988\n",
       "0    {'min_samples_leaf': 7}         0.824647\n",
       "8    {'min_samples_leaf': 7}         0.824647\n",
       "20  {'min_samples_leaf': 22}         0.824646\n",
       "32  {'min_samples_leaf': 22}         0.824646\n",
       "36  {'min_samples_leaf': 17}         0.824645\n",
       "11  {'min_samples_leaf': 23}         0.824304\n",
       "47  {'min_samples_leaf': 23}         0.824304\n",
       "18  {'min_samples_leaf': 24}         0.823962\n",
       "23  {'min_samples_leaf': 24}         0.823962\n",
       "14  {'min_samples_leaf': 24}         0.823962\n",
       "33  {'min_samples_leaf': 29}         0.823620\n",
       "6   {'min_samples_leaf': 29}         0.823620\n",
       "2   {'min_samples_leaf': 29}         0.823620\n",
       "35  {'min_samples_leaf': 25}         0.823620\n",
       "49  {'min_samples_leaf': 25}         0.823620\n",
       "25   {'min_samples_leaf': 6}         0.823618\n",
       "42  {'min_samples_leaf': 16}         0.823618\n",
       "37  {'min_samples_leaf': 27}         0.823277\n",
       "38  {'min_samples_leaf': 27}         0.823277\n",
       "27  {'min_samples_leaf': 28}         0.823277\n",
       "40  {'min_samples_leaf': 28}         0.823277\n",
       "41  {'min_samples_leaf': 28}         0.823277\n",
       "39  {'min_samples_leaf': 10}         0.822934\n",
       "28  {'min_samples_leaf': 21}         0.822592\n",
       "21  {'min_samples_leaf': 21}         0.822592\n",
       "15  {'min_samples_leaf': 21}         0.822592\n",
       "7   {'min_samples_leaf': 21}         0.822592\n",
       "45  {'min_samples_leaf': 19}         0.822251\n",
       "10  {'min_samples_leaf': 19}         0.822251\n",
       "31  {'min_samples_leaf': 26}         0.820194\n",
       "9   {'min_samples_leaf': 26}         0.820194"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results(gb1_rs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "434973a9-a6d5-4525-aaf3-eee96d10b21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:20:40.866718Z",
     "iopub.status.busy": "2021-08-27T11:20:40.866526Z",
     "iopub.status.idle": "2021-08-27T11:20:40.884520Z",
     "shell.execute_reply": "2021-08-27T11:20:40.883838Z",
     "shell.execute_reply.started": "2021-08-27T11:20:40.866701Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>0.826358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>0.822933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>0.822933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>0.818485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>0.818485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>0.817456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>0.814374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 13}</td>\n",
       "      <td>0.812317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_depth': 13}</td>\n",
       "      <td>0.812317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_depth': 13}</td>\n",
       "      <td>0.812317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>0.811976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>0.811976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>0.811976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>0.811632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>{'max_depth': 11}</td>\n",
       "      <td>0.811291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>0.810948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>0.810948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>0.810265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'max_depth': 14}</td>\n",
       "      <td>0.810264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'max_depth': 14}</td>\n",
       "      <td>0.810264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'max_depth': 14}</td>\n",
       "      <td>0.810264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'max_depth': 14}</td>\n",
       "      <td>0.810264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'max_depth': 19}</td>\n",
       "      <td>0.799992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>{'max_depth': 17}</td>\n",
       "      <td>0.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 17}</td>\n",
       "      <td>0.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>{'max_depth': 17}</td>\n",
       "      <td>0.799988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>{'max_depth': 18}</td>\n",
       "      <td>0.797251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_depth': 21}</td>\n",
       "      <td>0.796567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>{'max_depth': 21}</td>\n",
       "      <td>0.796567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>{'max_depth': 21}</td>\n",
       "      <td>0.796567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>{'max_depth': 23}</td>\n",
       "      <td>0.793485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_depth': 23}</td>\n",
       "      <td>0.793485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 23}</td>\n",
       "      <td>0.793485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'max_depth': 23}</td>\n",
       "      <td>0.793485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'max_depth': 23}</td>\n",
       "      <td>0.793485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'max_depth': 27}</td>\n",
       "      <td>0.793484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'max_depth': 27}</td>\n",
       "      <td>0.793484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>{'max_depth': 22}</td>\n",
       "      <td>0.793143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 22}</td>\n",
       "      <td>0.793143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'max_depth': 26}</td>\n",
       "      <td>0.793141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_depth': 26}</td>\n",
       "      <td>0.793141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'max_depth': 26}</td>\n",
       "      <td>0.793141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'max_depth': 29}</td>\n",
       "      <td>0.792799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'max_depth': 29}</td>\n",
       "      <td>0.792799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'max_depth': 24}</td>\n",
       "      <td>0.792799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'max_depth': 24}</td>\n",
       "      <td>0.792799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_depth': 25}</td>\n",
       "      <td>0.792457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>{'max_depth': 25}</td>\n",
       "      <td>0.792457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_depth': 28}</td>\n",
       "      <td>0.791772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'max_depth': 28}</td>\n",
       "      <td>0.791772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               params  mean_test_score\n",
       "26   {'max_depth': 3}         0.826358\n",
       "24   {'max_depth': 4}         0.822933\n",
       "20   {'max_depth': 4}         0.822933\n",
       "44   {'max_depth': 5}         0.818485\n",
       "17   {'max_depth': 5}         0.818485\n",
       "14   {'max_depth': 6}         0.817456\n",
       "45   {'max_depth': 7}         0.814374\n",
       "3   {'max_depth': 13}         0.812317\n",
       "10  {'max_depth': 13}         0.812317\n",
       "11  {'max_depth': 13}         0.812317\n",
       "0    {'max_depth': 9}         0.811976\n",
       "47   {'max_depth': 9}         0.811976\n",
       "6    {'max_depth': 9}         0.811976\n",
       "35  {'max_depth': 12}         0.811632\n",
       "49  {'max_depth': 11}         0.811291\n",
       "15  {'max_depth': 10}         0.810948\n",
       "4   {'max_depth': 10}         0.810948\n",
       "23   {'max_depth': 8}         0.810265\n",
       "22  {'max_depth': 14}         0.810264\n",
       "40  {'max_depth': 14}         0.810264\n",
       "30  {'max_depth': 14}         0.810264\n",
       "27  {'max_depth': 14}         0.810264\n",
       "32  {'max_depth': 19}         0.799992\n",
       "37  {'max_depth': 17}         0.799988\n",
       "2   {'max_depth': 17}         0.799988\n",
       "38  {'max_depth': 17}         0.799988\n",
       "36  {'max_depth': 18}         0.797251\n",
       "8   {'max_depth': 21}         0.796567\n",
       "46  {'max_depth': 21}         0.796567\n",
       "39  {'max_depth': 21}         0.796567\n",
       "48  {'max_depth': 23}         0.793485\n",
       "13  {'max_depth': 23}         0.793485\n",
       "5   {'max_depth': 23}         0.793485\n",
       "25  {'max_depth': 23}         0.793485\n",
       "19  {'max_depth': 23}         0.793485\n",
       "31  {'max_depth': 27}         0.793484\n",
       "43  {'max_depth': 27}         0.793484\n",
       "42  {'max_depth': 22}         0.793143\n",
       "1   {'max_depth': 22}         0.793143\n",
       "16  {'max_depth': 26}         0.793141\n",
       "12  {'max_depth': 26}         0.793141\n",
       "21  {'max_depth': 26}         0.793141\n",
       "34  {'max_depth': 29}         0.792799\n",
       "33  {'max_depth': 29}         0.792799\n",
       "18  {'max_depth': 24}         0.792799\n",
       "29  {'max_depth': 24}         0.792799\n",
       "9   {'max_depth': 25}         0.792457\n",
       "41  {'max_depth': 25}         0.792457\n",
       "7   {'max_depth': 28}         0.791772\n",
       "28  {'max_depth': 28}         0.791772"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results(gb1_rs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b22542-53f5-4ea1-8657-22d46ea71f96",
   "metadata": {
    "id": "d4b22542-53f5-4ea1-8657-22d46ea71f96"
   },
   "source": [
    "## XGBClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24c8afba-fba1-4b10-a194-782f13b0235d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:28.559395Z",
     "iopub.status.busy": "2021-08-27T04:05:28.559241Z",
     "iopub.status.idle": "2021-08-27T04:05:29.794013Z",
     "shell.execute_reply": "2021-08-27T04:05:29.793223Z",
     "shell.execute_reply.started": "2021-08-27T04:05:28.559370Z"
    },
    "id": "24c8afba-fba1-4b10-a194-782f13b0235d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanveer/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:05:29] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "# instantiate and fit model \n",
    "xgb_class = XGBClassifier().fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "469e0732-62c4-49a9-85e9-93849cf383ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:29.795074Z",
     "iopub.status.busy": "2021-08-27T04:05:29.794928Z",
     "iopub.status.idle": "2021-08-27T04:05:29.884185Z",
     "shell.execute_reply": "2021-08-27T04:05:29.883213Z",
     "shell.execute_reply.started": "2021-08-27T04:05:29.795057Z"
    },
    "id": "469e0732-62c4-49a9-85e9-93849cf383ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9267123287671233\n",
      "Test Accuracy: 0.8030095759233926\n"
     ]
    }
   ],
   "source": [
    "get_acc(xgb_class,vars_list_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d1f2b7-1a42-424c-a67a-0b35f0d33d36",
   "metadata": {
    "id": "e8d1f2b7-1a42-424c-a67a-0b35f0d33d36"
   },
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3b15732-ad03-4659-b046-2e3d53f6876b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:29.885132Z",
     "iopub.status.busy": "2021-08-27T04:05:29.884963Z",
     "iopub.status.idle": "2021-08-27T04:05:29.962977Z",
     "shell.execute_reply": "2021-08-27T04:05:29.962220Z",
     "shell.execute_reply.started": "2021-08-27T04:05:29.885112Z"
    },
    "id": "a3b15732-ad03-4659-b046-2e3d53f6876b"
   },
   "outputs": [],
   "source": [
    "# instantiate and fit model \n",
    "svc = SVC(random_state=42,).fit(Xs_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "891ed771-c433-41c0-aeb4-6cfc12e18b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:29.963926Z",
     "iopub.status.busy": "2021-08-27T04:05:29.963784Z",
     "iopub.status.idle": "2021-08-27T04:05:30.040117Z",
     "shell.execute_reply": "2021-08-27T04:05:30.039361Z",
     "shell.execute_reply.started": "2021-08-27T04:05:29.963910Z"
    },
    "id": "891ed771-c433-41c0-aeb4-6cfc12e18b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8383561643835616\n",
      "Test Accuracy: 0.79890560875513\n"
     ]
    }
   ],
   "source": [
    "get_acc(svc,vars_list_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bf5dbc-08f9-4989-b0d3-1b0cfd08aa7f",
   "metadata": {
    "id": "c5bf5dbc-08f9-4989-b0d3-1b0cfd08aa7f"
   },
   "source": [
    "## Feed Forward Neural Network \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e2a377d1-382e-4858-b281-b94225aa65ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:27:04.379536Z",
     "iopub.status.busy": "2021-08-27T11:27:04.379300Z",
     "iopub.status.idle": "2021-08-27T11:27:04.383326Z",
     "shell.execute_reply": "2021-08-27T11:27:04.382481Z",
     "shell.execute_reply.started": "2021-08-27T11:27:04.379519Z"
    },
    "id": "e2a377d1-382e-4858-b281-b94225aa65ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to plot train and val accuracy \n",
    "def plot_acc(hist):\n",
    "    plt.plot(hist.history['acc'], label='Train accuracy')\n",
    "    plt.plot(hist.history['val_acc'], label='Test accuracy')\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6777c0-2054-4829-b063-8775734be5ea",
   "metadata": {
    "id": "0f6777c0-2054-4829-b063-8775734be5ea",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dfc84a90-6af2-4753-97a8-ff80594c05ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.046946Z",
     "iopub.status.busy": "2021-08-27T04:05:30.046802Z",
     "iopub.status.idle": "2021-08-27T04:05:30.051713Z",
     "shell.execute_reply": "2021-08-27T04:05:30.051187Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.046930Z"
    },
    "id": "dfc84a90-6af2-4753-97a8-ff80594c05ff",
    "outputId": "d51eaf28-b00b-4643-e75c-d2dcf6aeeafe",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2920, 10)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many columns in X_train \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e772d6d-dea5-484f-a053-a4632a35b6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.052458Z",
     "iopub.status.busy": "2021-08-27T04:05:30.052336Z",
     "iopub.status.idle": "2021-08-27T04:05:30.055970Z",
     "shell.execute_reply": "2021-08-27T04:05:30.055234Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.052443Z"
    },
    "id": "7e772d6d-dea5-484f-a053-a4632a35b6d2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function \n",
    "def num_direction(value):\n",
    "    if value=='up': return 1\n",
    "    elif value=='down': return -1\n",
    "    else: return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e255257a-4224-4e4d-adc9-ef5a39a5b548",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.056684Z",
     "iopub.status.busy": "2021-08-27T04:05:30.056555Z",
     "iopub.status.idle": "2021-08-27T04:05:30.063997Z",
     "shell.execute_reply": "2021-08-27T04:05:30.063213Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.056668Z"
    },
    "id": "e255257a-4224-4e4d-adc9-ef5a39a5b548",
    "outputId": "06bb638d-ce73-4be3-dac7-fde3b8c3dd59",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "up      1345\n",
       "down    1080\n",
       "same     495\n",
       "Name: direction, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92fef31d-bab5-4964-a8bf-4fdece9e3a28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.064798Z",
     "iopub.status.busy": "2021-08-27T04:05:30.064672Z",
     "iopub.status.idle": "2021-08-27T04:05:30.071826Z",
     "shell.execute_reply": "2021-08-27T04:05:30.071194Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.064783Z"
    },
    "id": "92fef31d-bab5-4964-a8bf-4fdece9e3a28",
    "outputId": "a5b7a86e-e7d9-403b-c715-3aa6509d1f86",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2011-07-31    0\n",
       "2011-08-01    1\n",
       "2011-08-02   -1\n",
       "2011-08-03   -1\n",
       "2011-08-04    1\n",
       "             ..\n",
       "2019-08-03   -1\n",
       "2019-08-04    0\n",
       "2019-08-05   -1\n",
       "2019-08-06   -1\n",
       "2019-08-07   -1\n",
       "Name: direction, Length: 2920, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if it works \n",
    "y_train.apply(num_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84329dd7-f8b9-4554-a81b-5dc2e61a5413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.072647Z",
     "iopub.status.busy": "2021-08-27T04:05:30.072522Z",
     "iopub.status.idle": "2021-08-27T04:05:30.077959Z",
     "shell.execute_reply": "2021-08-27T04:05:30.077221Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.072632Z"
    },
    "id": "84329dd7-f8b9-4554-a81b-5dc2e61a5413",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make y categorical for use with neural networks \n",
    "y_train_nn = to_categorical(y_train.apply(num_direction),3)\n",
    "y_test_nn = to_categorical(y_test.apply(num_direction),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04588351-482e-4cab-bee7-ac89f3709069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.078688Z",
     "iopub.status.busy": "2021-08-27T04:05:30.078557Z",
     "iopub.status.idle": "2021-08-27T04:05:30.081761Z",
     "shell.execute_reply": "2021-08-27T04:05:30.081213Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.078673Z"
    },
    "id": "04588351-482e-4cab-bee7-ac89f3709069",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for metrics later \n",
    "vars_nn = [Xs_train,Xs_test,y_train_nn,y_test_nn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "519d7b5f-fcc2-4f6a-9919-909cca318c01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.082563Z",
     "iopub.status.busy": "2021-08-27T04:05:30.082432Z",
     "iopub.status.idle": "2021-08-27T04:05:30.127481Z",
     "shell.execute_reply": "2021-08-27T04:05:30.126257Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.082549Z"
    },
    "id": "519d7b5f-fcc2-4f6a-9919-909cca318c01",
    "outputId": "fd79f7e1-1a4c-48fa-a301-2239b642bcb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 9,859\n",
      "Trainable params: 9,859\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model network \n",
    "fnn = Sequential()\n",
    "fnn.add(Dense(128,activation=\"relu\", input_shape=(10,)))\n",
    "fnn.add(Dense(64, activation=\"relu\"))\n",
    "fnn.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "# compile model \n",
    "fnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "# check model \n",
    "fnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "867d1dc2-48b9-4414-890f-7177d20d367c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.128260Z",
     "iopub.status.busy": "2021-08-27T04:05:30.128107Z",
     "iopub.status.idle": "2021-08-27T04:05:30.135238Z",
     "shell.execute_reply": "2021-08-27T04:05:30.134270Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.128243Z"
    },
    "id": "867d1dc2-48b9-4414-890f-7177d20d367c",
    "outputId": "94e1d851-9d5d-421c-f466-ca617daaa0cb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test_nn).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e881389-0d80-4caa-9f6e-750455d45c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.137675Z",
     "iopub.status.busy": "2021-08-27T04:05:30.137521Z",
     "iopub.status.idle": "2021-08-27T04:05:30.141953Z",
     "shell.execute_reply": "2021-08-27T04:05:30.141254Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.137659Z"
    },
    "id": "0e881389-0d80-4caa-9f6e-750455d45c54"
   },
   "outputs": [],
   "source": [
    "validation_data=(Xs_test,y_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "55aca7be-6e73-4a52-a8b2-a6e1741074fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:30.146898Z",
     "iopub.status.busy": "2021-08-27T04:05:30.146753Z",
     "iopub.status.idle": "2021-08-27T04:05:37.326081Z",
     "shell.execute_reply": "2021-08-27T04:05:37.325390Z",
     "shell.execute_reply.started": "2021-08-27T04:05:30.146882Z"
    },
    "id": "55aca7be-6e73-4a52-a8b2-a6e1741074fa",
    "outputId": "4b745073-90f6-4896-ebc0-4adf6b7cfe3a",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.7504 - acc: 0.7034 - val_loss: 0.5072 - val_acc: 0.7729\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4396 - acc: 0.8123 - val_loss: 0.4823 - val_acc: 0.7880\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3898 - acc: 0.8178 - val_loss: 0.5058 - val_acc: 0.7907\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3754 - acc: 0.8216 - val_loss: 0.5194 - val_acc: 0.7893\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3683 - acc: 0.8264 - val_loss: 0.5257 - val_acc: 0.7893\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3637 - acc: 0.8281 - val_loss: 0.5288 - val_acc: 0.7934\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3603 - acc: 0.8288 - val_loss: 0.5307 - val_acc: 0.7893\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3575 - acc: 0.8291 - val_loss: 0.5310 - val_acc: 0.7907\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3553 - acc: 0.8295 - val_loss: 0.5315 - val_acc: 0.7907\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3532 - acc: 0.8295 - val_loss: 0.5312 - val_acc: 0.7921\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3516 - acc: 0.8298 - val_loss: 0.5311 - val_acc: 0.7921\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3500 - acc: 0.8298 - val_loss: 0.5310 - val_acc: 0.7948\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3485 - acc: 0.8308 - val_loss: 0.5301 - val_acc: 0.7962\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3472 - acc: 0.8312 - val_loss: 0.5300 - val_acc: 0.7975\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3460 - acc: 0.8315 - val_loss: 0.5298 - val_acc: 0.7989\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3447 - acc: 0.8315 - val_loss: 0.5296 - val_acc: 0.7948\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3436 - acc: 0.8301 - val_loss: 0.5301 - val_acc: 0.7948\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3426 - acc: 0.8318 - val_loss: 0.5296 - val_acc: 0.7948\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3417 - acc: 0.8322 - val_loss: 0.5300 - val_acc: 0.7948\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3408 - acc: 0.8312 - val_loss: 0.5305 - val_acc: 0.7948\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3400 - acc: 0.8308 - val_loss: 0.5309 - val_acc: 0.7948\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3393 - acc: 0.8312 - val_loss: 0.5312 - val_acc: 0.7948\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3386 - acc: 0.8315 - val_loss: 0.5315 - val_acc: 0.7934\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3379 - acc: 0.8322 - val_loss: 0.5317 - val_acc: 0.7948\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3373 - acc: 0.8308 - val_loss: 0.5323 - val_acc: 0.7962\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3366 - acc: 0.8318 - val_loss: 0.5328 - val_acc: 0.7962\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3361 - acc: 0.8308 - val_loss: 0.5338 - val_acc: 0.7975\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3355 - acc: 0.8315 - val_loss: 0.5344 - val_acc: 0.7962\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3349 - acc: 0.8318 - val_loss: 0.5342 - val_acc: 0.7975\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3344 - acc: 0.8325 - val_loss: 0.5359 - val_acc: 0.7975\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3340 - acc: 0.8322 - val_loss: 0.5363 - val_acc: 0.7975\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3336 - acc: 0.8332 - val_loss: 0.5374 - val_acc: 0.7989\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3330 - acc: 0.8325 - val_loss: 0.5376 - val_acc: 0.7989\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3326 - acc: 0.8339 - val_loss: 0.5390 - val_acc: 0.7989\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3321 - acc: 0.8325 - val_loss: 0.5391 - val_acc: 0.7989\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3317 - acc: 0.8325 - val_loss: 0.5404 - val_acc: 0.8003\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3313 - acc: 0.8315 - val_loss: 0.5415 - val_acc: 0.7989\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3308 - acc: 0.8349 - val_loss: 0.5424 - val_acc: 0.8030\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3304 - acc: 0.8349 - val_loss: 0.5439 - val_acc: 0.8030\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3300 - acc: 0.8356 - val_loss: 0.5435 - val_acc: 0.8016\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3297 - acc: 0.8360 - val_loss: 0.5452 - val_acc: 0.8016\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3292 - acc: 0.8363 - val_loss: 0.5459 - val_acc: 0.8016\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3289 - acc: 0.8370 - val_loss: 0.5472 - val_acc: 0.8016\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3284 - acc: 0.8366 - val_loss: 0.5481 - val_acc: 0.8016\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3281 - acc: 0.8370 - val_loss: 0.5493 - val_acc: 0.8016\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3277 - acc: 0.8370 - val_loss: 0.5488 - val_acc: 0.8016\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3274 - acc: 0.8370 - val_loss: 0.5505 - val_acc: 0.8016\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3268 - acc: 0.8366 - val_loss: 0.5504 - val_acc: 0.8016\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3266 - acc: 0.8377 - val_loss: 0.5521 - val_acc: 0.8016\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3262 - acc: 0.8377 - val_loss: 0.5526 - val_acc: 0.8016\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3259 - acc: 0.8377 - val_loss: 0.5537 - val_acc: 0.8016\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3255 - acc: 0.8377 - val_loss: 0.5539 - val_acc: 0.8016\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3253 - acc: 0.8380 - val_loss: 0.5551 - val_acc: 0.8016\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3249 - acc: 0.8366 - val_loss: 0.5547 - val_acc: 0.8016\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3246 - acc: 0.8373 - val_loss: 0.5564 - val_acc: 0.8016\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3242 - acc: 0.8384 - val_loss: 0.5571 - val_acc: 0.8016\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3241 - acc: 0.8384 - val_loss: 0.5581 - val_acc: 0.8003\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3236 - acc: 0.8401 - val_loss: 0.5576 - val_acc: 0.8016\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3233 - acc: 0.8390 - val_loss: 0.5592 - val_acc: 0.8016\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3229 - acc: 0.8390 - val_loss: 0.5593 - val_acc: 0.8016\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3227 - acc: 0.8404 - val_loss: 0.5601 - val_acc: 0.8016\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3224 - acc: 0.8394 - val_loss: 0.5604 - val_acc: 0.8016\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3222 - acc: 0.8390 - val_loss: 0.5610 - val_acc: 0.8016\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3216 - acc: 0.8411 - val_loss: 0.5616 - val_acc: 0.8016\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3215 - acc: 0.8397 - val_loss: 0.5621 - val_acc: 0.8016\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3211 - acc: 0.8418 - val_loss: 0.5624 - val_acc: 0.8016\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3209 - acc: 0.8414 - val_loss: 0.5625 - val_acc: 0.8016\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3206 - acc: 0.8418 - val_loss: 0.5633 - val_acc: 0.8016\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3202 - acc: 0.8428 - val_loss: 0.5637 - val_acc: 0.8016\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3199 - acc: 0.8425 - val_loss: 0.5646 - val_acc: 0.8003\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3195 - acc: 0.8428 - val_loss: 0.5652 - val_acc: 0.8016\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3193 - acc: 0.8425 - val_loss: 0.5643 - val_acc: 0.8016\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3191 - acc: 0.8425 - val_loss: 0.5664 - val_acc: 0.8016\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3187 - acc: 0.8425 - val_loss: 0.5668 - val_acc: 0.8030\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3184 - acc: 0.8428 - val_loss: 0.5663 - val_acc: 0.8030\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3184 - acc: 0.8421 - val_loss: 0.5679 - val_acc: 0.8003\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3178 - acc: 0.8428 - val_loss: 0.5679 - val_acc: 0.8030\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3178 - acc: 0.8432 - val_loss: 0.5698 - val_acc: 0.8016\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3175 - acc: 0.8428 - val_loss: 0.5709 - val_acc: 0.8030\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3173 - acc: 0.8425 - val_loss: 0.5699 - val_acc: 0.8030\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3172 - acc: 0.8432 - val_loss: 0.5710 - val_acc: 0.8030\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3168 - acc: 0.8435 - val_loss: 0.5718 - val_acc: 0.8003\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3167 - acc: 0.8438 - val_loss: 0.5730 - val_acc: 0.8030\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3162 - acc: 0.8432 - val_loss: 0.5720 - val_acc: 0.8003\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3162 - acc: 0.8435 - val_loss: 0.5736 - val_acc: 0.8003\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3158 - acc: 0.8442 - val_loss: 0.5736 - val_acc: 0.7989\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3155 - acc: 0.8445 - val_loss: 0.5746 - val_acc: 0.8003\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3153 - acc: 0.8449 - val_loss: 0.5743 - val_acc: 0.8016\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3152 - acc: 0.8442 - val_loss: 0.5764 - val_acc: 0.8003\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3149 - acc: 0.8445 - val_loss: 0.5765 - val_acc: 0.8003\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3145 - acc: 0.8452 - val_loss: 0.5757 - val_acc: 0.8016\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3145 - acc: 0.8455 - val_loss: 0.5780 - val_acc: 0.8003\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3142 - acc: 0.8445 - val_loss: 0.5774 - val_acc: 0.8003\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3140 - acc: 0.8459 - val_loss: 0.5806 - val_acc: 0.8016\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3136 - acc: 0.8452 - val_loss: 0.5781 - val_acc: 0.8003\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3134 - acc: 0.8459 - val_loss: 0.5809 - val_acc: 0.8003\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3134 - acc: 0.8449 - val_loss: 0.5799 - val_acc: 0.7989\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3128 - acc: 0.8452 - val_loss: 0.5815 - val_acc: 0.8016\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3128 - acc: 0.8462 - val_loss: 0.5805 - val_acc: 0.7989\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 1ms/step - loss: 0.3127 - acc: 0.8449 - val_loss: 0.5830 - val_acc: 0.7975\n"
     ]
    }
   ],
   "source": [
    "hist_fnn = fnn.fit(Xs_train,y_train_nn,batch_size=72,epochs=100,\n",
    "                   validation_data=(Xs_test,y_test_nn),shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "nNpRPZ_7vZbu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:37.327684Z",
     "iopub.status.busy": "2021-08-27T04:05:37.327542Z",
     "iopub.status.idle": "2021-08-27T04:05:37.430981Z",
     "shell.execute_reply": "2021-08-27T04:05:37.430358Z",
     "shell.execute_reply.started": "2021-08-27T04:05:37.327668Z"
    },
    "id": "nNpRPZ_7vZbu",
    "outputId": "0df0579a-5578-4a03-8c43-268de300e67f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc(hist_fnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "628c06a7-9e6b-4683-b322-16e65a86a502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:58:47.570440Z",
     "iopub.status.busy": "2021-08-27T11:58:47.570252Z",
     "iopub.status.idle": "2021-08-27T11:58:58.181805Z",
     "shell.execute_reply": "2021-08-27T11:58:58.181164Z",
     "shell.execute_reply.started": "2021-08-27T11:58:47.570423Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_210\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_631 (Dense)            (None, 128)               1408      \n",
      "_________________________________________________________________\n",
      "dense_632 (Dense)            (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "dense_633 (Dense)            (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 5,371\n",
      "Trainable params: 5,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/41 [==============================] - 0s 4ms/step - loss: 0.8381 - acc: 0.6298 - val_loss: 0.5644 - val_acc: 0.7428\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4899 - acc: 0.8007 - val_loss: 0.4759 - val_acc: 0.7661\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.4040 - acc: 0.8209 - val_loss: 0.4894 - val_acc: 0.7907\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3789 - acc: 0.8233 - val_loss: 0.5092 - val_acc: 0.7921\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3697 - acc: 0.8253 - val_loss: 0.5220 - val_acc: 0.7907\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3644 - acc: 0.8264 - val_loss: 0.5297 - val_acc: 0.7893\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3609 - acc: 0.8267 - val_loss: 0.5345 - val_acc: 0.7880\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3582 - acc: 0.8267 - val_loss: 0.5372 - val_acc: 0.7893\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3557 - acc: 0.8284 - val_loss: 0.5385 - val_acc: 0.7907\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3537 - acc: 0.8284 - val_loss: 0.5393 - val_acc: 0.7948\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3522 - acc: 0.8288 - val_loss: 0.5407 - val_acc: 0.7948\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3506 - acc: 0.8288 - val_loss: 0.5410 - val_acc: 0.7948\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3493 - acc: 0.8284 - val_loss: 0.5411 - val_acc: 0.7934\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3483 - acc: 0.8284 - val_loss: 0.5418 - val_acc: 0.7934\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3470 - acc: 0.8291 - val_loss: 0.5414 - val_acc: 0.7921\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3460 - acc: 0.8288 - val_loss: 0.5415 - val_acc: 0.7948\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3448 - acc: 0.8291 - val_loss: 0.5415 - val_acc: 0.7934\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3440 - acc: 0.8281 - val_loss: 0.5418 - val_acc: 0.7934\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3430 - acc: 0.8281 - val_loss: 0.5419 - val_acc: 0.7921\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3423 - acc: 0.8284 - val_loss: 0.5423 - val_acc: 0.7921\n",
      "Epoch 21/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3418 - acc: 0.8284 - val_loss: 0.5429 - val_acc: 0.7921\n",
      "Epoch 22/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3408 - acc: 0.8288 - val_loss: 0.5426 - val_acc: 0.7934\n",
      "Epoch 23/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3402 - acc: 0.8291 - val_loss: 0.5431 - val_acc: 0.7934\n",
      "Epoch 24/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3394 - acc: 0.8291 - val_loss: 0.5432 - val_acc: 0.7934\n",
      "Epoch 25/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3390 - acc: 0.8295 - val_loss: 0.5434 - val_acc: 0.7934\n",
      "Epoch 26/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3382 - acc: 0.8301 - val_loss: 0.5439 - val_acc: 0.7934\n",
      "Epoch 27/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3377 - acc: 0.8308 - val_loss: 0.5441 - val_acc: 0.7934\n",
      "Epoch 28/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3372 - acc: 0.8308 - val_loss: 0.5440 - val_acc: 0.7934\n",
      "Epoch 29/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3366 - acc: 0.8312 - val_loss: 0.5440 - val_acc: 0.7934\n",
      "Epoch 30/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3361 - acc: 0.8308 - val_loss: 0.5444 - val_acc: 0.7934\n",
      "Epoch 31/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3356 - acc: 0.8312 - val_loss: 0.5447 - val_acc: 0.7934\n",
      "Epoch 32/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3352 - acc: 0.8301 - val_loss: 0.5450 - val_acc: 0.7934\n",
      "Epoch 33/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3347 - acc: 0.8312 - val_loss: 0.5452 - val_acc: 0.7921\n",
      "Epoch 34/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3344 - acc: 0.8312 - val_loss: 0.5454 - val_acc: 0.7934\n",
      "Epoch 35/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3342 - acc: 0.8315 - val_loss: 0.5465 - val_acc: 0.7934\n",
      "Epoch 36/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3336 - acc: 0.8318 - val_loss: 0.5465 - val_acc: 0.7934\n",
      "Epoch 37/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3332 - acc: 0.8329 - val_loss: 0.5474 - val_acc: 0.7934\n",
      "Epoch 38/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3328 - acc: 0.8329 - val_loss: 0.5476 - val_acc: 0.7921\n",
      "Epoch 39/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3326 - acc: 0.8325 - val_loss: 0.5476 - val_acc: 0.7921\n",
      "Epoch 40/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3320 - acc: 0.8336 - val_loss: 0.5481 - val_acc: 0.7921\n",
      "Epoch 41/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3319 - acc: 0.8342 - val_loss: 0.5483 - val_acc: 0.7934\n",
      "Epoch 42/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3315 - acc: 0.8346 - val_loss: 0.5493 - val_acc: 0.7921\n",
      "Epoch 43/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3311 - acc: 0.8346 - val_loss: 0.5498 - val_acc: 0.7934\n",
      "Epoch 44/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3310 - acc: 0.8356 - val_loss: 0.5496 - val_acc: 0.7934\n",
      "Epoch 45/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3305 - acc: 0.8360 - val_loss: 0.5501 - val_acc: 0.7934\n",
      "Epoch 46/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3303 - acc: 0.8363 - val_loss: 0.5506 - val_acc: 0.7948\n",
      "Epoch 47/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3300 - acc: 0.8363 - val_loss: 0.5507 - val_acc: 0.7948\n",
      "Epoch 48/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3299 - acc: 0.8370 - val_loss: 0.5509 - val_acc: 0.7948\n",
      "Epoch 49/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3295 - acc: 0.8377 - val_loss: 0.5518 - val_acc: 0.7948\n",
      "Epoch 50/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3294 - acc: 0.8377 - val_loss: 0.5515 - val_acc: 0.7934\n",
      "Epoch 51/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3291 - acc: 0.8380 - val_loss: 0.5520 - val_acc: 0.7948\n",
      "Epoch 52/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3287 - acc: 0.8380 - val_loss: 0.5528 - val_acc: 0.7948\n",
      "Epoch 53/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3285 - acc: 0.8387 - val_loss: 0.5532 - val_acc: 0.7948\n",
      "Epoch 54/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3284 - acc: 0.8380 - val_loss: 0.5527 - val_acc: 0.7934\n",
      "Epoch 55/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3283 - acc: 0.8384 - val_loss: 0.5534 - val_acc: 0.7934\n",
      "Epoch 56/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3279 - acc: 0.8380 - val_loss: 0.5535 - val_acc: 0.7934\n",
      "Epoch 57/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3276 - acc: 0.8373 - val_loss: 0.5530 - val_acc: 0.7948\n",
      "Epoch 58/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3275 - acc: 0.8377 - val_loss: 0.5538 - val_acc: 0.7948\n",
      "Epoch 59/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3273 - acc: 0.8370 - val_loss: 0.5533 - val_acc: 0.7962\n",
      "Epoch 60/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3270 - acc: 0.8370 - val_loss: 0.5534 - val_acc: 0.7962\n",
      "Epoch 61/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3271 - acc: 0.8373 - val_loss: 0.5547 - val_acc: 0.7962\n",
      "Epoch 62/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3268 - acc: 0.8366 - val_loss: 0.5543 - val_acc: 0.7962\n",
      "Epoch 63/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3265 - acc: 0.8370 - val_loss: 0.5542 - val_acc: 0.7962\n",
      "Epoch 64/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3263 - acc: 0.8373 - val_loss: 0.5536 - val_acc: 0.7962\n",
      "Epoch 65/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3261 - acc: 0.8366 - val_loss: 0.5541 - val_acc: 0.7962\n",
      "Epoch 66/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3258 - acc: 0.8373 - val_loss: 0.5537 - val_acc: 0.7962\n",
      "Epoch 67/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3257 - acc: 0.8363 - val_loss: 0.5546 - val_acc: 0.7962\n",
      "Epoch 68/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3255 - acc: 0.8370 - val_loss: 0.5540 - val_acc: 0.7975\n",
      "Epoch 69/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3253 - acc: 0.8366 - val_loss: 0.5547 - val_acc: 0.7975\n",
      "Epoch 70/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3251 - acc: 0.8377 - val_loss: 0.5552 - val_acc: 0.7975\n",
      "Epoch 71/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3249 - acc: 0.8377 - val_loss: 0.5547 - val_acc: 0.7975\n",
      "Epoch 72/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3246 - acc: 0.8373 - val_loss: 0.5549 - val_acc: 0.7975\n",
      "Epoch 73/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3249 - acc: 0.8380 - val_loss: 0.5563 - val_acc: 0.7975\n",
      "Epoch 74/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3242 - acc: 0.8377 - val_loss: 0.5559 - val_acc: 0.7975\n",
      "Epoch 75/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3242 - acc: 0.8377 - val_loss: 0.5561 - val_acc: 0.7975\n",
      "Epoch 76/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3239 - acc: 0.8373 - val_loss: 0.5558 - val_acc: 0.7975\n",
      "Epoch 77/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3238 - acc: 0.8366 - val_loss: 0.5564 - val_acc: 0.7975\n",
      "Epoch 78/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3236 - acc: 0.8373 - val_loss: 0.5564 - val_acc: 0.7989\n",
      "Epoch 79/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3234 - acc: 0.8377 - val_loss: 0.5571 - val_acc: 0.7975\n",
      "Epoch 80/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3233 - acc: 0.8373 - val_loss: 0.5570 - val_acc: 0.7989\n",
      "Epoch 81/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3230 - acc: 0.8366 - val_loss: 0.5572 - val_acc: 0.7989\n",
      "Epoch 82/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3229 - acc: 0.8370 - val_loss: 0.5574 - val_acc: 0.7989\n",
      "Epoch 83/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3229 - acc: 0.8370 - val_loss: 0.5579 - val_acc: 0.7989\n",
      "Epoch 84/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3225 - acc: 0.8370 - val_loss: 0.5572 - val_acc: 0.8003\n",
      "Epoch 85/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3225 - acc: 0.8377 - val_loss: 0.5580 - val_acc: 0.8003\n",
      "Epoch 86/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3222 - acc: 0.8387 - val_loss: 0.5577 - val_acc: 0.8003\n",
      "Epoch 87/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3221 - acc: 0.8377 - val_loss: 0.5579 - val_acc: 0.8016\n",
      "Epoch 88/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3221 - acc: 0.8373 - val_loss: 0.5587 - val_acc: 0.8016\n",
      "Epoch 89/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3216 - acc: 0.8373 - val_loss: 0.5588 - val_acc: 0.8016\n",
      "Epoch 90/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3216 - acc: 0.8387 - val_loss: 0.5591 - val_acc: 0.8016\n",
      "Epoch 91/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3215 - acc: 0.8390 - val_loss: 0.5592 - val_acc: 0.8016\n",
      "Epoch 92/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3213 - acc: 0.8373 - val_loss: 0.5590 - val_acc: 0.8016\n",
      "Epoch 93/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3212 - acc: 0.8384 - val_loss: 0.5597 - val_acc: 0.8016\n",
      "Epoch 94/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3209 - acc: 0.8387 - val_loss: 0.5594 - val_acc: 0.8016\n",
      "Epoch 95/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3207 - acc: 0.8387 - val_loss: 0.5594 - val_acc: 0.8016\n",
      "Epoch 96/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3206 - acc: 0.8390 - val_loss: 0.5600 - val_acc: 0.8016\n",
      "Epoch 97/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3204 - acc: 0.8380 - val_loss: 0.5596 - val_acc: 0.8016\n",
      "Epoch 98/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3204 - acc: 0.8394 - val_loss: 0.5601 - val_acc: 0.8016\n",
      "Epoch 99/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3201 - acc: 0.8397 - val_loss: 0.5599 - val_acc: 0.8016\n",
      "Epoch 100/100\n",
      "41/41 [==============================] - 0s 2ms/step - loss: 0.3200 - acc: 0.8390 - val_loss: 0.5601 - val_acc: 0.8016\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model network \n",
    "fnn1 = Sequential()\n",
    "fnn1.add(Dense(128,activation=\"relu\", input_shape=(10,)))\n",
    "fnn1.add(Dense(30, activation=\"relu\"))\n",
    "fnn1.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "# compile model \n",
    "fnn1.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "# check model \n",
    "fnn1.summary()\n",
    "\n",
    "hist_fnn1 = fnn1.fit(Xs_train,y_train_nn,batch_size=72,epochs=100,\n",
    "                   validation_data=(Xs_test,y_test_nn),shuffle=False,)\n",
    "\n",
    "plot_acc(hist_fnn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9244ab1d-69be-457f-a945-3b94a917a6fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:11:08.558867Z",
     "iopub.status.busy": "2021-08-27T11:11:08.558667Z",
     "iopub.status.idle": "2021-08-27T11:11:08.562178Z",
     "shell.execute_reply": "2021-08-27T11:11:08.561550Z",
     "shell.execute_reply.started": "2021-08-27T11:11:08.558849Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "579f58cf-41e2-40b9-a47a-b4d71a4248c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T11:20:13.065686Z",
     "iopub.status.busy": "2021-08-27T11:20:13.065488Z",
     "iopub.status.idle": "2021-08-27T11:20:13.069515Z",
     "shell.execute_reply": "2021-08-27T11:20:13.068798Z",
     "shell.execute_reply.started": "2021-08-27T11:20:13.065669Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_confusion_matrix(fnn,Xs_test,y_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6f592c46-c3ed-4d89-9174-baf10edb5268",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:37.431813Z",
     "iopub.status.busy": "2021-08-27T04:05:37.431675Z",
     "iopub.status.idle": "2021-08-27T04:05:37.435076Z",
     "shell.execute_reply": "2021-08-27T04:05:37.434369Z",
     "shell.execute_reply.started": "2021-08-27T04:05:37.431797Z"
    },
    "id": "6f592c46-c3ed-4d89-9174-baf10edb5268"
   },
   "outputs": [],
   "source": [
    "# check results\n",
    "#get_acc(fnn,vars_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c216e82-d869-4281-85a6-02474e4f9d52",
   "metadata": {
    "id": "6c216e82-d869-4281-85a6-02474e4f9d52"
   },
   "source": [
    "## RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ccb52618-eb12-4967-9dc9-9810cf22573f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:37.436166Z",
     "iopub.status.busy": "2021-08-27T04:05:37.435985Z",
     "iopub.status.idle": "2021-08-27T04:05:37.440100Z",
     "shell.execute_reply": "2021-08-27T04:05:37.439386Z",
     "shell.execute_reply.started": "2021-08-27T04:05:37.436149Z"
    },
    "id": "ccb52618-eb12-4967-9dc9-9810cf22573f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create training sequences\n",
    "train_sequences = TimeseriesGenerator(Xs_train, y_train_nn, length=1,batch_size=64)\n",
    "\n",
    "# Create Test Sequences\n",
    "test_sequences = TimeseriesGenerator(Xs_test, y_test_nn, length=1,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aa5cffbe-a6db-4e2a-b41b-91c98fea6608",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:37.441020Z",
     "iopub.status.busy": "2021-08-27T04:05:37.440862Z",
     "iopub.status.idle": "2021-08-27T04:05:37.446987Z",
     "shell.execute_reply": "2021-08-27T04:05:37.446365Z",
     "shell.execute_reply.started": "2021-08-27T04:05:37.441004Z"
    },
    "id": "aa5cffbe-a6db-4e2a-b41b-91c98fea6608",
    "outputId": "79488f5f-48f6-4d1e-d033-d9c9a4ba8a1f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1, 10)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences[0][0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8fd5980b-fd57-41f4-9952-b0423cc5f064",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:37.447829Z",
     "iopub.status.busy": "2021-08-27T04:05:37.447685Z",
     "iopub.status.idle": "2021-08-27T04:05:37.453048Z",
     "shell.execute_reply": "2021-08-27T04:05:37.452377Z",
     "shell.execute_reply.started": "2021-08-27T04:05:37.447813Z"
    },
    "id": "8fd5980b-fd57-41f4-9952-b0423cc5f064",
    "outputId": "721094bf-14ce-48f0-9eef-ad961752eb5f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sequences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c9d73e2-6b89-4b4a-8781-a548547996c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:37.453828Z",
     "iopub.status.busy": "2021-08-27T04:05:37.453702Z",
     "iopub.status.idle": "2021-08-27T04:05:37.458079Z",
     "shell.execute_reply": "2021-08-27T04:05:37.457411Z",
     "shell.execute_reply.started": "2021-08-27T04:05:37.453812Z"
    },
    "id": "3c9d73e2-6b89-4b4a-8781-a548547996c3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = train_sequences[0][0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f82371f-a0aa-4f9d-aacb-8c9621e9a0a4",
   "metadata": {
    "id": "2f82371f-a0aa-4f9d-aacb-8c9621e9a0a4"
   },
   "source": [
    "### rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "657b80f0-5c1b-4f19-8fc2-63dbacfdd723",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:37.458854Z",
     "iopub.status.busy": "2021-08-27T04:05:37.458710Z",
     "iopub.status.idle": "2021-08-27T04:05:37.727118Z",
     "shell.execute_reply": "2021-08-27T04:05:37.726444Z",
     "shell.execute_reply.started": "2021-08-27T04:05:37.458821Z"
    },
    "id": "657b80f0-5c1b-4f19-8fc2-63dbacfdd723",
    "outputId": "b952b210-aba7-456b-f060-96921a17e615",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 1, 8)              480       \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 8)                 432       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,035\n",
      "Trainable params: 1,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model network \n",
    "\n",
    "rnn = Sequential()\n",
    "rnn.add(GRU(8,input_shape=input_shape, return_sequences=True))\n",
    "rnn.add(GRU(8,return_sequences=False)) # false if next layer dense\n",
    "rnn.add(Dense(10,activation='relu'))\n",
    "rnn.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# compile model \n",
    "rnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "# show summary \n",
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cbe27934-5a53-4512-8182-4606f28144d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:37.728016Z",
     "iopub.status.busy": "2021-08-27T04:05:37.727885Z",
     "iopub.status.idle": "2021-08-27T04:05:50.046454Z",
     "shell.execute_reply": "2021-08-27T04:05:50.045969Z",
     "shell.execute_reply.started": "2021-08-27T04:05:37.728001Z"
    },
    "id": "cbe27934-5a53-4512-8182-4606f28144d5",
    "outputId": "bef836b9-966d-4287-d3f0-92b47f261801",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "46/46 - 3s - loss: 1.0822 - acc: 0.4121 - val_loss: 1.0584 - val_acc: 0.4753\n",
      "Epoch 2/50\n",
      "46/46 - 0s - loss: 1.0352 - acc: 0.4443 - val_loss: 0.9981 - val_acc: 0.5055\n",
      "Epoch 3/50\n",
      "46/46 - 0s - loss: 0.9601 - acc: 0.4539 - val_loss: 0.9059 - val_acc: 0.5781\n",
      "Epoch 4/50\n",
      "46/46 - 0s - loss: 0.8555 - acc: 0.5844 - val_loss: 0.7930 - val_acc: 0.6384\n",
      "Epoch 5/50\n",
      "46/46 - 0s - loss: 0.7604 - acc: 0.5999 - val_loss: 0.7167 - val_acc: 0.6397\n",
      "Epoch 6/50\n",
      "46/46 - 0s - loss: 0.7049 - acc: 0.6002 - val_loss: 0.6814 - val_acc: 0.6397\n",
      "Epoch 7/50\n",
      "46/46 - 0s - loss: 0.6806 - acc: 0.5958 - val_loss: 0.6670 - val_acc: 0.6384\n",
      "Epoch 8/50\n",
      "46/46 - 0s - loss: 0.6700 - acc: 0.6009 - val_loss: 0.6580 - val_acc: 0.6438\n",
      "Epoch 9/50\n",
      "46/46 - 0s - loss: 0.6649 - acc: 0.6016 - val_loss: 0.6518 - val_acc: 0.6466\n",
      "Epoch 10/50\n",
      "46/46 - 0s - loss: 0.6611 - acc: 0.6047 - val_loss: 0.6503 - val_acc: 0.6466\n",
      "Epoch 11/50\n",
      "46/46 - 0s - loss: 0.6587 - acc: 0.6043 - val_loss: 0.6496 - val_acc: 0.6466\n",
      "Epoch 12/50\n",
      "46/46 - 0s - loss: 0.6566 - acc: 0.6043 - val_loss: 0.6480 - val_acc: 0.6452\n",
      "Epoch 13/50\n",
      "46/46 - 0s - loss: 0.6553 - acc: 0.6029 - val_loss: 0.6435 - val_acc: 0.6425\n",
      "Epoch 14/50\n",
      "46/46 - 0s - loss: 0.6540 - acc: 0.6036 - val_loss: 0.6459 - val_acc: 0.6507\n",
      "Epoch 15/50\n",
      "46/46 - 0s - loss: 0.6532 - acc: 0.6047 - val_loss: 0.6424 - val_acc: 0.6452\n",
      "Epoch 16/50\n",
      "46/46 - 0s - loss: 0.6519 - acc: 0.6043 - val_loss: 0.6439 - val_acc: 0.6452\n",
      "Epoch 17/50\n",
      "46/46 - 0s - loss: 0.6525 - acc: 0.6043 - val_loss: 0.6432 - val_acc: 0.6452\n",
      "Epoch 18/50\n",
      "46/46 - 0s - loss: 0.6507 - acc: 0.6040 - val_loss: 0.6422 - val_acc: 0.6466\n",
      "Epoch 19/50\n",
      "46/46 - 0s - loss: 0.6507 - acc: 0.6047 - val_loss: 0.6412 - val_acc: 0.6479\n",
      "Epoch 20/50\n",
      "46/46 - 0s - loss: 0.6512 - acc: 0.6043 - val_loss: 0.6421 - val_acc: 0.6479\n",
      "Epoch 21/50\n",
      "46/46 - 0s - loss: 0.6507 - acc: 0.6043 - val_loss: 0.6412 - val_acc: 0.6466\n",
      "Epoch 22/50\n",
      "46/46 - 0s - loss: 0.6500 - acc: 0.6043 - val_loss: 0.6420 - val_acc: 0.6438\n",
      "Epoch 23/50\n",
      "46/46 - 0s - loss: 0.6493 - acc: 0.6047 - val_loss: 0.6422 - val_acc: 0.6479\n",
      "Epoch 24/50\n",
      "46/46 - 0s - loss: 0.6493 - acc: 0.6036 - val_loss: 0.6407 - val_acc: 0.6479\n",
      "Epoch 25/50\n",
      "46/46 - 0s - loss: 0.6500 - acc: 0.6029 - val_loss: 0.6386 - val_acc: 0.6493\n",
      "Epoch 26/50\n",
      "46/46 - 0s - loss: 0.6485 - acc: 0.6040 - val_loss: 0.6389 - val_acc: 0.6452\n",
      "Epoch 27/50\n",
      "46/46 - 0s - loss: 0.6488 - acc: 0.6040 - val_loss: 0.6406 - val_acc: 0.6438\n",
      "Epoch 28/50\n",
      "46/46 - 0s - loss: 0.6484 - acc: 0.6043 - val_loss: 0.6391 - val_acc: 0.6452\n",
      "Epoch 29/50\n",
      "46/46 - 0s - loss: 0.6491 - acc: 0.6040 - val_loss: 0.6414 - val_acc: 0.6452\n",
      "Epoch 30/50\n",
      "46/46 - 0s - loss: 0.6475 - acc: 0.6026 - val_loss: 0.6404 - val_acc: 0.6452\n",
      "Epoch 31/50\n",
      "46/46 - 0s - loss: 0.6474 - acc: 0.6036 - val_loss: 0.6399 - val_acc: 0.6452\n",
      "Epoch 32/50\n",
      "46/46 - 0s - loss: 0.6488 - acc: 0.6047 - val_loss: 0.6413 - val_acc: 0.6466\n",
      "Epoch 33/50\n",
      "46/46 - 0s - loss: 0.6473 - acc: 0.6023 - val_loss: 0.6387 - val_acc: 0.6452\n",
      "Epoch 34/50\n",
      "46/46 - 0s - loss: 0.6471 - acc: 0.6047 - val_loss: 0.6391 - val_acc: 0.6397\n",
      "Epoch 35/50\n",
      "46/46 - 0s - loss: 0.6469 - acc: 0.6057 - val_loss: 0.6388 - val_acc: 0.6425\n",
      "Epoch 36/50\n",
      "46/46 - 0s - loss: 0.6468 - acc: 0.6047 - val_loss: 0.6376 - val_acc: 0.6479\n",
      "Epoch 37/50\n",
      "46/46 - 0s - loss: 0.6471 - acc: 0.6036 - val_loss: 0.6381 - val_acc: 0.6438\n",
      "Epoch 38/50\n",
      "46/46 - 0s - loss: 0.6466 - acc: 0.6040 - val_loss: 0.6411 - val_acc: 0.6438\n",
      "Epoch 39/50\n",
      "46/46 - 0s - loss: 0.6466 - acc: 0.6026 - val_loss: 0.6404 - val_acc: 0.6342\n",
      "Epoch 40/50\n",
      "46/46 - 0s - loss: 0.6470 - acc: 0.6040 - val_loss: 0.6397 - val_acc: 0.6438\n",
      "Epoch 41/50\n",
      "46/46 - 0s - loss: 0.6467 - acc: 0.6040 - val_loss: 0.6401 - val_acc: 0.6370\n",
      "Epoch 42/50\n",
      "46/46 - 0s - loss: 0.6458 - acc: 0.6053 - val_loss: 0.6402 - val_acc: 0.6452\n",
      "Epoch 43/50\n",
      "46/46 - 0s - loss: 0.6459 - acc: 0.6057 - val_loss: 0.6381 - val_acc: 0.6452\n",
      "Epoch 44/50\n",
      "46/46 - 0s - loss: 0.6454 - acc: 0.6050 - val_loss: 0.6408 - val_acc: 0.6425\n",
      "Epoch 45/50\n",
      "46/46 - 0s - loss: 0.6459 - acc: 0.6047 - val_loss: 0.6383 - val_acc: 0.6342\n",
      "Epoch 46/50\n",
      "46/46 - 0s - loss: 0.6465 - acc: 0.6036 - val_loss: 0.6414 - val_acc: 0.6425\n",
      "Epoch 47/50\n",
      "46/46 - 0s - loss: 0.6456 - acc: 0.6060 - val_loss: 0.6396 - val_acc: 0.6397\n",
      "Epoch 48/50\n",
      "46/46 - 0s - loss: 0.6464 - acc: 0.6043 - val_loss: 0.6437 - val_acc: 0.6329\n",
      "Epoch 49/50\n",
      "46/46 - 0s - loss: 0.6464 - acc: 0.6064 - val_loss: 0.6388 - val_acc: 0.6425\n",
      "Epoch 50/50\n",
      "46/46 - 0s - loss: 0.6459 - acc: 0.6053 - val_loss: 0.6394 - val_acc: 0.6438\n"
     ]
    }
   ],
   "source": [
    "hist_rnn = rnn.fit(train_sequences,validation_data=test_sequences,\n",
    "                  epochs=50,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "969fb11a-ffd7-41c4-adae-fdb12a919a51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:50.047590Z",
     "iopub.status.busy": "2021-08-27T04:05:50.047360Z",
     "iopub.status.idle": "2021-08-27T04:05:50.129362Z",
     "shell.execute_reply": "2021-08-27T04:05:50.128999Z",
     "shell.execute_reply.started": "2021-08-27T04:05:50.047572Z"
    },
    "id": "969fb11a-ffd7-41c4-adae-fdb12a919a51",
    "outputId": "e4bf05c7-3883-4e59-c4de-fe737016742d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc(hist_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2c167-6db2-4407-9fea-313cc8076630",
   "metadata": {
    "id": "b4d2c167-6db2-4407-9fea-313cc8076630"
   },
   "source": [
    "### rnn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48cab5d5-7f21-484a-8241-40eea57153f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:50.130261Z",
     "iopub.status.busy": "2021-08-27T04:05:50.130044Z",
     "iopub.status.idle": "2021-08-27T04:05:50.404379Z",
     "shell.execute_reply": "2021-08-27T04:05:50.404029Z",
     "shell.execute_reply.started": "2021-08-27T04:05:50.130245Z"
    },
    "id": "48cab5d5-7f21-484a-8241-40eea57153f6",
    "outputId": "382cbcbf-2b8f-4e96-c37f-d796cdebe24c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 1, 80)             22080     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 80)                38880     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                810       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 61,803\n",
      "Trainable params: 61,803\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model network \n",
    "\n",
    "rnn2 = Sequential()\n",
    "rnn2.add(GRU(80,input_shape=input_shape, return_sequences=True))\n",
    "rnn2.add(GRU(80,return_sequences=False)) # false if next layer dense\n",
    "rnn2.add(Dense(10,activation='relu'))\n",
    "rnn2.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# compile model \n",
    "rnn2.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "# show summary \n",
    "rnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d817104-81fa-426e-9d52-34021a162fbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:05:50.405228Z",
     "iopub.status.busy": "2021-08-27T04:05:50.405024Z",
     "iopub.status.idle": "2021-08-27T04:07:49.097697Z",
     "shell.execute_reply": "2021-08-27T04:07:49.096840Z",
     "shell.execute_reply.started": "2021-08-27T04:05:50.405210Z"
    },
    "id": "9d817104-81fa-426e-9d52-34021a162fbf",
    "outputId": "4aafa639-950d-4855-ad6a-9afbd16522c2",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "46/46 - 2s - loss: 0.9156 - acc: 0.4851 - val_loss: 0.7347 - val_acc: 0.5836\n",
      "Epoch 2/500\n",
      "46/46 - 0s - loss: 0.6882 - acc: 0.5762 - val_loss: 0.6596 - val_acc: 0.6370\n",
      "Epoch 3/500\n",
      "46/46 - 0s - loss: 0.6624 - acc: 0.6023 - val_loss: 0.6537 - val_acc: 0.6219\n",
      "Epoch 4/500\n",
      "46/46 - 0s - loss: 0.6583 - acc: 0.6009 - val_loss: 0.6496 - val_acc: 0.6370\n",
      "Epoch 5/500\n",
      "46/46 - 0s - loss: 0.6558 - acc: 0.6002 - val_loss: 0.6517 - val_acc: 0.6356\n",
      "Epoch 6/500\n",
      "46/46 - 0s - loss: 0.6545 - acc: 0.6002 - val_loss: 0.6479 - val_acc: 0.6288\n",
      "Epoch 7/500\n",
      "46/46 - 0s - loss: 0.6533 - acc: 0.6009 - val_loss: 0.6497 - val_acc: 0.6384\n",
      "Epoch 8/500\n",
      "46/46 - 0s - loss: 0.6547 - acc: 0.6047 - val_loss: 0.6522 - val_acc: 0.6370\n",
      "Epoch 9/500\n",
      "46/46 - 0s - loss: 0.6536 - acc: 0.6060 - val_loss: 0.6535 - val_acc: 0.6342\n",
      "Epoch 10/500\n",
      "46/46 - 0s - loss: 0.6534 - acc: 0.6040 - val_loss: 0.6513 - val_acc: 0.6274\n",
      "Epoch 11/500\n",
      "46/46 - 0s - loss: 0.6508 - acc: 0.6043 - val_loss: 0.6462 - val_acc: 0.6315\n",
      "Epoch 12/500\n",
      "46/46 - 0s - loss: 0.6509 - acc: 0.6023 - val_loss: 0.6559 - val_acc: 0.6274\n",
      "Epoch 13/500\n",
      "46/46 - 0s - loss: 0.6502 - acc: 0.6057 - val_loss: 0.6464 - val_acc: 0.6315\n",
      "Epoch 14/500\n",
      "46/46 - 0s - loss: 0.6488 - acc: 0.6009 - val_loss: 0.6444 - val_acc: 0.6329\n",
      "Epoch 15/500\n",
      "46/46 - 0s - loss: 0.6467 - acc: 0.6016 - val_loss: 0.6493 - val_acc: 0.6301\n",
      "Epoch 16/500\n",
      "46/46 - 0s - loss: 0.6458 - acc: 0.6029 - val_loss: 0.6416 - val_acc: 0.6342\n",
      "Epoch 17/500\n",
      "46/46 - 0s - loss: 0.6459 - acc: 0.6033 - val_loss: 0.6475 - val_acc: 0.6315\n",
      "Epoch 18/500\n",
      "46/46 - 0s - loss: 0.6446 - acc: 0.6033 - val_loss: 0.6437 - val_acc: 0.6329\n",
      "Epoch 19/500\n",
      "46/46 - 0s - loss: 0.6467 - acc: 0.6029 - val_loss: 0.6438 - val_acc: 0.6315\n",
      "Epoch 20/500\n",
      "46/46 - 0s - loss: 0.6449 - acc: 0.5968 - val_loss: 0.6451 - val_acc: 0.6356\n",
      "Epoch 21/500\n",
      "46/46 - 0s - loss: 0.6435 - acc: 0.6043 - val_loss: 0.6476 - val_acc: 0.6288\n",
      "Epoch 22/500\n",
      "46/46 - 0s - loss: 0.6434 - acc: 0.6064 - val_loss: 0.6440 - val_acc: 0.6274\n",
      "Epoch 23/500\n",
      "46/46 - 0s - loss: 0.6439 - acc: 0.6053 - val_loss: 0.6464 - val_acc: 0.6356\n",
      "Epoch 24/500\n",
      "46/46 - 0s - loss: 0.6424 - acc: 0.6088 - val_loss: 0.6424 - val_acc: 0.6356\n",
      "Epoch 25/500\n",
      "46/46 - 0s - loss: 0.6449 - acc: 0.6047 - val_loss: 0.6470 - val_acc: 0.6315\n",
      "Epoch 26/500\n",
      "46/46 - 0s - loss: 0.6428 - acc: 0.6081 - val_loss: 0.6501 - val_acc: 0.6233\n",
      "Epoch 27/500\n",
      "46/46 - 0s - loss: 0.6437 - acc: 0.6067 - val_loss: 0.6468 - val_acc: 0.6315\n",
      "Epoch 28/500\n",
      "46/46 - 0s - loss: 0.6419 - acc: 0.6108 - val_loss: 0.6478 - val_acc: 0.6356\n",
      "Epoch 29/500\n",
      "46/46 - 0s - loss: 0.6409 - acc: 0.6108 - val_loss: 0.6561 - val_acc: 0.6178\n",
      "Epoch 30/500\n",
      "46/46 - 0s - loss: 0.6438 - acc: 0.6091 - val_loss: 0.6524 - val_acc: 0.6301\n",
      "Epoch 31/500\n",
      "46/46 - 0s - loss: 0.6418 - acc: 0.6088 - val_loss: 0.6491 - val_acc: 0.6315\n",
      "Epoch 32/500\n",
      "46/46 - 0s - loss: 0.6404 - acc: 0.6122 - val_loss: 0.6490 - val_acc: 0.6370\n",
      "Epoch 33/500\n",
      "46/46 - 0s - loss: 0.6404 - acc: 0.6095 - val_loss: 0.6496 - val_acc: 0.6301\n",
      "Epoch 34/500\n",
      "46/46 - 0s - loss: 0.6407 - acc: 0.6115 - val_loss: 0.6493 - val_acc: 0.6301\n",
      "Epoch 35/500\n",
      "46/46 - 0s - loss: 0.6386 - acc: 0.6084 - val_loss: 0.6484 - val_acc: 0.6342\n",
      "Epoch 36/500\n",
      "46/46 - 0s - loss: 0.6419 - acc: 0.6064 - val_loss: 0.6489 - val_acc: 0.6315\n",
      "Epoch 37/500\n",
      "46/46 - 0s - loss: 0.6402 - acc: 0.6160 - val_loss: 0.6482 - val_acc: 0.6288\n",
      "Epoch 38/500\n",
      "46/46 - 0s - loss: 0.6401 - acc: 0.6115 - val_loss: 0.6535 - val_acc: 0.6301\n",
      "Epoch 39/500\n",
      "46/46 - 0s - loss: 0.6385 - acc: 0.6112 - val_loss: 0.6493 - val_acc: 0.6301\n",
      "Epoch 40/500\n",
      "46/46 - 0s - loss: 0.6389 - acc: 0.6125 - val_loss: 0.6543 - val_acc: 0.6288\n",
      "Epoch 41/500\n",
      "46/46 - 0s - loss: 0.6385 - acc: 0.6139 - val_loss: 0.6522 - val_acc: 0.6288\n",
      "Epoch 42/500\n",
      "46/46 - 0s - loss: 0.6377 - acc: 0.6170 - val_loss: 0.6515 - val_acc: 0.6288\n",
      "Epoch 43/500\n",
      "46/46 - 0s - loss: 0.6378 - acc: 0.6129 - val_loss: 0.6497 - val_acc: 0.6274\n",
      "Epoch 44/500\n",
      "46/46 - 0s - loss: 0.6376 - acc: 0.6112 - val_loss: 0.6552 - val_acc: 0.6123\n",
      "Epoch 45/500\n",
      "46/46 - 0s - loss: 0.6385 - acc: 0.6160 - val_loss: 0.6543 - val_acc: 0.6274\n",
      "Epoch 46/500\n",
      "46/46 - 0s - loss: 0.6372 - acc: 0.6112 - val_loss: 0.6580 - val_acc: 0.6137\n",
      "Epoch 47/500\n",
      "46/46 - 0s - loss: 0.6387 - acc: 0.6143 - val_loss: 0.6540 - val_acc: 0.6288\n",
      "Epoch 48/500\n",
      "46/46 - 0s - loss: 0.6384 - acc: 0.6184 - val_loss: 0.6520 - val_acc: 0.6192\n",
      "Epoch 49/500\n",
      "46/46 - 0s - loss: 0.6368 - acc: 0.6129 - val_loss: 0.6539 - val_acc: 0.6247\n",
      "Epoch 50/500\n",
      "46/46 - 0s - loss: 0.6360 - acc: 0.6163 - val_loss: 0.6617 - val_acc: 0.6205\n",
      "Epoch 51/500\n",
      "46/46 - 0s - loss: 0.6362 - acc: 0.6143 - val_loss: 0.6601 - val_acc: 0.6123\n",
      "Epoch 52/500\n",
      "46/46 - 0s - loss: 0.6359 - acc: 0.6170 - val_loss: 0.6611 - val_acc: 0.6164\n",
      "Epoch 53/500\n",
      "46/46 - 0s - loss: 0.6363 - acc: 0.6108 - val_loss: 0.6604 - val_acc: 0.6110\n",
      "Epoch 54/500\n",
      "46/46 - 0s - loss: 0.6372 - acc: 0.6146 - val_loss: 0.6564 - val_acc: 0.6219\n",
      "Epoch 55/500\n",
      "46/46 - 0s - loss: 0.6353 - acc: 0.6146 - val_loss: 0.6539 - val_acc: 0.6219\n",
      "Epoch 56/500\n",
      "46/46 - 0s - loss: 0.6353 - acc: 0.6125 - val_loss: 0.6571 - val_acc: 0.6301\n",
      "Epoch 57/500\n",
      "46/46 - 0s - loss: 0.6347 - acc: 0.6187 - val_loss: 0.6578 - val_acc: 0.6178\n",
      "Epoch 58/500\n",
      "46/46 - 0s - loss: 0.6363 - acc: 0.6146 - val_loss: 0.6631 - val_acc: 0.6164\n",
      "Epoch 59/500\n",
      "46/46 - 0s - loss: 0.6348 - acc: 0.6153 - val_loss: 0.6574 - val_acc: 0.6233\n",
      "Epoch 60/500\n",
      "46/46 - 0s - loss: 0.6357 - acc: 0.6136 - val_loss: 0.6625 - val_acc: 0.6247\n",
      "Epoch 61/500\n",
      "46/46 - 0s - loss: 0.6346 - acc: 0.6119 - val_loss: 0.6550 - val_acc: 0.6288\n",
      "Epoch 62/500\n",
      "46/46 - 0s - loss: 0.6347 - acc: 0.6149 - val_loss: 0.6569 - val_acc: 0.6178\n",
      "Epoch 63/500\n",
      "46/46 - 0s - loss: 0.6340 - acc: 0.6177 - val_loss: 0.6587 - val_acc: 0.6233\n",
      "Epoch 64/500\n",
      "46/46 - 0s - loss: 0.6354 - acc: 0.6166 - val_loss: 0.6596 - val_acc: 0.6260\n",
      "Epoch 65/500\n",
      "46/46 - 0s - loss: 0.6328 - acc: 0.6204 - val_loss: 0.6591 - val_acc: 0.6342\n",
      "Epoch 66/500\n",
      "46/46 - 0s - loss: 0.6366 - acc: 0.6160 - val_loss: 0.6607 - val_acc: 0.6260\n",
      "Epoch 67/500\n",
      "46/46 - 0s - loss: 0.6343 - acc: 0.6190 - val_loss: 0.6607 - val_acc: 0.6274\n",
      "Epoch 68/500\n",
      "46/46 - 0s - loss: 0.6346 - acc: 0.6088 - val_loss: 0.6635 - val_acc: 0.6260\n",
      "Epoch 69/500\n",
      "46/46 - 0s - loss: 0.6332 - acc: 0.6225 - val_loss: 0.6635 - val_acc: 0.6219\n",
      "Epoch 70/500\n",
      "46/46 - 0s - loss: 0.6337 - acc: 0.6177 - val_loss: 0.6625 - val_acc: 0.6205\n",
      "Epoch 71/500\n",
      "46/46 - 0s - loss: 0.6333 - acc: 0.6166 - val_loss: 0.6657 - val_acc: 0.6178\n",
      "Epoch 72/500\n",
      "46/46 - 0s - loss: 0.6341 - acc: 0.6149 - val_loss: 0.6608 - val_acc: 0.6205\n",
      "Epoch 73/500\n",
      "46/46 - 0s - loss: 0.6333 - acc: 0.6177 - val_loss: 0.6670 - val_acc: 0.6219\n",
      "Epoch 74/500\n",
      "46/46 - 0s - loss: 0.6331 - acc: 0.6160 - val_loss: 0.6668 - val_acc: 0.6151\n",
      "Epoch 75/500\n",
      "46/46 - 0s - loss: 0.6335 - acc: 0.6136 - val_loss: 0.6698 - val_acc: 0.6110\n",
      "Epoch 76/500\n",
      "46/46 - 0s - loss: 0.6359 - acc: 0.6194 - val_loss: 0.6633 - val_acc: 0.6315\n",
      "Epoch 77/500\n",
      "46/46 - 0s - loss: 0.6322 - acc: 0.6190 - val_loss: 0.6691 - val_acc: 0.6151\n",
      "Epoch 78/500\n",
      "46/46 - 0s - loss: 0.6332 - acc: 0.6163 - val_loss: 0.6659 - val_acc: 0.6274\n",
      "Epoch 79/500\n",
      "46/46 - 0s - loss: 0.6322 - acc: 0.6156 - val_loss: 0.6666 - val_acc: 0.6233\n",
      "Epoch 80/500\n",
      "46/46 - 0s - loss: 0.6330 - acc: 0.6190 - val_loss: 0.6679 - val_acc: 0.6274\n",
      "Epoch 81/500\n",
      "46/46 - 0s - loss: 0.6318 - acc: 0.6170 - val_loss: 0.6704 - val_acc: 0.6151\n",
      "Epoch 82/500\n",
      "46/46 - 0s - loss: 0.6318 - acc: 0.6208 - val_loss: 0.6707 - val_acc: 0.6041\n",
      "Epoch 83/500\n",
      "46/46 - 0s - loss: 0.6320 - acc: 0.6204 - val_loss: 0.6690 - val_acc: 0.6151\n",
      "Epoch 84/500\n",
      "46/46 - 0s - loss: 0.6326 - acc: 0.6204 - val_loss: 0.6695 - val_acc: 0.6082\n",
      "Epoch 85/500\n",
      "46/46 - 0s - loss: 0.6314 - acc: 0.6143 - val_loss: 0.6688 - val_acc: 0.6151\n",
      "Epoch 86/500\n",
      "46/46 - 0s - loss: 0.6311 - acc: 0.6197 - val_loss: 0.6699 - val_acc: 0.6260\n",
      "Epoch 87/500\n",
      "46/46 - 0s - loss: 0.6314 - acc: 0.6194 - val_loss: 0.6767 - val_acc: 0.6014\n",
      "Epoch 88/500\n",
      "46/46 - 0s - loss: 0.6312 - acc: 0.6139 - val_loss: 0.6689 - val_acc: 0.6274\n",
      "Epoch 89/500\n",
      "46/46 - 0s - loss: 0.6317 - acc: 0.6146 - val_loss: 0.6689 - val_acc: 0.6274\n",
      "Epoch 90/500\n",
      "46/46 - 0s - loss: 0.6309 - acc: 0.6180 - val_loss: 0.6755 - val_acc: 0.6137\n",
      "Epoch 91/500\n",
      "46/46 - 0s - loss: 0.6309 - acc: 0.6184 - val_loss: 0.6741 - val_acc: 0.6137\n",
      "Epoch 92/500\n",
      "46/46 - 0s - loss: 0.6309 - acc: 0.6197 - val_loss: 0.6723 - val_acc: 0.6219\n",
      "Epoch 93/500\n",
      "46/46 - 0s - loss: 0.6305 - acc: 0.6201 - val_loss: 0.6721 - val_acc: 0.6192\n",
      "Epoch 94/500\n",
      "46/46 - 0s - loss: 0.6302 - acc: 0.6197 - val_loss: 0.6716 - val_acc: 0.6110\n",
      "Epoch 95/500\n",
      "46/46 - 0s - loss: 0.6298 - acc: 0.6194 - val_loss: 0.6722 - val_acc: 0.6233\n",
      "Epoch 96/500\n",
      "46/46 - 0s - loss: 0.6314 - acc: 0.6163 - val_loss: 0.6760 - val_acc: 0.6027\n",
      "Epoch 97/500\n",
      "46/46 - 0s - loss: 0.6295 - acc: 0.6173 - val_loss: 0.6707 - val_acc: 0.6192\n",
      "Epoch 98/500\n",
      "46/46 - 0s - loss: 0.6307 - acc: 0.6184 - val_loss: 0.6718 - val_acc: 0.6233\n",
      "Epoch 99/500\n",
      "46/46 - 0s - loss: 0.6305 - acc: 0.6177 - val_loss: 0.6784 - val_acc: 0.6151\n",
      "Epoch 100/500\n",
      "46/46 - 0s - loss: 0.6287 - acc: 0.6180 - val_loss: 0.6724 - val_acc: 0.6274\n",
      "Epoch 101/500\n",
      "46/46 - 0s - loss: 0.6291 - acc: 0.6249 - val_loss: 0.6768 - val_acc: 0.6055\n",
      "Epoch 102/500\n",
      "46/46 - 0s - loss: 0.6293 - acc: 0.6238 - val_loss: 0.6822 - val_acc: 0.6068\n",
      "Epoch 103/500\n",
      "46/46 - 0s - loss: 0.6287 - acc: 0.6184 - val_loss: 0.6764 - val_acc: 0.6110\n",
      "Epoch 104/500\n",
      "46/46 - 0s - loss: 0.6279 - acc: 0.6228 - val_loss: 0.6788 - val_acc: 0.6192\n",
      "Epoch 105/500\n",
      "46/46 - 0s - loss: 0.6289 - acc: 0.6204 - val_loss: 0.6820 - val_acc: 0.6000\n",
      "Epoch 106/500\n",
      "46/46 - 0s - loss: 0.6292 - acc: 0.6218 - val_loss: 0.6831 - val_acc: 0.6082\n",
      "Epoch 107/500\n",
      "46/46 - 0s - loss: 0.6269 - acc: 0.6238 - val_loss: 0.6859 - val_acc: 0.6027\n",
      "Epoch 108/500\n",
      "46/46 - 0s - loss: 0.6273 - acc: 0.6204 - val_loss: 0.6809 - val_acc: 0.6205\n",
      "Epoch 109/500\n",
      "46/46 - 0s - loss: 0.6273 - acc: 0.6238 - val_loss: 0.6788 - val_acc: 0.6260\n",
      "Epoch 110/500\n",
      "46/46 - 0s - loss: 0.6278 - acc: 0.6225 - val_loss: 0.6831 - val_acc: 0.6110\n",
      "Epoch 111/500\n",
      "46/46 - 0s - loss: 0.6280 - acc: 0.6194 - val_loss: 0.6845 - val_acc: 0.6027\n",
      "Epoch 112/500\n",
      "46/46 - 0s - loss: 0.6263 - acc: 0.6218 - val_loss: 0.6810 - val_acc: 0.6137\n",
      "Epoch 113/500\n",
      "46/46 - 0s - loss: 0.6272 - acc: 0.6259 - val_loss: 0.6861 - val_acc: 0.5986\n",
      "Epoch 114/500\n",
      "46/46 - 0s - loss: 0.6260 - acc: 0.6242 - val_loss: 0.6812 - val_acc: 0.6123\n",
      "Epoch 115/500\n",
      "46/46 - 0s - loss: 0.6276 - acc: 0.6153 - val_loss: 0.6789 - val_acc: 0.6301\n",
      "Epoch 116/500\n",
      "46/46 - 0s - loss: 0.6259 - acc: 0.6214 - val_loss: 0.6813 - val_acc: 0.6192\n",
      "Epoch 117/500\n",
      "46/46 - 0s - loss: 0.6254 - acc: 0.6276 - val_loss: 0.6866 - val_acc: 0.6151\n",
      "Epoch 118/500\n",
      "46/46 - 0s - loss: 0.6260 - acc: 0.6225 - val_loss: 0.6975 - val_acc: 0.5877\n",
      "Epoch 119/500\n",
      "46/46 - 0s - loss: 0.6257 - acc: 0.6280 - val_loss: 0.6864 - val_acc: 0.6027\n",
      "Epoch 120/500\n",
      "46/46 - 0s - loss: 0.6252 - acc: 0.6252 - val_loss: 0.6903 - val_acc: 0.6068\n",
      "Epoch 121/500\n",
      "46/46 - 0s - loss: 0.6240 - acc: 0.6214 - val_loss: 0.6874 - val_acc: 0.6192\n",
      "Epoch 122/500\n",
      "46/46 - 0s - loss: 0.6254 - acc: 0.6194 - val_loss: 0.6905 - val_acc: 0.5986\n",
      "Epoch 123/500\n",
      "46/46 - 0s - loss: 0.6262 - acc: 0.6201 - val_loss: 0.6877 - val_acc: 0.6233\n",
      "Epoch 124/500\n",
      "46/46 - 0s - loss: 0.6241 - acc: 0.6208 - val_loss: 0.6922 - val_acc: 0.6219\n",
      "Epoch 125/500\n",
      "46/46 - 0s - loss: 0.6230 - acc: 0.6307 - val_loss: 0.6930 - val_acc: 0.5986\n",
      "Epoch 126/500\n",
      "46/46 - 0s - loss: 0.6249 - acc: 0.6194 - val_loss: 0.6977 - val_acc: 0.5932\n",
      "Epoch 127/500\n",
      "46/46 - 0s - loss: 0.6249 - acc: 0.6184 - val_loss: 0.6928 - val_acc: 0.5973\n",
      "Epoch 128/500\n",
      "46/46 - 0s - loss: 0.6231 - acc: 0.6280 - val_loss: 0.6946 - val_acc: 0.6164\n",
      "Epoch 129/500\n",
      "46/46 - 0s - loss: 0.6234 - acc: 0.6214 - val_loss: 0.6993 - val_acc: 0.6055\n",
      "Epoch 130/500\n",
      "46/46 - 0s - loss: 0.6233 - acc: 0.6232 - val_loss: 0.6933 - val_acc: 0.6110\n",
      "Epoch 131/500\n",
      "46/46 - 0s - loss: 0.6235 - acc: 0.6204 - val_loss: 0.6953 - val_acc: 0.6219\n",
      "Epoch 132/500\n",
      "46/46 - 0s - loss: 0.6223 - acc: 0.6197 - val_loss: 0.6957 - val_acc: 0.6137\n",
      "Epoch 133/500\n",
      "46/46 - 0s - loss: 0.6225 - acc: 0.6245 - val_loss: 0.6921 - val_acc: 0.6205\n",
      "Epoch 134/500\n",
      "46/46 - 0s - loss: 0.6231 - acc: 0.6238 - val_loss: 0.6996 - val_acc: 0.6000\n",
      "Epoch 135/500\n",
      "46/46 - 0s - loss: 0.6222 - acc: 0.6184 - val_loss: 0.6952 - val_acc: 0.6247\n",
      "Epoch 136/500\n",
      "46/46 - 0s - loss: 0.6228 - acc: 0.6232 - val_loss: 0.6902 - val_acc: 0.6137\n",
      "Epoch 137/500\n",
      "46/46 - 0s - loss: 0.6234 - acc: 0.6228 - val_loss: 0.7013 - val_acc: 0.6233\n",
      "Epoch 138/500\n",
      "46/46 - 0s - loss: 0.6215 - acc: 0.6280 - val_loss: 0.7018 - val_acc: 0.6014\n",
      "Epoch 139/500\n",
      "46/46 - 0s - loss: 0.6213 - acc: 0.6266 - val_loss: 0.7003 - val_acc: 0.6219\n",
      "Epoch 140/500\n",
      "46/46 - 0s - loss: 0.6210 - acc: 0.6300 - val_loss: 0.7035 - val_acc: 0.6233\n",
      "Epoch 141/500\n",
      "46/46 - 0s - loss: 0.6222 - acc: 0.6262 - val_loss: 0.7053 - val_acc: 0.6164\n",
      "Epoch 142/500\n",
      "46/46 - 0s - loss: 0.6201 - acc: 0.6310 - val_loss: 0.6972 - val_acc: 0.6110\n",
      "Epoch 143/500\n",
      "46/46 - 0s - loss: 0.6209 - acc: 0.6221 - val_loss: 0.7057 - val_acc: 0.6151\n",
      "Epoch 144/500\n",
      "46/46 - 0s - loss: 0.6202 - acc: 0.6269 - val_loss: 0.7069 - val_acc: 0.6137\n",
      "Epoch 145/500\n",
      "46/46 - 0s - loss: 0.6205 - acc: 0.6259 - val_loss: 0.7078 - val_acc: 0.6110\n",
      "Epoch 146/500\n",
      "46/46 - 0s - loss: 0.6204 - acc: 0.6211 - val_loss: 0.7088 - val_acc: 0.6041\n",
      "Epoch 147/500\n",
      "46/46 - 0s - loss: 0.6196 - acc: 0.6228 - val_loss: 0.7093 - val_acc: 0.6014\n",
      "Epoch 148/500\n",
      "46/46 - 0s - loss: 0.6206 - acc: 0.6221 - val_loss: 0.7123 - val_acc: 0.6205\n",
      "Epoch 149/500\n",
      "46/46 - 0s - loss: 0.6196 - acc: 0.6280 - val_loss: 0.7060 - val_acc: 0.6137\n",
      "Epoch 150/500\n",
      "46/46 - 0s - loss: 0.6198 - acc: 0.6252 - val_loss: 0.7130 - val_acc: 0.6178\n",
      "Epoch 151/500\n",
      "46/46 - 0s - loss: 0.6186 - acc: 0.6341 - val_loss: 0.7151 - val_acc: 0.6178\n",
      "Epoch 152/500\n",
      "46/46 - 0s - loss: 0.6197 - acc: 0.6228 - val_loss: 0.7106 - val_acc: 0.6151\n",
      "Epoch 153/500\n",
      "46/46 - 0s - loss: 0.6197 - acc: 0.6221 - val_loss: 0.7113 - val_acc: 0.6137\n",
      "Epoch 154/500\n",
      "46/46 - 0s - loss: 0.6175 - acc: 0.6262 - val_loss: 0.7139 - val_acc: 0.6233\n",
      "Epoch 155/500\n",
      "46/46 - 0s - loss: 0.6180 - acc: 0.6293 - val_loss: 0.7169 - val_acc: 0.6068\n",
      "Epoch 156/500\n",
      "46/46 - 0s - loss: 0.6180 - acc: 0.6252 - val_loss: 0.7185 - val_acc: 0.6096\n",
      "Epoch 157/500\n",
      "46/46 - 0s - loss: 0.6179 - acc: 0.6307 - val_loss: 0.7167 - val_acc: 0.6096\n",
      "Epoch 158/500\n",
      "46/46 - 0s - loss: 0.6177 - acc: 0.6232 - val_loss: 0.7124 - val_acc: 0.6219\n",
      "Epoch 159/500\n",
      "46/46 - 0s - loss: 0.6168 - acc: 0.6269 - val_loss: 0.7235 - val_acc: 0.6041\n",
      "Epoch 160/500\n",
      "46/46 - 0s - loss: 0.6179 - acc: 0.6328 - val_loss: 0.7233 - val_acc: 0.6055\n",
      "Epoch 161/500\n",
      "46/46 - 0s - loss: 0.6178 - acc: 0.6242 - val_loss: 0.7243 - val_acc: 0.6096\n",
      "Epoch 162/500\n",
      "46/46 - 0s - loss: 0.6175 - acc: 0.6242 - val_loss: 0.7220 - val_acc: 0.5945\n",
      "Epoch 163/500\n",
      "46/46 - 0s - loss: 0.6170 - acc: 0.6266 - val_loss: 0.7292 - val_acc: 0.6000\n",
      "Epoch 164/500\n",
      "46/46 - 0s - loss: 0.6162 - acc: 0.6262 - val_loss: 0.7183 - val_acc: 0.6178\n",
      "Epoch 165/500\n",
      "46/46 - 0s - loss: 0.6170 - acc: 0.6276 - val_loss: 0.7244 - val_acc: 0.6164\n",
      "Epoch 166/500\n",
      "46/46 - 0s - loss: 0.6166 - acc: 0.6245 - val_loss: 0.7246 - val_acc: 0.6205\n",
      "Epoch 167/500\n",
      "46/46 - 0s - loss: 0.6147 - acc: 0.6372 - val_loss: 0.7356 - val_acc: 0.5904\n",
      "Epoch 168/500\n",
      "46/46 - 0s - loss: 0.6181 - acc: 0.6225 - val_loss: 0.7304 - val_acc: 0.6123\n",
      "Epoch 169/500\n",
      "46/46 - 0s - loss: 0.6156 - acc: 0.6307 - val_loss: 0.7316 - val_acc: 0.6110\n",
      "Epoch 170/500\n",
      "46/46 - 0s - loss: 0.6162 - acc: 0.6221 - val_loss: 0.7268 - val_acc: 0.6151\n",
      "Epoch 171/500\n",
      "46/46 - 0s - loss: 0.6155 - acc: 0.6276 - val_loss: 0.7304 - val_acc: 0.6110\n",
      "Epoch 172/500\n",
      "46/46 - 0s - loss: 0.6153 - acc: 0.6300 - val_loss: 0.7293 - val_acc: 0.6137\n",
      "Epoch 173/500\n",
      "46/46 - 0s - loss: 0.6151 - acc: 0.6358 - val_loss: 0.7314 - val_acc: 0.6192\n",
      "Epoch 174/500\n",
      "46/46 - 0s - loss: 0.6143 - acc: 0.6372 - val_loss: 0.7322 - val_acc: 0.6041\n",
      "Epoch 175/500\n",
      "46/46 - 0s - loss: 0.6147 - acc: 0.6304 - val_loss: 0.7297 - val_acc: 0.6041\n",
      "Epoch 176/500\n",
      "46/46 - 0s - loss: 0.6144 - acc: 0.6259 - val_loss: 0.7277 - val_acc: 0.6096\n",
      "Epoch 177/500\n",
      "46/46 - 0s - loss: 0.6146 - acc: 0.6262 - val_loss: 0.7380 - val_acc: 0.6068\n",
      "Epoch 178/500\n",
      "46/46 - 0s - loss: 0.6126 - acc: 0.6297 - val_loss: 0.7331 - val_acc: 0.6192\n",
      "Epoch 179/500\n",
      "46/46 - 0s - loss: 0.6140 - acc: 0.6252 - val_loss: 0.7373 - val_acc: 0.6068\n",
      "Epoch 180/500\n",
      "46/46 - 0s - loss: 0.6126 - acc: 0.6365 - val_loss: 0.7453 - val_acc: 0.6041\n",
      "Epoch 181/500\n",
      "46/46 - 0s - loss: 0.6135 - acc: 0.6280 - val_loss: 0.7333 - val_acc: 0.6151\n",
      "Epoch 182/500\n",
      "46/46 - 0s - loss: 0.6127 - acc: 0.6355 - val_loss: 0.7445 - val_acc: 0.6068\n",
      "Epoch 183/500\n",
      "46/46 - 0s - loss: 0.6121 - acc: 0.6348 - val_loss: 0.7411 - val_acc: 0.5932\n",
      "Epoch 184/500\n",
      "46/46 - 0s - loss: 0.6122 - acc: 0.6331 - val_loss: 0.7489 - val_acc: 0.6123\n",
      "Epoch 185/500\n",
      "46/46 - 0s - loss: 0.6121 - acc: 0.6232 - val_loss: 0.7345 - val_acc: 0.6301\n",
      "Epoch 186/500\n",
      "46/46 - 0s - loss: 0.6122 - acc: 0.6266 - val_loss: 0.7474 - val_acc: 0.6110\n",
      "Epoch 187/500\n",
      "46/46 - 0s - loss: 0.6131 - acc: 0.6328 - val_loss: 0.7344 - val_acc: 0.6219\n",
      "Epoch 188/500\n",
      "46/46 - 0s - loss: 0.6113 - acc: 0.6345 - val_loss: 0.7387 - val_acc: 0.6178\n",
      "Epoch 189/500\n",
      "46/46 - 0s - loss: 0.6104 - acc: 0.6345 - val_loss: 0.7484 - val_acc: 0.6082\n",
      "Epoch 190/500\n",
      "46/46 - 0s - loss: 0.6115 - acc: 0.6314 - val_loss: 0.7453 - val_acc: 0.6247\n",
      "Epoch 191/500\n",
      "46/46 - 0s - loss: 0.6104 - acc: 0.6300 - val_loss: 0.7510 - val_acc: 0.6110\n",
      "Epoch 192/500\n",
      "46/46 - 0s - loss: 0.6112 - acc: 0.6365 - val_loss: 0.7499 - val_acc: 0.6164\n",
      "Epoch 193/500\n",
      "46/46 - 0s - loss: 0.6112 - acc: 0.6307 - val_loss: 0.7512 - val_acc: 0.6110\n",
      "Epoch 194/500\n",
      "46/46 - 0s - loss: 0.6089 - acc: 0.6324 - val_loss: 0.7642 - val_acc: 0.6082\n",
      "Epoch 195/500\n",
      "46/46 - 0s - loss: 0.6120 - acc: 0.6293 - val_loss: 0.7537 - val_acc: 0.5986\n",
      "Epoch 196/500\n",
      "46/46 - 0s - loss: 0.6104 - acc: 0.6293 - val_loss: 0.7630 - val_acc: 0.6137\n",
      "Epoch 197/500\n",
      "46/46 - 0s - loss: 0.6090 - acc: 0.6362 - val_loss: 0.7603 - val_acc: 0.6110\n",
      "Epoch 198/500\n",
      "46/46 - 0s - loss: 0.6087 - acc: 0.6331 - val_loss: 0.7679 - val_acc: 0.6027\n",
      "Epoch 199/500\n",
      "46/46 - 0s - loss: 0.6094 - acc: 0.6314 - val_loss: 0.7546 - val_acc: 0.6233\n",
      "Epoch 200/500\n",
      "46/46 - 0s - loss: 0.6087 - acc: 0.6372 - val_loss: 0.7602 - val_acc: 0.6164\n",
      "Epoch 201/500\n",
      "46/46 - 0s - loss: 0.6077 - acc: 0.6345 - val_loss: 0.7665 - val_acc: 0.6164\n",
      "Epoch 202/500\n",
      "46/46 - 0s - loss: 0.6077 - acc: 0.6369 - val_loss: 0.7584 - val_acc: 0.6219\n",
      "Epoch 203/500\n",
      "46/46 - 0s - loss: 0.6064 - acc: 0.6369 - val_loss: 0.7628 - val_acc: 0.6219\n",
      "Epoch 204/500\n",
      "46/46 - 0s - loss: 0.6079 - acc: 0.6317 - val_loss: 0.7677 - val_acc: 0.6260\n",
      "Epoch 205/500\n",
      "46/46 - 0s - loss: 0.6073 - acc: 0.6417 - val_loss: 0.7660 - val_acc: 0.6151\n",
      "Epoch 206/500\n",
      "46/46 - 0s - loss: 0.6066 - acc: 0.6393 - val_loss: 0.7702 - val_acc: 0.6082\n",
      "Epoch 207/500\n",
      "46/46 - 0s - loss: 0.6063 - acc: 0.6396 - val_loss: 0.7692 - val_acc: 0.6247\n",
      "Epoch 208/500\n",
      "46/46 - 0s - loss: 0.6059 - acc: 0.6355 - val_loss: 0.7642 - val_acc: 0.6329\n",
      "Epoch 209/500\n",
      "46/46 - 0s - loss: 0.6055 - acc: 0.6300 - val_loss: 0.7732 - val_acc: 0.6110\n",
      "Epoch 210/500\n",
      "46/46 - 0s - loss: 0.6050 - acc: 0.6420 - val_loss: 0.7695 - val_acc: 0.6123\n",
      "Epoch 211/500\n",
      "46/46 - 0s - loss: 0.6049 - acc: 0.6403 - val_loss: 0.7709 - val_acc: 0.6164\n",
      "Epoch 212/500\n",
      "46/46 - 0s - loss: 0.6045 - acc: 0.6389 - val_loss: 0.7798 - val_acc: 0.6178\n",
      "Epoch 213/500\n",
      "46/46 - 0s - loss: 0.6054 - acc: 0.6382 - val_loss: 0.7724 - val_acc: 0.6219\n",
      "Epoch 214/500\n",
      "46/46 - 0s - loss: 0.6052 - acc: 0.6379 - val_loss: 0.7877 - val_acc: 0.6123\n",
      "Epoch 215/500\n",
      "46/46 - 0s - loss: 0.6045 - acc: 0.6406 - val_loss: 0.7780 - val_acc: 0.6068\n",
      "Epoch 216/500\n",
      "46/46 - 0s - loss: 0.6038 - acc: 0.6393 - val_loss: 0.7872 - val_acc: 0.6068\n",
      "Epoch 217/500\n",
      "46/46 - 0s - loss: 0.6032 - acc: 0.6351 - val_loss: 0.7827 - val_acc: 0.6137\n",
      "Epoch 218/500\n",
      "46/46 - 0s - loss: 0.6024 - acc: 0.6358 - val_loss: 0.7930 - val_acc: 0.6000\n",
      "Epoch 219/500\n",
      "46/46 - 0s - loss: 0.6052 - acc: 0.6369 - val_loss: 0.7903 - val_acc: 0.6219\n",
      "Epoch 220/500\n",
      "46/46 - 0s - loss: 0.6021 - acc: 0.6410 - val_loss: 0.7889 - val_acc: 0.6288\n",
      "Epoch 221/500\n",
      "46/46 - 0s - loss: 0.6015 - acc: 0.6458 - val_loss: 0.7854 - val_acc: 0.6110\n",
      "Epoch 222/500\n",
      "46/46 - 0s - loss: 0.6028 - acc: 0.6372 - val_loss: 0.8017 - val_acc: 0.6082\n",
      "Epoch 223/500\n",
      "46/46 - 0s - loss: 0.6021 - acc: 0.6399 - val_loss: 0.7862 - val_acc: 0.6151\n",
      "Epoch 224/500\n",
      "46/46 - 0s - loss: 0.6025 - acc: 0.6441 - val_loss: 0.7831 - val_acc: 0.6192\n",
      "Epoch 225/500\n",
      "46/46 - 0s - loss: 0.6027 - acc: 0.6372 - val_loss: 0.7942 - val_acc: 0.6260\n",
      "Epoch 226/500\n",
      "46/46 - 0s - loss: 0.6028 - acc: 0.6386 - val_loss: 0.7917 - val_acc: 0.6192\n",
      "Epoch 227/500\n",
      "46/46 - 0s - loss: 0.6023 - acc: 0.6475 - val_loss: 0.7888 - val_acc: 0.6178\n",
      "Epoch 228/500\n",
      "46/46 - 0s - loss: 0.6018 - acc: 0.6420 - val_loss: 0.7994 - val_acc: 0.6205\n",
      "Epoch 229/500\n",
      "46/46 - 0s - loss: 0.6009 - acc: 0.6437 - val_loss: 0.7938 - val_acc: 0.6151\n",
      "Epoch 230/500\n",
      "46/46 - 0s - loss: 0.6008 - acc: 0.6437 - val_loss: 0.8096 - val_acc: 0.5863\n",
      "Epoch 231/500\n",
      "46/46 - 0s - loss: 0.6006 - acc: 0.6413 - val_loss: 0.8045 - val_acc: 0.6041\n",
      "Epoch 232/500\n",
      "46/46 - 0s - loss: 0.5999 - acc: 0.6365 - val_loss: 0.7996 - val_acc: 0.5945\n",
      "Epoch 233/500\n",
      "46/46 - 0s - loss: 0.5976 - acc: 0.6458 - val_loss: 0.7997 - val_acc: 0.6151\n",
      "Epoch 234/500\n",
      "46/46 - 0s - loss: 0.5988 - acc: 0.6489 - val_loss: 0.8129 - val_acc: 0.6068\n",
      "Epoch 235/500\n",
      "46/46 - 0s - loss: 0.6006 - acc: 0.6369 - val_loss: 0.7993 - val_acc: 0.6082\n",
      "Epoch 236/500\n",
      "46/46 - 0s - loss: 0.5997 - acc: 0.6355 - val_loss: 0.8019 - val_acc: 0.6110\n",
      "Epoch 237/500\n",
      "46/46 - 0s - loss: 0.5982 - acc: 0.6406 - val_loss: 0.8046 - val_acc: 0.6205\n",
      "Epoch 238/500\n",
      "46/46 - 0s - loss: 0.5998 - acc: 0.6465 - val_loss: 0.8203 - val_acc: 0.6068\n",
      "Epoch 239/500\n",
      "46/46 - 0s - loss: 0.5976 - acc: 0.6458 - val_loss: 0.8080 - val_acc: 0.6110\n",
      "Epoch 240/500\n",
      "46/46 - 0s - loss: 0.5968 - acc: 0.6417 - val_loss: 0.8180 - val_acc: 0.6041\n",
      "Epoch 241/500\n",
      "46/46 - 0s - loss: 0.5977 - acc: 0.6410 - val_loss: 0.8316 - val_acc: 0.6014\n",
      "Epoch 242/500\n",
      "46/46 - 0s - loss: 0.5988 - acc: 0.6406 - val_loss: 0.8212 - val_acc: 0.6041\n",
      "Epoch 243/500\n",
      "46/46 - 0s - loss: 0.5959 - acc: 0.6482 - val_loss: 0.8226 - val_acc: 0.6164\n",
      "Epoch 244/500\n",
      "46/46 - 0s - loss: 0.5969 - acc: 0.6451 - val_loss: 0.8323 - val_acc: 0.6123\n",
      "Epoch 245/500\n",
      "46/46 - 0s - loss: 0.5964 - acc: 0.6454 - val_loss: 0.8226 - val_acc: 0.6110\n",
      "Epoch 246/500\n",
      "46/46 - 0s - loss: 0.5948 - acc: 0.6502 - val_loss: 0.8271 - val_acc: 0.5877\n",
      "Epoch 247/500\n",
      "46/46 - 0s - loss: 0.5967 - acc: 0.6437 - val_loss: 0.8403 - val_acc: 0.5918\n",
      "Epoch 248/500\n",
      "46/46 - 0s - loss: 0.5953 - acc: 0.6458 - val_loss: 0.8252 - val_acc: 0.6014\n",
      "Epoch 249/500\n",
      "46/46 - 0s - loss: 0.5955 - acc: 0.6475 - val_loss: 0.8315 - val_acc: 0.6137\n",
      "Epoch 250/500\n",
      "46/46 - 0s - loss: 0.5935 - acc: 0.6375 - val_loss: 0.8266 - val_acc: 0.6219\n",
      "Epoch 251/500\n",
      "46/46 - 0s - loss: 0.5932 - acc: 0.6403 - val_loss: 0.8483 - val_acc: 0.6041\n",
      "Epoch 252/500\n",
      "46/46 - 0s - loss: 0.5940 - acc: 0.6437 - val_loss: 0.8281 - val_acc: 0.5822\n",
      "Epoch 253/500\n",
      "46/46 - 0s - loss: 0.5938 - acc: 0.6437 - val_loss: 0.8421 - val_acc: 0.6205\n",
      "Epoch 254/500\n",
      "46/46 - 0s - loss: 0.5960 - acc: 0.6441 - val_loss: 0.8353 - val_acc: 0.6164\n",
      "Epoch 255/500\n",
      "46/46 - 0s - loss: 0.5933 - acc: 0.6489 - val_loss: 0.8358 - val_acc: 0.6178\n",
      "Epoch 256/500\n",
      "46/46 - 0s - loss: 0.5924 - acc: 0.6489 - val_loss: 0.8288 - val_acc: 0.5918\n",
      "Epoch 257/500\n",
      "46/46 - 0s - loss: 0.5924 - acc: 0.6410 - val_loss: 0.8412 - val_acc: 0.6041\n",
      "Epoch 258/500\n",
      "46/46 - 0s - loss: 0.5915 - acc: 0.6468 - val_loss: 0.8291 - val_acc: 0.6110\n",
      "Epoch 259/500\n",
      "46/46 - 0s - loss: 0.5920 - acc: 0.6485 - val_loss: 0.8421 - val_acc: 0.5808\n",
      "Epoch 260/500\n",
      "46/46 - 0s - loss: 0.5905 - acc: 0.6526 - val_loss: 0.8355 - val_acc: 0.6123\n",
      "Epoch 261/500\n",
      "46/46 - 0s - loss: 0.5907 - acc: 0.6437 - val_loss: 0.8414 - val_acc: 0.6137\n",
      "Epoch 262/500\n",
      "46/46 - 0s - loss: 0.5903 - acc: 0.6458 - val_loss: 0.8509 - val_acc: 0.6123\n",
      "Epoch 263/500\n",
      "46/46 - 0s - loss: 0.5907 - acc: 0.6536 - val_loss: 0.8497 - val_acc: 0.5904\n",
      "Epoch 264/500\n",
      "46/46 - 0s - loss: 0.5892 - acc: 0.6465 - val_loss: 0.8492 - val_acc: 0.6068\n",
      "Epoch 265/500\n",
      "46/46 - 0s - loss: 0.5893 - acc: 0.6471 - val_loss: 0.8482 - val_acc: 0.6164\n",
      "Epoch 266/500\n",
      "46/46 - 0s - loss: 0.5894 - acc: 0.6454 - val_loss: 0.8520 - val_acc: 0.5890\n",
      "Epoch 267/500\n",
      "46/46 - 0s - loss: 0.5885 - acc: 0.6482 - val_loss: 0.8419 - val_acc: 0.6205\n",
      "Epoch 268/500\n",
      "46/46 - 0s - loss: 0.5881 - acc: 0.6533 - val_loss: 0.8460 - val_acc: 0.6096\n",
      "Epoch 269/500\n",
      "46/46 - 0s - loss: 0.5885 - acc: 0.6499 - val_loss: 0.8534 - val_acc: 0.6096\n",
      "Epoch 270/500\n",
      "46/46 - 0s - loss: 0.5890 - acc: 0.6502 - val_loss: 0.8513 - val_acc: 0.6178\n",
      "Epoch 271/500\n",
      "46/46 - 0s - loss: 0.5887 - acc: 0.6526 - val_loss: 0.8574 - val_acc: 0.5959\n",
      "Epoch 272/500\n",
      "46/46 - 0s - loss: 0.5891 - acc: 0.6461 - val_loss: 0.8686 - val_acc: 0.6110\n",
      "Epoch 273/500\n",
      "46/46 - 0s - loss: 0.5877 - acc: 0.6499 - val_loss: 0.8530 - val_acc: 0.6041\n",
      "Epoch 274/500\n",
      "46/46 - 0s - loss: 0.5896 - acc: 0.6485 - val_loss: 0.8682 - val_acc: 0.6178\n",
      "Epoch 275/500\n",
      "46/46 - 0s - loss: 0.5863 - acc: 0.6571 - val_loss: 0.8615 - val_acc: 0.6123\n",
      "Epoch 276/500\n",
      "46/46 - 0s - loss: 0.5850 - acc: 0.6543 - val_loss: 0.8559 - val_acc: 0.6151\n",
      "Epoch 277/500\n",
      "46/46 - 0s - loss: 0.5858 - acc: 0.6543 - val_loss: 0.8590 - val_acc: 0.6178\n",
      "Epoch 278/500\n",
      "46/46 - 0s - loss: 0.5839 - acc: 0.6533 - val_loss: 0.8835 - val_acc: 0.6137\n",
      "Epoch 279/500\n",
      "46/46 - 0s - loss: 0.5884 - acc: 0.6540 - val_loss: 0.8643 - val_acc: 0.6123\n",
      "Epoch 280/500\n",
      "46/46 - 0s - loss: 0.5843 - acc: 0.6536 - val_loss: 0.8819 - val_acc: 0.5932\n",
      "Epoch 281/500\n",
      "46/46 - 0s - loss: 0.5854 - acc: 0.6588 - val_loss: 0.8687 - val_acc: 0.6151\n",
      "Epoch 282/500\n",
      "46/46 - 0s - loss: 0.5832 - acc: 0.6588 - val_loss: 0.8737 - val_acc: 0.5904\n",
      "Epoch 283/500\n",
      "46/46 - 0s - loss: 0.5839 - acc: 0.6564 - val_loss: 0.8695 - val_acc: 0.6123\n",
      "Epoch 284/500\n",
      "46/46 - 0s - loss: 0.5838 - acc: 0.6485 - val_loss: 0.8644 - val_acc: 0.6123\n",
      "Epoch 285/500\n",
      "46/46 - 0s - loss: 0.5808 - acc: 0.6567 - val_loss: 0.8833 - val_acc: 0.5945\n",
      "Epoch 286/500\n",
      "46/46 - 0s - loss: 0.5826 - acc: 0.6584 - val_loss: 0.8736 - val_acc: 0.6027\n",
      "Epoch 287/500\n",
      "46/46 - 0s - loss: 0.5830 - acc: 0.6543 - val_loss: 0.8654 - val_acc: 0.6137\n",
      "Epoch 288/500\n",
      "46/46 - 0s - loss: 0.5822 - acc: 0.6513 - val_loss: 0.8796 - val_acc: 0.5986\n",
      "Epoch 289/500\n",
      "46/46 - 0s - loss: 0.5857 - acc: 0.6574 - val_loss: 0.8634 - val_acc: 0.5959\n",
      "Epoch 290/500\n",
      "46/46 - 0s - loss: 0.5799 - acc: 0.6595 - val_loss: 0.8643 - val_acc: 0.6082\n",
      "Epoch 291/500\n",
      "46/46 - 0s - loss: 0.5809 - acc: 0.6533 - val_loss: 0.8718 - val_acc: 0.6151\n",
      "Epoch 292/500\n",
      "46/46 - 0s - loss: 0.5799 - acc: 0.6595 - val_loss: 0.8706 - val_acc: 0.6192\n",
      "Epoch 293/500\n",
      "46/46 - 0s - loss: 0.5788 - acc: 0.6595 - val_loss: 0.8726 - val_acc: 0.6068\n",
      "Epoch 294/500\n",
      "46/46 - 0s - loss: 0.5802 - acc: 0.6632 - val_loss: 0.8910 - val_acc: 0.6137\n",
      "Epoch 295/500\n",
      "46/46 - 0s - loss: 0.5792 - acc: 0.6578 - val_loss: 0.8904 - val_acc: 0.6027\n",
      "Epoch 296/500\n",
      "46/46 - 0s - loss: 0.5788 - acc: 0.6581 - val_loss: 0.8835 - val_acc: 0.5918\n",
      "Epoch 297/500\n",
      "46/46 - 0s - loss: 0.5766 - acc: 0.6608 - val_loss: 0.8836 - val_acc: 0.6096\n",
      "Epoch 298/500\n",
      "46/46 - 0s - loss: 0.5777 - acc: 0.6560 - val_loss: 0.8899 - val_acc: 0.5808\n",
      "Epoch 299/500\n",
      "46/46 - 0s - loss: 0.5775 - acc: 0.6663 - val_loss: 0.8877 - val_acc: 0.6110\n",
      "Epoch 300/500\n",
      "46/46 - 0s - loss: 0.5762 - acc: 0.6646 - val_loss: 0.8787 - val_acc: 0.6068\n",
      "Epoch 301/500\n",
      "46/46 - 0s - loss: 0.5769 - acc: 0.6622 - val_loss: 0.8783 - val_acc: 0.6151\n",
      "Epoch 302/500\n",
      "46/46 - 0s - loss: 0.5752 - acc: 0.6605 - val_loss: 0.8910 - val_acc: 0.6205\n",
      "Epoch 303/500\n",
      "46/46 - 0s - loss: 0.5770 - acc: 0.6602 - val_loss: 0.8966 - val_acc: 0.6027\n",
      "Epoch 304/500\n",
      "46/46 - 0s - loss: 0.5762 - acc: 0.6643 - val_loss: 0.8947 - val_acc: 0.6000\n",
      "Epoch 305/500\n",
      "46/46 - 0s - loss: 0.5756 - acc: 0.6643 - val_loss: 0.8868 - val_acc: 0.6137\n",
      "Epoch 306/500\n",
      "46/46 - 0s - loss: 0.5766 - acc: 0.6653 - val_loss: 0.8917 - val_acc: 0.6110\n",
      "Epoch 307/500\n",
      "46/46 - 0s - loss: 0.5757 - acc: 0.6636 - val_loss: 0.8930 - val_acc: 0.5986\n",
      "Epoch 308/500\n",
      "46/46 - 0s - loss: 0.5746 - acc: 0.6650 - val_loss: 0.8931 - val_acc: 0.6096\n",
      "Epoch 309/500\n",
      "46/46 - 0s - loss: 0.5755 - acc: 0.6687 - val_loss: 0.9018 - val_acc: 0.6041\n",
      "Epoch 310/500\n",
      "46/46 - 0s - loss: 0.5736 - acc: 0.6639 - val_loss: 0.9022 - val_acc: 0.6014\n",
      "Epoch 311/500\n",
      "46/46 - 0s - loss: 0.5745 - acc: 0.6704 - val_loss: 0.9043 - val_acc: 0.6082\n",
      "Epoch 312/500\n",
      "46/46 - 0s - loss: 0.5738 - acc: 0.6643 - val_loss: 0.9068 - val_acc: 0.6096\n",
      "Epoch 313/500\n",
      "46/46 - 0s - loss: 0.5718 - acc: 0.6653 - val_loss: 0.9090 - val_acc: 0.5836\n",
      "Epoch 314/500\n",
      "46/46 - 0s - loss: 0.5702 - acc: 0.6711 - val_loss: 0.9092 - val_acc: 0.6096\n",
      "Epoch 315/500\n",
      "46/46 - 0s - loss: 0.5708 - acc: 0.6708 - val_loss: 0.9077 - val_acc: 0.6151\n",
      "Epoch 316/500\n",
      "46/46 - 0s - loss: 0.5696 - acc: 0.6694 - val_loss: 0.9087 - val_acc: 0.5973\n",
      "Epoch 317/500\n",
      "46/46 - 0s - loss: 0.5698 - acc: 0.6674 - val_loss: 0.9058 - val_acc: 0.6082\n",
      "Epoch 318/500\n",
      "46/46 - 0s - loss: 0.5694 - acc: 0.6677 - val_loss: 0.9153 - val_acc: 0.5890\n",
      "Epoch 319/500\n",
      "46/46 - 0s - loss: 0.5702 - acc: 0.6615 - val_loss: 0.9096 - val_acc: 0.5918\n",
      "Epoch 320/500\n",
      "46/46 - 0s - loss: 0.5688 - acc: 0.6728 - val_loss: 0.9005 - val_acc: 0.6178\n",
      "Epoch 321/500\n",
      "46/46 - 0s - loss: 0.5690 - acc: 0.6677 - val_loss: 0.9140 - val_acc: 0.6123\n",
      "Epoch 322/500\n",
      "46/46 - 0s - loss: 0.5688 - acc: 0.6739 - val_loss: 0.9137 - val_acc: 0.6082\n",
      "Epoch 323/500\n",
      "46/46 - 0s - loss: 0.5675 - acc: 0.6725 - val_loss: 0.9079 - val_acc: 0.6068\n",
      "Epoch 324/500\n",
      "46/46 - 0s - loss: 0.5672 - acc: 0.6742 - val_loss: 0.9153 - val_acc: 0.5918\n",
      "Epoch 325/500\n",
      "46/46 - 0s - loss: 0.5686 - acc: 0.6725 - val_loss: 0.9209 - val_acc: 0.6055\n",
      "Epoch 326/500\n",
      "46/46 - 0s - loss: 0.5666 - acc: 0.6739 - val_loss: 0.9036 - val_acc: 0.6137\n",
      "Epoch 327/500\n",
      "46/46 - 0s - loss: 0.5664 - acc: 0.6732 - val_loss: 0.9247 - val_acc: 0.5863\n",
      "Epoch 328/500\n",
      "46/46 - 0s - loss: 0.5654 - acc: 0.6718 - val_loss: 0.9205 - val_acc: 0.6068\n",
      "Epoch 329/500\n",
      "46/46 - 0s - loss: 0.5640 - acc: 0.6739 - val_loss: 0.9260 - val_acc: 0.6014\n",
      "Epoch 330/500\n",
      "46/46 - 0s - loss: 0.5662 - acc: 0.6728 - val_loss: 0.9135 - val_acc: 0.6055\n",
      "Epoch 331/500\n",
      "46/46 - 0s - loss: 0.5631 - acc: 0.6766 - val_loss: 0.9218 - val_acc: 0.6027\n",
      "Epoch 332/500\n",
      "46/46 - 0s - loss: 0.5644 - acc: 0.6745 - val_loss: 0.9282 - val_acc: 0.6068\n",
      "Epoch 333/500\n",
      "46/46 - 0s - loss: 0.5637 - acc: 0.6773 - val_loss: 0.9270 - val_acc: 0.5904\n",
      "Epoch 334/500\n",
      "46/46 - 0s - loss: 0.5630 - acc: 0.6780 - val_loss: 0.9334 - val_acc: 0.6082\n",
      "Epoch 335/500\n",
      "46/46 - 0s - loss: 0.5625 - acc: 0.6704 - val_loss: 0.9263 - val_acc: 0.5959\n",
      "Epoch 336/500\n",
      "46/46 - 0s - loss: 0.5615 - acc: 0.6797 - val_loss: 0.9243 - val_acc: 0.5973\n",
      "Epoch 337/500\n",
      "46/46 - 0s - loss: 0.5616 - acc: 0.6793 - val_loss: 0.9124 - val_acc: 0.6027\n",
      "Epoch 338/500\n",
      "46/46 - 0s - loss: 0.5601 - acc: 0.6804 - val_loss: 0.9485 - val_acc: 0.5795\n",
      "Epoch 339/500\n",
      "46/46 - 0s - loss: 0.5596 - acc: 0.6793 - val_loss: 0.9313 - val_acc: 0.6041\n",
      "Epoch 340/500\n",
      "46/46 - 0s - loss: 0.5598 - acc: 0.6752 - val_loss: 0.9417 - val_acc: 0.6027\n",
      "Epoch 341/500\n",
      "46/46 - 0s - loss: 0.5601 - acc: 0.6766 - val_loss: 0.9305 - val_acc: 0.6137\n",
      "Epoch 342/500\n",
      "46/46 - 0s - loss: 0.5619 - acc: 0.6749 - val_loss: 0.9436 - val_acc: 0.6027\n",
      "Epoch 343/500\n",
      "46/46 - 0s - loss: 0.5576 - acc: 0.6845 - val_loss: 0.9336 - val_acc: 0.6000\n",
      "Epoch 344/500\n",
      "46/46 - 0s - loss: 0.5602 - acc: 0.6769 - val_loss: 0.9589 - val_acc: 0.5904\n",
      "Epoch 345/500\n",
      "46/46 - 0s - loss: 0.5599 - acc: 0.6643 - val_loss: 0.9590 - val_acc: 0.5904\n",
      "Epoch 346/500\n",
      "46/46 - 0s - loss: 0.5574 - acc: 0.6773 - val_loss: 0.9485 - val_acc: 0.5973\n",
      "Epoch 347/500\n",
      "46/46 - 0s - loss: 0.5558 - acc: 0.6807 - val_loss: 0.9432 - val_acc: 0.5986\n",
      "Epoch 348/500\n",
      "46/46 - 0s - loss: 0.5563 - acc: 0.6763 - val_loss: 0.9407 - val_acc: 0.6055\n",
      "Epoch 349/500\n",
      "46/46 - 0s - loss: 0.5584 - acc: 0.6804 - val_loss: 0.9461 - val_acc: 0.5986\n",
      "Epoch 350/500\n",
      "46/46 - 0s - loss: 0.5557 - acc: 0.6835 - val_loss: 0.9520 - val_acc: 0.5753\n",
      "Epoch 351/500\n",
      "46/46 - 0s - loss: 0.5557 - acc: 0.6742 - val_loss: 0.9678 - val_acc: 0.6055\n",
      "Epoch 352/500\n",
      "46/46 - 0s - loss: 0.5555 - acc: 0.6797 - val_loss: 0.9583 - val_acc: 0.6082\n",
      "Epoch 353/500\n",
      "46/46 - 0s - loss: 0.5553 - acc: 0.6773 - val_loss: 0.9751 - val_acc: 0.5945\n",
      "Epoch 354/500\n",
      "46/46 - 0s - loss: 0.5555 - acc: 0.6807 - val_loss: 0.9358 - val_acc: 0.5945\n",
      "Epoch 355/500\n",
      "46/46 - 0s - loss: 0.5574 - acc: 0.6821 - val_loss: 0.9434 - val_acc: 0.5904\n",
      "Epoch 356/500\n",
      "46/46 - 0s - loss: 0.5564 - acc: 0.6807 - val_loss: 0.9627 - val_acc: 0.5795\n",
      "Epoch 357/500\n",
      "46/46 - 0s - loss: 0.5527 - acc: 0.6848 - val_loss: 0.9586 - val_acc: 0.5959\n",
      "Epoch 358/500\n",
      "46/46 - 0s - loss: 0.5527 - acc: 0.6783 - val_loss: 0.9616 - val_acc: 0.5877\n",
      "Epoch 359/500\n",
      "46/46 - 0s - loss: 0.5537 - acc: 0.6852 - val_loss: 0.9609 - val_acc: 0.6027\n",
      "Epoch 360/500\n",
      "46/46 - 0s - loss: 0.5564 - acc: 0.6807 - val_loss: 0.9824 - val_acc: 0.6096\n",
      "Epoch 361/500\n",
      "46/46 - 0s - loss: 0.5535 - acc: 0.6807 - val_loss: 0.9467 - val_acc: 0.6123\n",
      "Epoch 362/500\n",
      "46/46 - 0s - loss: 0.5519 - acc: 0.6893 - val_loss: 0.9658 - val_acc: 0.5890\n",
      "Epoch 363/500\n",
      "46/46 - 0s - loss: 0.5525 - acc: 0.6886 - val_loss: 0.9614 - val_acc: 0.5877\n",
      "Epoch 364/500\n",
      "46/46 - 0s - loss: 0.5490 - acc: 0.6859 - val_loss: 0.9626 - val_acc: 0.6041\n",
      "Epoch 365/500\n",
      "46/46 - 0s - loss: 0.5490 - acc: 0.6821 - val_loss: 0.9694 - val_acc: 0.5822\n",
      "Epoch 366/500\n",
      "46/46 - 0s - loss: 0.5496 - acc: 0.6872 - val_loss: 0.9610 - val_acc: 0.6014\n",
      "Epoch 367/500\n",
      "46/46 - 0s - loss: 0.5469 - acc: 0.6848 - val_loss: 0.9861 - val_acc: 0.5836\n",
      "Epoch 368/500\n",
      "46/46 - 0s - loss: 0.5478 - acc: 0.6886 - val_loss: 0.9819 - val_acc: 0.5945\n",
      "Epoch 369/500\n",
      "46/46 - 0s - loss: 0.5467 - acc: 0.6841 - val_loss: 0.9709 - val_acc: 0.5808\n",
      "Epoch 370/500\n",
      "46/46 - 0s - loss: 0.5471 - acc: 0.6896 - val_loss: 0.9751 - val_acc: 0.5932\n",
      "Epoch 371/500\n",
      "46/46 - 0s - loss: 0.5473 - acc: 0.6882 - val_loss: 0.9800 - val_acc: 0.5945\n",
      "Epoch 372/500\n",
      "46/46 - 0s - loss: 0.5467 - acc: 0.6824 - val_loss: 0.9709 - val_acc: 0.5959\n",
      "Epoch 373/500\n",
      "46/46 - 0s - loss: 0.5457 - acc: 0.6930 - val_loss: 0.9768 - val_acc: 0.5877\n",
      "Epoch 374/500\n",
      "46/46 - 0s - loss: 0.5442 - acc: 0.6934 - val_loss: 0.9862 - val_acc: 0.5945\n",
      "Epoch 375/500\n",
      "46/46 - 0s - loss: 0.5451 - acc: 0.6951 - val_loss: 0.9861 - val_acc: 0.5877\n",
      "Epoch 376/500\n",
      "46/46 - 0s - loss: 0.5466 - acc: 0.6903 - val_loss: 0.9813 - val_acc: 0.5863\n",
      "Epoch 377/500\n",
      "46/46 - 0s - loss: 0.5447 - acc: 0.6811 - val_loss: 0.9889 - val_acc: 0.5863\n",
      "Epoch 378/500\n",
      "46/46 - 0s - loss: 0.5430 - acc: 0.6882 - val_loss: 0.9872 - val_acc: 0.5753\n",
      "Epoch 379/500\n",
      "46/46 - 0s - loss: 0.5417 - acc: 0.6896 - val_loss: 1.0039 - val_acc: 0.5945\n",
      "Epoch 380/500\n",
      "46/46 - 0s - loss: 0.5426 - acc: 0.6869 - val_loss: 1.0050 - val_acc: 0.5685\n",
      "Epoch 381/500\n",
      "46/46 - 0s - loss: 0.5437 - acc: 0.6852 - val_loss: 0.9977 - val_acc: 0.5986\n",
      "Epoch 382/500\n",
      "46/46 - 0s - loss: 0.5409 - acc: 0.6910 - val_loss: 1.0055 - val_acc: 0.5945\n",
      "Epoch 383/500\n",
      "46/46 - 0s - loss: 0.5408 - acc: 0.6924 - val_loss: 1.0055 - val_acc: 0.5973\n",
      "Epoch 384/500\n",
      "46/46 - 0s - loss: 0.5403 - acc: 0.6800 - val_loss: 1.0097 - val_acc: 0.5808\n",
      "Epoch 385/500\n",
      "46/46 - 0s - loss: 0.5417 - acc: 0.6934 - val_loss: 1.0096 - val_acc: 0.5753\n",
      "Epoch 386/500\n",
      "46/46 - 0s - loss: 0.5394 - acc: 0.6924 - val_loss: 0.9962 - val_acc: 0.5986\n",
      "Epoch 387/500\n",
      "46/46 - 0s - loss: 0.5388 - acc: 0.6924 - val_loss: 1.0128 - val_acc: 0.5219\n",
      "Epoch 388/500\n",
      "46/46 - 0s - loss: 0.5400 - acc: 0.6869 - val_loss: 1.0170 - val_acc: 0.5740\n",
      "Epoch 389/500\n",
      "46/46 - 0s - loss: 0.5375 - acc: 0.6896 - val_loss: 1.0203 - val_acc: 0.5658\n",
      "Epoch 390/500\n",
      "46/46 - 0s - loss: 0.5371 - acc: 0.6999 - val_loss: 1.0250 - val_acc: 0.5795\n",
      "Epoch 391/500\n",
      "46/46 - 0s - loss: 0.5378 - acc: 0.6893 - val_loss: 1.0093 - val_acc: 0.5781\n",
      "Epoch 392/500\n",
      "46/46 - 0s - loss: 0.5372 - acc: 0.6924 - val_loss: 1.0161 - val_acc: 0.5877\n",
      "Epoch 393/500\n",
      "46/46 - 0s - loss: 0.5369 - acc: 0.6913 - val_loss: 1.0144 - val_acc: 0.5849\n",
      "Epoch 394/500\n",
      "46/46 - 0s - loss: 0.5384 - acc: 0.6889 - val_loss: 1.0139 - val_acc: 0.5795\n",
      "Epoch 395/500\n",
      "46/46 - 0s - loss: 0.5354 - acc: 0.6958 - val_loss: 1.0288 - val_acc: 0.5918\n",
      "Epoch 396/500\n",
      "46/46 - 0s - loss: 0.5356 - acc: 0.6948 - val_loss: 1.0450 - val_acc: 0.5726\n",
      "Epoch 397/500\n",
      "46/46 - 0s - loss: 0.5376 - acc: 0.6941 - val_loss: 1.0329 - val_acc: 0.5753\n",
      "Epoch 398/500\n",
      "46/46 - 0s - loss: 0.5349 - acc: 0.6978 - val_loss: 1.0455 - val_acc: 0.5726\n",
      "Epoch 399/500\n",
      "46/46 - 0s - loss: 0.5331 - acc: 0.6900 - val_loss: 1.0505 - val_acc: 0.5918\n",
      "Epoch 400/500\n",
      "46/46 - 0s - loss: 0.5330 - acc: 0.6920 - val_loss: 1.0240 - val_acc: 0.5795\n",
      "Epoch 401/500\n",
      "46/46 - 0s - loss: 0.5296 - acc: 0.6951 - val_loss: 1.0379 - val_acc: 0.5726\n",
      "Epoch 402/500\n",
      "46/46 - 0s - loss: 0.5333 - acc: 0.6951 - val_loss: 1.0426 - val_acc: 0.5712\n",
      "Epoch 403/500\n",
      "46/46 - 0s - loss: 0.5332 - acc: 0.6941 - val_loss: 1.0484 - val_acc: 0.5685\n",
      "Epoch 404/500\n",
      "46/46 - 0s - loss: 0.5330 - acc: 0.6937 - val_loss: 1.0464 - val_acc: 0.5808\n",
      "Epoch 405/500\n",
      "46/46 - 0s - loss: 0.5297 - acc: 0.6999 - val_loss: 1.0427 - val_acc: 0.5849\n",
      "Epoch 406/500\n",
      "46/46 - 0s - loss: 0.5303 - acc: 0.6941 - val_loss: 1.0477 - val_acc: 0.5808\n",
      "Epoch 407/500\n",
      "46/46 - 0s - loss: 0.5316 - acc: 0.6958 - val_loss: 1.0260 - val_acc: 0.5932\n",
      "Epoch 408/500\n",
      "46/46 - 0s - loss: 0.5300 - acc: 0.6992 - val_loss: 1.0317 - val_acc: 0.5932\n",
      "Epoch 409/500\n",
      "46/46 - 0s - loss: 0.5294 - acc: 0.6944 - val_loss: 1.0567 - val_acc: 0.5753\n",
      "Epoch 410/500\n",
      "46/46 - 0s - loss: 0.5302 - acc: 0.6968 - val_loss: 1.0477 - val_acc: 0.5932\n",
      "Epoch 411/500\n",
      "46/46 - 0s - loss: 0.5315 - acc: 0.6992 - val_loss: 1.0583 - val_acc: 0.5767\n",
      "Epoch 412/500\n",
      "46/46 - 0s - loss: 0.5284 - acc: 0.6968 - val_loss: 1.0715 - val_acc: 0.5671\n",
      "Epoch 413/500\n",
      "46/46 - 0s - loss: 0.5323 - acc: 0.6972 - val_loss: 1.0522 - val_acc: 0.5904\n",
      "Epoch 414/500\n",
      "46/46 - 0s - loss: 0.5271 - acc: 0.7006 - val_loss: 1.0629 - val_acc: 0.5890\n",
      "Epoch 415/500\n",
      "46/46 - 0s - loss: 0.5273 - acc: 0.6954 - val_loss: 1.0691 - val_acc: 0.5740\n",
      "Epoch 416/500\n",
      "46/46 - 0s - loss: 0.5268 - acc: 0.7006 - val_loss: 1.0714 - val_acc: 0.5836\n",
      "Epoch 417/500\n",
      "46/46 - 0s - loss: 0.5238 - acc: 0.6920 - val_loss: 1.0675 - val_acc: 0.5740\n",
      "Epoch 418/500\n",
      "46/46 - 0s - loss: 0.5242 - acc: 0.6999 - val_loss: 1.0552 - val_acc: 0.5932\n",
      "Epoch 419/500\n",
      "46/46 - 0s - loss: 0.5244 - acc: 0.6982 - val_loss: 1.0739 - val_acc: 0.5699\n",
      "Epoch 420/500\n",
      "46/46 - 0s - loss: 0.5248 - acc: 0.6989 - val_loss: 1.0741 - val_acc: 0.5836\n",
      "Epoch 421/500\n",
      "46/46 - 0s - loss: 0.5251 - acc: 0.6906 - val_loss: 1.0787 - val_acc: 0.5877\n",
      "Epoch 422/500\n",
      "46/46 - 0s - loss: 0.5249 - acc: 0.6996 - val_loss: 1.0858 - val_acc: 0.5863\n",
      "Epoch 423/500\n",
      "46/46 - 0s - loss: 0.5237 - acc: 0.6930 - val_loss: 1.0579 - val_acc: 0.6027\n",
      "Epoch 424/500\n",
      "46/46 - 0s - loss: 0.5228 - acc: 0.6972 - val_loss: 1.0865 - val_acc: 0.5836\n",
      "Epoch 425/500\n",
      "46/46 - 0s - loss: 0.5212 - acc: 0.7016 - val_loss: 1.0936 - val_acc: 0.5849\n",
      "Epoch 426/500\n",
      "46/46 - 0s - loss: 0.5209 - acc: 0.6978 - val_loss: 1.0908 - val_acc: 0.5863\n",
      "Epoch 427/500\n",
      "46/46 - 0s - loss: 0.5205 - acc: 0.7016 - val_loss: 1.0762 - val_acc: 0.5877\n",
      "Epoch 428/500\n",
      "46/46 - 0s - loss: 0.5203 - acc: 0.6992 - val_loss: 1.0988 - val_acc: 0.5740\n",
      "Epoch 429/500\n",
      "46/46 - 0s - loss: 0.5193 - acc: 0.7054 - val_loss: 1.1022 - val_acc: 0.5849\n",
      "Epoch 430/500\n",
      "46/46 - 0s - loss: 0.5216 - acc: 0.7006 - val_loss: 1.1092 - val_acc: 0.6000\n",
      "Epoch 431/500\n",
      "46/46 - 0s - loss: 0.5204 - acc: 0.7085 - val_loss: 1.1000 - val_acc: 0.6000\n",
      "Epoch 432/500\n",
      "46/46 - 0s - loss: 0.5172 - acc: 0.7044 - val_loss: 1.1023 - val_acc: 0.5877\n",
      "Epoch 433/500\n",
      "46/46 - 0s - loss: 0.5161 - acc: 0.7078 - val_loss: 1.1068 - val_acc: 0.5767\n",
      "Epoch 434/500\n",
      "46/46 - 0s - loss: 0.5175 - acc: 0.7085 - val_loss: 1.1181 - val_acc: 0.5781\n",
      "Epoch 435/500\n",
      "46/46 - 0s - loss: 0.5178 - acc: 0.7074 - val_loss: 1.1052 - val_acc: 0.5822\n",
      "Epoch 436/500\n",
      "46/46 - 0s - loss: 0.5145 - acc: 0.7040 - val_loss: 1.1146 - val_acc: 0.5712\n",
      "Epoch 437/500\n",
      "46/46 - 0s - loss: 0.5150 - acc: 0.7095 - val_loss: 1.1033 - val_acc: 0.5822\n",
      "Epoch 438/500\n",
      "46/46 - 0s - loss: 0.5144 - acc: 0.7057 - val_loss: 1.1144 - val_acc: 0.5849\n",
      "Epoch 439/500\n",
      "46/46 - 0s - loss: 0.5152 - acc: 0.7040 - val_loss: 1.1290 - val_acc: 0.6014\n",
      "Epoch 440/500\n",
      "46/46 - 0s - loss: 0.5152 - acc: 0.7112 - val_loss: 1.1396 - val_acc: 0.5904\n",
      "Epoch 441/500\n",
      "46/46 - 0s - loss: 0.5149 - acc: 0.7088 - val_loss: 1.1465 - val_acc: 0.5849\n",
      "Epoch 442/500\n",
      "46/46 - 0s - loss: 0.5149 - acc: 0.7105 - val_loss: 1.1303 - val_acc: 0.5849\n",
      "Epoch 443/500\n",
      "46/46 - 0s - loss: 0.5115 - acc: 0.7139 - val_loss: 1.1326 - val_acc: 0.5863\n",
      "Epoch 444/500\n",
      "46/46 - 0s - loss: 0.5116 - acc: 0.7187 - val_loss: 1.1362 - val_acc: 0.5781\n",
      "Epoch 445/500\n",
      "46/46 - 0s - loss: 0.5127 - acc: 0.7133 - val_loss: 1.1659 - val_acc: 0.5712\n",
      "Epoch 446/500\n",
      "46/46 - 0s - loss: 0.5130 - acc: 0.7074 - val_loss: 1.1353 - val_acc: 0.5849\n",
      "Epoch 447/500\n",
      "46/46 - 0s - loss: 0.5111 - acc: 0.7078 - val_loss: 1.1387 - val_acc: 0.5863\n",
      "Epoch 448/500\n",
      "46/46 - 0s - loss: 0.5148 - acc: 0.7067 - val_loss: 1.1297 - val_acc: 0.5890\n",
      "Epoch 449/500\n",
      "46/46 - 0s - loss: 0.5105 - acc: 0.7136 - val_loss: 1.1546 - val_acc: 0.5808\n",
      "Epoch 450/500\n",
      "46/46 - 0s - loss: 0.5094 - acc: 0.7098 - val_loss: 1.1395 - val_acc: 0.5959\n",
      "Epoch 451/500\n",
      "46/46 - 0s - loss: 0.5075 - acc: 0.7181 - val_loss: 1.1396 - val_acc: 0.5808\n",
      "Epoch 452/500\n",
      "46/46 - 0s - loss: 0.5081 - acc: 0.7157 - val_loss: 1.1441 - val_acc: 0.5959\n",
      "Epoch 453/500\n",
      "46/46 - 0s - loss: 0.5084 - acc: 0.7078 - val_loss: 1.1528 - val_acc: 0.5986\n",
      "Epoch 454/500\n",
      "46/46 - 0s - loss: 0.5084 - acc: 0.7184 - val_loss: 1.1591 - val_acc: 0.5740\n",
      "Epoch 455/500\n",
      "46/46 - 0s - loss: 0.5074 - acc: 0.7133 - val_loss: 1.1536 - val_acc: 0.5918\n",
      "Epoch 456/500\n",
      "46/46 - 0s - loss: 0.5073 - acc: 0.7160 - val_loss: 1.1550 - val_acc: 0.5973\n",
      "Epoch 457/500\n",
      "46/46 - 0s - loss: 0.5092 - acc: 0.7129 - val_loss: 1.1843 - val_acc: 0.5849\n",
      "Epoch 458/500\n",
      "46/46 - 0s - loss: 0.5072 - acc: 0.7133 - val_loss: 1.1640 - val_acc: 0.5781\n",
      "Epoch 459/500\n",
      "46/46 - 0s - loss: 0.5040 - acc: 0.7167 - val_loss: 1.1804 - val_acc: 0.5890\n",
      "Epoch 460/500\n",
      "46/46 - 0s - loss: 0.5058 - acc: 0.7191 - val_loss: 1.1812 - val_acc: 0.5863\n",
      "Epoch 461/500\n",
      "46/46 - 0s - loss: 0.5058 - acc: 0.7160 - val_loss: 1.1701 - val_acc: 0.5795\n",
      "Epoch 462/500\n",
      "46/46 - 0s - loss: 0.5041 - acc: 0.7160 - val_loss: 1.1762 - val_acc: 0.5849\n",
      "Epoch 463/500\n",
      "46/46 - 0s - loss: 0.5046 - acc: 0.7174 - val_loss: 1.2005 - val_acc: 0.5890\n",
      "Epoch 464/500\n",
      "46/46 - 0s - loss: 0.5004 - acc: 0.7184 - val_loss: 1.2002 - val_acc: 0.5808\n",
      "Epoch 465/500\n",
      "46/46 - 0s - loss: 0.5047 - acc: 0.7095 - val_loss: 1.1954 - val_acc: 0.5781\n",
      "Epoch 466/500\n",
      "46/46 - 0s - loss: 0.5000 - acc: 0.7187 - val_loss: 1.2058 - val_acc: 0.5836\n",
      "Epoch 467/500\n",
      "46/46 - 0s - loss: 0.5005 - acc: 0.7198 - val_loss: 1.1989 - val_acc: 0.5904\n",
      "Epoch 468/500\n",
      "46/46 - 0s - loss: 0.5002 - acc: 0.7181 - val_loss: 1.1993 - val_acc: 0.5877\n",
      "Epoch 469/500\n",
      "46/46 - 0s - loss: 0.4999 - acc: 0.7153 - val_loss: 1.2090 - val_acc: 0.5767\n",
      "Epoch 470/500\n",
      "46/46 - 0s - loss: 0.5005 - acc: 0.7205 - val_loss: 1.1948 - val_acc: 0.5808\n",
      "Epoch 471/500\n",
      "46/46 - 0s - loss: 0.5013 - acc: 0.7276 - val_loss: 1.2113 - val_acc: 0.5699\n",
      "Epoch 472/500\n",
      "46/46 - 0s - loss: 0.4999 - acc: 0.7201 - val_loss: 1.2196 - val_acc: 0.5877\n",
      "Epoch 473/500\n",
      "46/46 - 0s - loss: 0.4986 - acc: 0.7218 - val_loss: 1.2157 - val_acc: 0.5753\n",
      "Epoch 474/500\n",
      "46/46 - 0s - loss: 0.4979 - acc: 0.7181 - val_loss: 1.2361 - val_acc: 0.5712\n",
      "Epoch 475/500\n",
      "46/46 - 0s - loss: 0.4967 - acc: 0.7211 - val_loss: 1.2307 - val_acc: 0.5795\n",
      "Epoch 476/500\n",
      "46/46 - 0s - loss: 0.4986 - acc: 0.7174 - val_loss: 1.2195 - val_acc: 0.5849\n",
      "Epoch 477/500\n",
      "46/46 - 0s - loss: 0.4970 - acc: 0.7091 - val_loss: 1.2365 - val_acc: 0.5658\n",
      "Epoch 478/500\n",
      "46/46 - 0s - loss: 0.4965 - acc: 0.7283 - val_loss: 1.2522 - val_acc: 0.5699\n",
      "Epoch 479/500\n",
      "46/46 - 0s - loss: 0.4970 - acc: 0.7208 - val_loss: 1.2260 - val_acc: 0.5808\n",
      "Epoch 480/500\n",
      "46/46 - 0s - loss: 0.4944 - acc: 0.7187 - val_loss: 1.2395 - val_acc: 0.5904\n",
      "Epoch 481/500\n",
      "46/46 - 0s - loss: 0.4975 - acc: 0.7232 - val_loss: 1.2236 - val_acc: 0.5685\n",
      "Epoch 482/500\n",
      "46/46 - 0s - loss: 0.4970 - acc: 0.7280 - val_loss: 1.2572 - val_acc: 0.5822\n",
      "Epoch 483/500\n",
      "46/46 - 0s - loss: 0.4975 - acc: 0.7201 - val_loss: 1.2244 - val_acc: 0.5740\n",
      "Epoch 484/500\n",
      "46/46 - 0s - loss: 0.4988 - acc: 0.7194 - val_loss: 1.2425 - val_acc: 0.5658\n",
      "Epoch 485/500\n",
      "46/46 - 0s - loss: 0.4941 - acc: 0.7266 - val_loss: 1.2372 - val_acc: 0.5781\n",
      "Epoch 486/500\n",
      "46/46 - 0s - loss: 0.4916 - acc: 0.7294 - val_loss: 1.2340 - val_acc: 0.5740\n",
      "Epoch 487/500\n",
      "46/46 - 0s - loss: 0.4937 - acc: 0.7235 - val_loss: 1.2307 - val_acc: 0.5795\n",
      "Epoch 488/500\n",
      "46/46 - 0s - loss: 0.4937 - acc: 0.7259 - val_loss: 1.2427 - val_acc: 0.5808\n",
      "Epoch 489/500\n",
      "46/46 - 0s - loss: 0.4945 - acc: 0.7235 - val_loss: 1.2744 - val_acc: 0.5671\n",
      "Epoch 490/500\n",
      "46/46 - 0s - loss: 0.4977 - acc: 0.7129 - val_loss: 1.2417 - val_acc: 0.5849\n",
      "Epoch 491/500\n",
      "46/46 - 0s - loss: 0.4909 - acc: 0.7273 - val_loss: 1.2537 - val_acc: 0.5781\n",
      "Epoch 492/500\n",
      "46/46 - 0s - loss: 0.4925 - acc: 0.7205 - val_loss: 1.2691 - val_acc: 0.5795\n",
      "Epoch 493/500\n",
      "46/46 - 0s - loss: 0.4901 - acc: 0.7280 - val_loss: 1.2455 - val_acc: 0.5740\n",
      "Epoch 494/500\n",
      "46/46 - 0s - loss: 0.4904 - acc: 0.7273 - val_loss: 1.2625 - val_acc: 0.5836\n",
      "Epoch 495/500\n",
      "46/46 - 0s - loss: 0.4948 - acc: 0.7290 - val_loss: 1.2561 - val_acc: 0.5740\n",
      "Epoch 496/500\n",
      "46/46 - 0s - loss: 0.5005 - acc: 0.7256 - val_loss: 1.2874 - val_acc: 0.5863\n",
      "Epoch 497/500\n",
      "46/46 - 0s - loss: 0.4935 - acc: 0.7270 - val_loss: 1.2783 - val_acc: 0.5753\n",
      "Epoch 498/500\n",
      "46/46 - 0s - loss: 0.4883 - acc: 0.7311 - val_loss: 1.2756 - val_acc: 0.5808\n",
      "Epoch 499/500\n",
      "46/46 - 0s - loss: 0.4881 - acc: 0.7270 - val_loss: 1.2678 - val_acc: 0.5767\n",
      "Epoch 500/500\n",
      "46/46 - 0s - loss: 0.4863 - acc: 0.7297 - val_loss: 1.2967 - val_acc: 0.5904\n"
     ]
    }
   ],
   "source": [
    "hist_rnn2 = rnn2.fit(train_sequences,validation_data=test_sequences,\n",
    "                  epochs=500,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "52d9fcd6-cc1f-44b4-8754-f87d028bc625",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:07:49.098951Z",
     "iopub.status.busy": "2021-08-27T04:07:49.098815Z",
     "iopub.status.idle": "2021-08-27T04:07:49.193718Z",
     "shell.execute_reply": "2021-08-27T04:07:49.192874Z",
     "shell.execute_reply.started": "2021-08-27T04:07:49.098934Z"
    },
    "id": "52d9fcd6-cc1f-44b4-8754-f87d028bc625",
    "outputId": "217d4447-7330-4a3f-e832-35193d9457db"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABUNklEQVR4nO2dd3gc1dWH36tV781d7r133DAu4AI2LRAwLZSAMT0QICaEkhAIoePQQw3VfIDB9GpjGxt3ufcuVxWrd+39/rgzu7Ozu9LKqK7v+zx6dnfmzuy9I+k3Z8499xwhpUSj0Wg0wUtIY3dAo9FoNPWLFnqNRqMJcrTQazQaTZCjhV6j0WiCHC30Go1GE+SENnYHfJGamio7derU2N3QaDSaZsPq1auzpJQtfO1rkkLfqVMnVq1a1djd0Gg0mmaDEGKfv33adaPRaDRBjhZ6jUajCXK00Gs0Gk2Q0yR99L6oqKggIyOD0tLSxu6KpgYiIyNJS0sjLCyssbui0WhoRkKfkZFBXFwcnTp1QgjR2N3R+EFKSXZ2NhkZGXTu3Lmxu6PRaGhGrpvS0lJSUlK0yDdxhBCkpKToJy+NpgnRbIQe0CLfTNC/J42madGshF6j0WiCkRV7cth0KK/ezq+FPgCys7MZNGgQgwYNonXr1rRr1871uby8vNpjV61axa233tpAPdVoNE2VkvIq/NX/uOjlZUybs4TP1x2iyln3NUKazWRsY5KSkkJ6ejoADz74ILGxsdx5552u/ZWVlYSG+r6Uw4YNY9iwYQ3RzVpTXb81Gs2JszuzkLaJUUSGOQDYk1XEhCcWMueSwZwzsC2gAhfe/nUf6ftzXcc9/OUWpg9oU+f90Rb9CXLVVVdxxx13MGHCBP7yl7+wYsUKRo8ezeDBgxk9ejTbtm0DYOHChUyfPh1QN4lrrrmG8ePH06VLF+bMmePz3DfccAPDhg2jb9++PPDAA67tK1euZPTo0QwcOJBTTjmFgoICqqqquPPOO+nfvz8DBgzgP//5D6DSSGRlZQHqqWL8+PGuPsycOZPJkyfzhz/8gb179zJ27FiGDBnCkCFDWLp0qev7HnvsMfr378/AgQOZPXs2u3btYsiQIa79O3bsYOjQoXV3UTWaZkh2YRm3z02noLQCgMoqJxOf/Jkb3lnNa0v2cOGLS/lp6zEAFhiv32w8zJRnFnH/Z5v4ZO1B17m6t4qtlzmuZmnO/f3zTWw+lF+n5+zTNp4Hzu5bq2O2b9/ODz/8gMPhID8/n0WLFhEaGsoPP/zAX//6Vz7++GOvY7Zu3cqCBQsoKCigZ8+e3HDDDV7x5g8//DDJyclUVVVx+umns379enr16sXFF1/M3LlzGT58OPn5+URFRfHKK6+wZ88e1q5dS2hoKDk5OTX2e/Xq1SxZsoSoqCiKi4v5/vvviYyMZMeOHVxyySWsWrWKr7/+mk8//ZTly5cTHR1NTk4OycnJJCQkkJ6ezqBBg3jjjTe46qqranXNNJpg4/kFu5i39iAD0xK4akxniiuqAFiwLRMJrN5/nMTocAC2HSlgfUYus95Z4/Nck/q0qpc+Nkuhbyr8/ve/x+FQj2Z5eXlceeWV7NixAyEEFRUVPo+ZNm0aERERRERE0LJlS44ePUpaWppHmw8//JBXXnmFyspKDh8+zObNmxFC0KZNG4YPHw5AfHw8AD/88AOzZs1yuWCSk5Nr7Pc555xDVFQUoBai3XzzzaSnp+NwONi+fbvrvFdffTXR0dEe57322mt54403eOqpp5g7dy4rVqyo1TXTaIKN8iol7KZrvbS8yrVvx9FCpITV+5QBtvlwPuc894tr/7WndubVJXvo1jKWZ2cMok+b+HrpY7MU+tpa3vVFTEyM6/19993HhAkTmDdvHnv37nW5SuxERES43jscDiorKz3279mzhyeeeIKVK1eSlJTEVVddRWlpKVJKn490/raHhobidDoBvGLarf1++umnadWqFevWrcPpdBIZGVnteS+44AL+/ve/M3HiRIYOHUpKSorPcWo0Jwvm/GqJYcmbrwAHc0sAOF7s2/Dr2y6e964dQd92CSRE1d9Kcu2jryPy8vJo164dAG+++eYJnyc/P5+YmBgSEhI4evQoX3/9NQC9evXi0KFDrFy5EoCCggIqKyuZPHkyL730kuuGYbpuOnXqxOrVqwF8upCs/W7Tpg0hISG8/fbbVBnWyeTJk3n99dcpLi72OG9kZCRTpkzhhhtu4Oqrrz7hcWo0wUJuiRLxI3nKoLIKvZXEaG8hbxUXyehuqfUq8qCFvs64++67ueeeexgzZoxLLE+EgQMHMnjwYPr27cs111zDmDFjAAgPD2fu3LnccsstDBw4kEmTJlFaWsq1115Lhw4dGDBgAAMHDuS9994D4IEHHuC2225j7NixLveSL2688UbeeustRo4cyfbt213W/tSpUznnnHMYNmwYgwYN4oknnnAdc9lllyGEYPLkySc8To0mWDhqCPzbv+7jjg/TWb3vuM92957Vm09uHO2xrWV8ZL33D0D4i+tsTIYNGybthUe2bNlC7969G6lHGitPPPEEeXl5PPTQQ37b6N+XJtjZnVlIlVNy9ZsryTheUmP7t/94Cu0So5j45M+ubesfnEx8ZN1Y80KI1VJKn7HczdJHr2k8zj//fHbt2sVPP/3U2F3RaOqERdszEQLGdveswpdTVE5RWSXtk6NxOiXXv7Oai4e155QuyWzIyOOyV5e72rZNiORQnu/8Tu2ToziQU0JaUrSHi+aBs/vUmcjXhBZ6Ta2YN29eY3dBo6lT/vC6ihzb++g0AN5fsZ97PtlATLiDovIq9j46jbUHjvP95qN8v/moz3PcNbUnX6w7zI9GnDzAyC7JnNotlWvHdiH9QC6dU2OorHK69l9ySod6HJUn2kev0WhOWqzpBkw39hu/7AGgyAiT/Hl7Jt/5EXiTTikxPHnRQG6e0M217fELB3LzxO5EhjkY2UVFp4U63JIbEdpw8quFXqPRnLQctPjW84zoma4tYj3aXPn6CuatOYgvHCEqBLlzagyJ0eFcPLy9a5+Z/sAfDZnlVbtuNBrNScvOzALX+/05xRwrKGPR9kyvdscKyph5WhdmntaF9P25XPs/FSzyxS2nsnBbpmvla4s49zqZqPDqhb4h0UKv0WhOWjZkuFOp7Msu5pb31/ptO6JzMqmxER5i3rtNPL0tq1mtVnxkA7pmakILfQBkZ2dz+umnA3DkyBEcDgctWqgZ+hUrVhAeHl7t8QsXLiQ8PJzRo0dX206j0TQMVU7JO7/u45edWaQlRZFxvIT9OcVe7aYNaMOZ/VpTXF7FxF4tAUiJrf7/3cTqj7fy0axRFJRV+txXX2ihD4Ca0hTXxMKFC4mNjW10oa+qqqp28ZRGczJQUFrB2v25PDB/EwAzhrfnhy3H2J/tLfTDOiYxfUBbj20pMRFe7WrDsE4156Oqa5rOs0UzY/Xq1YwbN46hQ4cyZcoUDh8+DMCcOXPo06cPAwYMYMaMGezdu5eXXnqJp59+mkGDBrF48WKP8/hLb+wv/bCvVMVvvvkmN998s+uc06dPZ+HChQDExsZy//33M2LECJYtW8Y//vEPhg8fTr9+/Zg5c6Yr0mDnzp2cccYZDBw4kCFDhrBr1y6uuOIKPvvsM9d5L7vsMubPn19v11SjqQ+OFZRyIKeYnccKOJhbQv8Hv+Puj9a79p/Vvw0dkqPYaKnwZKYr8FUExPS9966nBGT1QfO06L+eDUc21O05W/eHMx8NqKmUkltuuYXPPvuMFi1aMHfuXO69915ef/11Hn30Ufbs2UNERAS5ubkkJiYya9Ysv08BvXr18pne2Ff64fLycp+piqujqKiIfv368Y9//AOAPn36cP/99wNwxRVX8MUXX3D22Wdz2WWXMXv2bM4//3xKS0txOp1ce+21PP3005x77rnk5eWxdOlS3nrrrVpeWI2mcRn/+EKKyz3TkhzJV4ubRnVJYWz3VD5ek8Fn6YcAeO7SwWw5nM/zC3b5PecPd4zz8NVb+fSmMRzw4QZqTJqn0DcyZWVlbNy4kUmTJgHK+m7TRlWFGTBgAJdddhnnnXce5513Xo3n8pfe2Ff64Q0bNvhMVVwdDoeDCy64wPV5wYIFPPbYYxQXF5OTk0Pfvn0ZP348Bw8e5PzzzwdwZbAcN24cN910E8eOHeOTTz7hggsu0BWpNM0Ou8ibRISG8N51IxBCcGq3VJfQt0mI4rQeLTheXMEMP4uaurWM9bkdYFD7RAa1T/zN/a5Lmud/bYCWd30hpaRv374sW7bMa9+XX37JokWLmD9/Pg899BCbNm2q9lz+0hv7ShMcSEpi8ExLHBkZ6fLLl5aWcuONN7Jq1Srat2/Pgw8+6EqB7I8rrriCd999lw8++IDXX3+92rFoNE2Nv33qfvKPCnN4ZJasqHK6/p9+P6w9k/q04uM1BxnUPhFHiOCR8/s3eH/rC+2jPwEiIiLIzMx0CX1FRQWbNm3C6XRy4MABJkyYwGOPPUZubi6FhYXExcVRUFDg81z+0hv7Sj/sL1Vxp06dSE9Pd32/v2Ig5g0gNTWVwsJCPvroI0A9GaSlpfHpp58C6onFTE981VVX8cwzzwDQt2/TqAOg0QSC0yl559f9rs+junrWTrC73xOjw/njqZ1di6CCiYCEXggxVQixTQixUwgx28f+u4QQ6cbPRiFElRAiOZBjmyMhISF89NFH/OUvf2HgwIEMGjSIpUuXUlVVxeWXX07//v0ZPHgwt99+O4mJiZx99tnMmzfP52Ssv/TGvtIP+0tVPGbMGDp37kz//v258847Peq6WklMTOS6666jf//+nHfeeS4XEMDbb7/NnDlzGDBgAKNHj+bIkSMAtGrVit69e+vc85pmx7GCMtf7kV2SefqiQbxyxVBmn9mLv03rzbMzBjVe5xqYGtMUCyEcwHZgEpABrAQukVJu9tP+bOB2KeXE2h5rotMUNx2Ki4vp378/a9asISEhIeDj9O9L01jszizk3nkbWbk3h0rDbH/y9wO5YGhaDUc2b6pLUxyIRX8KsFNKuVtKWQ58AJxbTftLgPdP8FhNE+KHH36gV69e3HLLLbUSeY0mUHZlFrLxYF61bY7ll7J0V5bHtpLyKnr+7Ws6zf6Sy19dzq+7swHILS7nsW+2sWx3tkvkAaKbUDqCxiCQydh2wAHL5wxghK+GQohoYCpgBnXX5tiZwEyADh0aLn2nxj9nnHEG+/fvr7mhRnOCnG4U4TBTBPviopeXsTe7mFsmdqOs0klmQRnlVU7KKlUAwpKdWSzZmcUpnZJZsTfH6/h/nNuXKX1b188AmgmBCL2vmQl//p6zgV+klObVDvhYKeUrwCugXDd+2jRoxjfNidEUq5Zpmg/PL9hJi9gILjIyQe41Vqz+56ed1R7nS+QfPr8fl43oWPedbGYEIvQZQHvL5zTgkJ+2M3C7bWp7bLVERkaSnZ1NSkqKFvsmjJSS7OxsVyy+RhMIUkqqnJKySiePf6tWh180vH0NR/mnXWIUd0zqEfR++UAJROhXAt2FEJ2Bgygxv9TeSAiRAIwDLq/tsYGQlpZGRkYGmZneKUQ1TYvIyEjS0vQ/2MnO/HWHaJMQyfAAcruUVFTxyFdbPMIhX128m/xS7+RfnVNjuGJkR55fsJPsonIAhnRIZM3+XFebO6f04PzB+m/QpEahl1JWCiFuBr4FHMDrUspNQohZxv6XjKbnA99JKYtqOvZEOhoWFkbnzp1P5FCNRtPAHM4r4VYj5a/d/55fWoGUEBvhlp/c4gq+WH/Yo90/v9zi89xnD2zLNad2ZlKfVlz40lKO5pfRJiEKyHW16dmq+eShaQgCWhkrpfwK+Mq27SXb5zeBNwM5VqPRBC8VVU4u++9yn/tW7zvOXz5ez85jhTxz8SDX9q82HCYxKozQEEFWYblr++Q+rVi97zj90xK4ZkxnisurOLV7KgDtk6OZeVpXHvpiM8kx7tTBoSGCri1j6mdwzZTmmQJBo9E0WbIKy9id5Xqwp6iskpiIUHYcLeCCF5e6tv9pbrrrvWm9zzytC91bxnKXkV3yhcuG+M3rDsoXD9CjlTv3zLMzBhMRenKHU9rRKRA0Gk2dkVdcwdF8tSL1vEEqj/vOY4Ucyy/l3eU1h+q2jo8kPkqlCG6fHFWtyANM6duKd68d4RFZM21AmxPtftCiLXqNRnNCPPzlZg7mlvDURYOIDHOwam8OF728zJVDpl+7BD5NP8Sf5qazJ6uInq3iXMf2bBXHtqPe+Z8iwxz0b6cW5/3zvJqTigkhGNNNuXLm3zyGsBpuDCcrWug1Gs0J8d/FewAY0y2D1NgIrn97tcf+ri2UO2WP4caxCnvfdvGuz/ee1ZthnZJ47JttnNG7JS3jI6tdQOWPAWmJJzKMkwIt9BqN5oRIjgknp6ice+dt9Lm/Swv/E6KdU9z7rjutCwDvzxxZtx3UuNBCr9FoAmZ/djE7jhWQXVjO8eLyatu2incvmouPDPWIiY+LDOWNq4fTMTm63vqqcaOFXqPRAPDNxiPMemc1S2dPpK0RzXIwt4RWcRGuSdHTHl/gcczAtATWZfhOShYZ5o58efriQbywcBdH8ko5mFtCXGQYE3q2rKeRaOzomQuNRgPAh6tU/sENRjbJAznFjHn0J176WdVOzSnytuDHW8T6o1mjuHlCN5/nHpCWyMc3jHaV4IuN1DZmQ6KFXqPRAGqhEeDKCrl8j0oSln4gj4O5JQx56HuvY0Z2UVWb+raNZ1inZO6c0pNRXVJIjA7zaJdiLGgy01Q5dL6qBkXfVjWak5TSiip+2ZnFVxuO8MA5fQgLVXZfdmEZQx763mXBR4SF8PT3232eo21iJF/fNpbWFn+8WXAbYHinJFbuPU6IcRMJMbbr/KYNixZ6jeYk5d/fbOWNX/YCRmEOQ33TD+R6uGm+NHLQDO2YhCNEsGJPDi3iIrhrSk86JEd7ZZO1fn7n2hGUV7oL1/9hVEd+2nqMAWm6kE1DooVeoznJKC6v5G/zNvLJ2oMAdG0Rwy+7slxW+Tcbj/g8bky3VAa0S2DFnhxuGNeVi4bVnEY4ItThkY5gfM+WJxQjr/ltaKHXaE4ivlx/mL99uoHjxRUAjOvRgkHtE3n2xx3szlQLm8osFriVEZ2TGd01hbf/eApjuqY2WJ81vx0t9BrNScRN763x+JwSE06v1nF+WruZc8lgV6qBsd1b1EvfNPWHFnqNJghxOiXvLN/Hsl3ZtEuM4tTuqR6+cpPkmHBGdkmhd5t4thzOd23vlBLNwrsmcOq/fyLjeAkjO9dcPETTdNFCr9EEGRnHi7l9bjor9x53bXt1yR7X+98PTSMq3MH/lu0jLjKMpJhwvr5tLMXllTz85RbeXb6fuEgVHvnalcP5csNhWsRFNPg4NHWHjqPXaIKAzYfyyS5U6YEfnL/ZQ+SttEuM4q9n9SYxWsW1V1kKuUeHh5JgpAiOMxY09Wwdxx2Teug6zc0cbdFrNM2YOT/uoG1iFHf+3zoAfr3ndMJD3aKcfv8k4iLD2HakgMU7Mrl+XFcAooz0BCE2/TYteYd9h6ZZo4Veo2mmLN2ZxVO2hUxzftrhstYB1/s+bePp09ZdR/WKUR3Zl13E1WM86zDHR2lJCEb0b1WjaYbsPFbIpa961mXt0yae95bvD8gaj40I5dELBnhtNy16TXChffQaTRNGSsm8tRmUVlR5bN9siZAxuWtKTwCqjBJP143t7NWmJuIitO0XjGih12iaMGv253L73HUuH7yUkteW7OHdX/d5tBMCJvRqyTWGK6Z3m3jundan1t8Xon3zQYkWeo2mCZNfolawfrH+MAWlFUybs4SHvtjsyixpYtZjHdYpCYDCsooT+r4wQ+itueQ1zR8t9BpNE2PbkQI6zf6SHUcLPKo4vfnLXg+XzfQBbUiKDuPykR14+48jAEhLUgVDCizVnGrDiC4pXD+uCw+f1+83jEDT1NAOOY2miTF3pSoA8s3GI0RbfOZPGhE2a+6bRGFpJR1SvMvwtTMqQxWeoNA7QgT3nNn7hI7VNF200Gs0TYxcw4r/36/7yCxQi6DOGdiW+esOERcRSnJMOMkx4T6PTY4JZ3TXFK4a3amhuqtpBmih12gaGCkl89cdokVsBKO7pVJYVklMuIP7PtvIZ+mHXG4XU+QB7pjUg+1HC1wVnfwhhOC960bWa/81zQ8t9BpNA7PxYD63fZAOwMc3jOKCF5fxr9/1551f97vaRIc7KC53h1R2So3hmz+d1tBd1QQJejJWo2kAzn3+F65/exUAuzILXduvfmMlAI98tcW1rX1yFPec2YvBHRIbtI+a4EULvUbTAKw7kMu3m47idEp2Z6kCH+GOEPINN401SkYguGJUJ+bdOAbQi5g0vx39F6TR1BE7jhbQtUWs16Ijc6UqwKSnf2ZXZhGpsREkRIWyy6jq5I8Vfz2dMIe2xzS/jYD+goQQU4UQ24QQO4UQs/20GS+ESBdCbBJC/GzZvlcIscHYt6quOq7RNBUW78jk5+2ZTHp6ES8v2k1+aQWd7/mS+esO8Vn6QbKL3JOqprAP75TkyvFupgY26dYy1vW+ZXwkSX4ibDSaQKnRohdCOIDngUlABrBSCDFfSrnZ0iYReAGYKqXcL4RoaTvNBCllVt11W6NpGhSVVXLFaytcn5fvyWZYpySkhFvfXwu4c9A8f+kQQC1q6tYy1lXWb9qANry3XE3EvnDZEEZ3rT6yRqOpLYFY9KcAO6WUu6WU5cAHwLm2NpcCn0gp9wNIKY/VbTc1msbhQE4xX64/7Hf/1iMFHp+dEvZlF3ts+3HLUQBSYsOZNqANA9snEhMRiungOaWTKtN3zsC2nNW/jUeaYY2mLgjER98OOGD5nAGMsLXpAYQJIRYCccCzUsr/Gfsk8J0QQgIvSylf8fUlQoiZwEyADh06BDwAjea3siEjj4SoMJ8rTX/34lIyC8o4o89UIkLd+V++23SESqckp6jco73TKdmTVeixbc3+XABSYz3L8ZlVmyLDQtj60FTti9fUG4H8ZflKZydtn0OBocA0YApwnxCih7FvjJRyCHAmcJMQwmcwsJTyFSnlMCnlsBYtdJV5Tf2x8WAeFVWqULaUkrOfW8Kkp3/2aLPtSAEXGCIP6mZwIEdZ6rnF5cx8ezU3vruGbzYe8TiuoKyS3ZlFtEuMYtFdEzz2tYz3FPqBaYkAtE6IIjLMoas6aeqNQIQ+A2hv+ZwGHPLR5hspZZHhi18EDASQUh4yXo8B81CuII2mUdifXcz0/yzh4S9V3Lo5OVpW6SSnqJz3lu+nosrJy4t2sXqfu+7qhS8tY+xjCwBV9MNkyU7Pqad1B3L5euMRhnVK8nhC+N81pxBvK+px88RuzLtxNIPaJ9bpGDUaO4EI/UqguxCisxAiHJgBzLe1+QwYK4QIFUJEo1w7W4QQMUKIOAAhRAwwGdhYd93XaGrm759v4rFvtgKQY+SRWbQjE4BVe1W639iIUD5afYC/ztvAfZ9u9HKzWLEKPeBTqMd0TQWgQ7IS+9N6eD+lOkIEgzsk1XI0Gk3tqdFHL6WsFELcDHwLOIDXpZSbhBCzjP0vSSm3CCG+AdYDTuBVKeVGIUQXYJ7hiwwF3pNSflNfg9FofPHF+sO0jo+kR6uDHCsoBWB3ZhFLd2VxMLcEgMToMA7kqPe/7s5mmDFBGu4Iodxw8wDsySris3TPB9oOydGkH8jlylEduWJUR/755Ram9G0NwOe3nEpZpWd1KI2moRFS2t3tjc+wYcPkqlU65F7z2zleVM7gh74nOSbca+IUoFNKNHuzi0mMDqN/uwQW78hCCBjSIYmKKifzbhzDxCcXuiJpEqPDyC2uYErfVny7SUXTPHbhAO7+aD1f3HIq/dolNOj4NBoTIcRqKeUwX/v0NL+m2bLpUB7/XbQbgJ+2HmXanMVetVW3H1Xhj75EHmCvIeD5JRXsyy4mIjQEKWH1vuO0jo/EESL47KYxPGQU4sgtruDykR146fKhrnNcOCSNlfeeoUVe02TRQq9pttz6/loe/moL+7KLeG3JHjYdymfe2oOs3neca99aRVFZpUvo7Tx8fj8m9Wnl+uyUsD+nmAuHppEaq+LYzZWridHhtIpz++wvGtbeFRoJqs5qizj/Pn2NprHRuW40zZak6HCgiHGPL+SM3kq0n/tpJ60TIlm97zivLdnj8slbSUuK4rIRHTmaX8b3m4967BvYPpFZ47ry1tK9nDOorWu7tdBH7zbxAHx/+2m6tqqmWRC8Qn90E7xxJlwxD9oNrbm9psGocsrfFDMupUQI4VFm78etSrAP5ZW4Jlh/2nqM8NAQHCHCI7FYrHFc1xYxXufumBxN++Ro/ja9j8d262pVc2FTd6Mgt0bT1Aku182htfDvzvDccPj531CaB/Nm1f48VRXw39Nh549138eTjN+98AtjHv3J9fnZH3bQ676vKTGKaqzel8O6A7k+jz1WUMpn6QcBdXPIOF7MI19tofM9X3H+C7+waHsmY7qlEOYQSAkD0xJ4+fKhDO6QSPeWsazPyGXLoXz6tlUWuOltOX9wOwC6pMZ6fWenVG/xB/dip1sndqv9RdBoGpngsugXPQElOeonSxVSJms7lBVChO2fOmsHLHgY+l0IS56CU++A6BRY9z6MuhkOroLPboI/b234cQQR5vJ/gPJKJ0//oH4vB3NL6NYylgteXAbA9ad14fZJPTxcITe+s4ZV+44zumsqc1fu54nvtrv2rTXO2zIukq4tYtl6pID4qDAm923N5L6t+XDVAe7+aD0FZZXcNaUnpRVORnZJZumubCYZbp5uLWOJCnNw77Te/O3Tjcb5fPva4yPD2PDgZNfTgEbTnAiuv9ow71wlAOxdAj2nqvdr/geRifDLs0rMj22BzK1K4Ld+odp0O0O9VpXDl3+G8X+FmN+YUXDZ89B2CHQc9dvO00TIOF7Mwm2ZXD6yY62OMTmcV+KRjvflRbspr3Jy//Q+3Pz+WnYdK3QlDMs4XszKvce9zgcQHxlKz9ZxLqE3GdE5mZhwB9eO7cLY7u7FSmZ8O0BUuIMtD6m/i4jQEHYeK/SYZLUTZ1vZqtE0F4JM6CN9bz+6EXpMUWL73b2e+zINi/3IBs/2AMXZsPJVSOkGI2848X5JCd/+Vb1/MO/Ez9OE+MPrK9idWcTZA9qSEO0WwJ+2HqV3m3jaJER5HXPgeInr/eE870nSD1Yc4NRuqV7ZIpfvySHR8h1CwCWndOC95fspKq9idOg28kJ2EhWW5mrTMSWGDQ9O8SoC4o/fD2tfcyONppkSXD76UG9xISoJ1n+o3Dp2kbeSu8/9/ugmz327fuI3UZbvf5/TCenvq3mBJkpFlRP7wrqDhmjnl7r7XVZZxTVvruLS/y73OoeUkv05Fos+txSn0/OcJRVVvLp4D+GOEA8XyaNfb/VYjXrHGT1cKQbySiq4eOP1vBn+OPklntcwUJHXaIKd4BL6MB9CH98OsrbBgn/6Py4i3vOz6cIx2fkjrHkbcvfX3IeKEtj7i+e2wmrS82/6BD6dBUueqfncJ0J5Mexb5rV5b1YRF7+8zEOofbH1SD7d7/2a+z/zvPmZUSx5hrg+9f12Hv9mG6DSBAAeQn7Nmys5kFNMeGgIyTHhHMkv8aiTmhgdRntxlLyDW0lLjmJiL3vtGmiXqH6/wzsnM6FXCyb2aslfpvZy7c8tbro3S42mMQl+oQ/xEef8l73KhZJg5L1v3d+7TZ/z1GtCB5BVMP9meOMs2PEDVBql4XIPqMgeK5/fBm+epfY5nWoOoDqhLzF8zwX2hKB1xOe3wRtTIS/DY/Pj321j+Z4cFmz137dVe3OY+sxiAN7+dZ/HvkpDxHOLK3hw/ibm/LiDV5fsAZS/G6Cw3C3kC7ZlsnxPjit8cVdmEQP/8Z1rf0pMOIsjbucrcRvtEqOYNa4r4I5ZB1WJads/pzKySwrR4aG8ftVwDz//2O6p3oNwVkHmNv/XR6M5CQguoQ+1+eg7jYViyyTeqbfD3zKVOwcgxhCGFj29zzXhr3DnDrjBsM4d4ZB/EN69AD7+IxTnwDP94JXxnscdMNwW5YUqqueFkbBvqXt/mW2lpjn5V5yjbhrlntWJKM6BnN2+x1tZ7n2jsWPMN2zYsYdXF+9my2HlRjJdMXuy1KpSOwdzS7jydXeJvMgw95/KYiPzI8DKvTm8uXSvx7HR4ermunx3jsf2dQdyGdejBT1axrJij+c+68rStKRo+rSNZ8W9p/PFLafy3KWDGdklmSl9W3kU/wA8XF43TvAR+vjj3+H5UyDHe4wazclCcAm9lbv3wGUfQadT3dvaDIRQS5m2UTep19YDvI+PTIDYlhAZD3/eBn89DLeuhZE3wpbP4bHOqp1dhE1rv6wANn6s3mdaQjQf66IE2kQYv4LNn8KjHZQoWXlhJMwZDMd8hHm+93t1jB2rP92hxvvAx6v455dbOPNZZaE7jYSMz/ywg4e+2OzlwnljyR6Kyt15Y0ornDz+reqDtUbqd7aVpaAqJz385Wau+593YrqJvVvSs7X3QqOHzu3nep+WpJ7MWsapXDPTB7Tlg5mjGNox2fMgpxOK3Dcdn4uwtn2tXs0bbBNM4qfR1DfBJfTSktAqOllF4Ux/Cm5aATN/drtjTPpfCNcvgsFXeJ/L6rePaw2OUEjqBJ3HVd+HSiOapDTP7S45tsW9v6pc+eVNhO1XkGdUbSw4Cg8mQKEhpL5cO7sXAp6+cIpz4O+JsOp1/vPjDrZlqRtPgihyd8EpqbIJ3uFczygYX7775xfsYtH2TI9t5hOClZyicv672LcF3aNVHD1sK0q/unWsxyrTjj5K+nlxfC/8I0lFRVWH6RqrqoCtX6lrk72r5vNrNEFEcAm900fe77Ao5ZppO8jtJrHSZqAScV/H+cK+8Argzenu96ZFX3AYnIZYHtuk0jDMeB/CYiDDYuk63X5sDzJtFnyp/8idC178BSklTqdk23o18epM/4Anv99OdqkacyLuYhnbjxZ4Rbwcyi1h1d4cbn/hY3gwAXF4HcM7JbH1oalMH9DG1W75nmy//bDTr12817aUmHDGdEvlofP6uVaZtknwdLkN7pAEn94I/53o/+S7jdJ/q95wb/MVuVSSq14ritVaCYCDawIdgkYTFAS/0J8o/hbOhPsQ+r2L3d9tWvSLn/Js02Mq9DoLZ6t+lB9a795e4R1PrraXeH42XQ/LnocPr4Sv7nbt2nQgi0e/2cpj327j+flqTmF1trp5laPizxOFW+hzVn3ELYfuJhT3TebqN1fyxtK9xB9UAvrv7Fu4nC+JfGsqnZ3u2vDPL1DW8GMXDiA2IpTrHF/wddpbPH/pEECtNu2QHM3147rw7rUjmWa5SYBy6zhCBFeM7Mgdk3uy99FpJFkShgG0TYiE9Hfh4GrPa1CcA/8ZBkc3u598rL8P+zUD9822wjL3Uennmms0QUpwLZjyZx0Hwh/mQ3EWfHRN9e0i/CSyytkNh9eBNJzfx/eoiJ08IySzrRLCFSVt6Zv1DVWFeUR9d5cPS10oP3KFbVJ2z8+wf5kSQBuRlPPyz2qu4GaHiqLZUaAmNyuNe3mi4bqJjQil/ZbX6FC+kQsdi/igSlnNZ4cspd2mLHJwj+/cI88BMKDdCmC0x3e2T4qmXWIU9+a9B1nQqUs081u9SrsZz5LSxj1vcP/0Pl4LoHxicSWJz2/z3Wb3AsjeAR9d7X7iKbFM6laWwobv1LU/7S7PY8uLcNW0zz+BCKeqSvj8VjWv06pv7Y/XaBqRILPoDaH/3X9rf2yXcdDn/Jrb+bLoAY6sh82feW5LcqcH+OFoNFsO5/Nhfj/iRAmOV8bC+rmw/Wt3+77nA5JrXlnAN2ttfuQN/+dT5AEicE/udhTKp+9A3XCihLJo+yRW8es9pzOofSLrypWV3Ue4Qyb/E/4cs8M+4AaHvRwwjOsYwUPn9WPagDbEU8gH7T9lWLtIPrzenc4hasv/MSDvJ1JWPuE+sCiLVr88yM93jObVPwzjmz+N9dl/wNPtsuYt320iE9Wr1a1VbqnfWlGiIqJ+MtZMWJ/wKoqhyCjkve0rWPio57mlhJ8fV08Lvji6UV3/uVfA13+p1pXGtq9h/f/5338i5B+Gb++t26dWzUlDcAm9rFL5bgZcdGLHhwRwOXz56EFNDpYchw6jcEYbuVUS3EvyZ32RyZnPLuazot6sd3YmPH+f1ymOhqhkW1v3HGDV1sDDAaNEOX90fMWEDqEMS1WCGSOUGyM1QglD6/BSWidEcm27vQyuWAuoJwGAWywZGTuHeEfRhBcf4YqRHXnkvP58P2IdIzM/JGzdux6pD1xC7bBsm38LLH+RjvmrOaNPK3q1joeVr7knqde+445aqnBPFntgdW1ZRS4iwXv9g9V1I6Xn5/JiFR4LcDgdFv5LuYJc+wvVorq3zvbdD9N1lrMLlr8ECx7x3Q7g/RnwybX+91dH7gF1jex8ch0se05laNVoaklwCb2zCkLq2RvlL3FaYaaa+ItMZH+hcVnj3YUrKg0vWZUT1ju7+DzFnDVKeAe28PSp18SEkHTuC3uHN9rMo3O8mlvon+rgxcuGECGVULZ0KpfO+OUzSRPKsu3bUrl3aiyeYQhkQnQYrZKMcnlLnoZ1H7jbmJZ1iCH0uQeU5QzuCKbj++DLO+Dja1WI6Wc3wetGsjlf/nXwXHdQaWmT3Mm9HsIky7IwqqzA0xdfkgN5Bz3bH7fcTIuNSWZ//nszesdk+YvVL4QDlUwve5e6oWz5HLJ2uieR/fHGmeoa2ddHHN+rXn0tALRTVgAbP6m5neakIciEvtI7XLG2xLeDIVf63T37kw0en8eXPUl2RHuOrf8W57HNEJVEMUYUSVQSBe0n8EuVp0/3varTKZehbHV6JtLKkOpJYFCqZ5RMTVw/0JjMrChxWcYdY52c2b8NEU4lXCmF293B8wa9W4Tz90lpXJLmGTLphVUgIw2hLzgE8653bzejW8wIpq//4t5XZbiWTEu+osSd/8cMH7UvFDPZ+YP7vfVmkNzFW+hXv+l+X5zt2f7gGvXEN+kh97YcH0JvPpFUlsOexe79Zj+ti/J+/rd3fw9bJtrfnAb/GaIiiOZeDh9eoVw/1cXym5PMdtdQTdfJyvf3q3mMAytqbqs5KQgyoa8Di/6OzXDOHNdHKSX9HviWVxfv5mBuCR+sPODRvEhGsbMkhpYluwmRVZSHJ/BI5aUA/FremXe7PcllFZ7J1LbQiR5l/+Nnp+dCrSypLN9LO+bTRniuHK2OtqGG1RsR5xYCw8IONyz60Moiz8RtQEhVKVceuJfkd6dW/wW5+y2+az8iVZprnNS4/uGWJ5+qciXyh9epz7EtPS3WzG3+XTefznK7WKzC3WaQt9Dv+sl9oy/O8bTOD/yqXntNU4vfQAl9ZZlyH5nf4TBW6C59Ft6arqxycC/MCrG4pnzN17zsYx6i8Ih6PbYZyvLU7yFze/WCb7fozZulfZLetb/CvT7AfArK2uH//JqTiiAT+so6d93kl1ZSWFbJP7/cwvLd3jHkhURSJd2Xcc7SLJY4+9Oz9E1mfCOYn36IHq1i2frQVLoY1YtO7ZZKdLiDQ9IzN8vY/spXHrfwb5zuqIUv1rT2IuLcQlBeCMU5xDvKWes0fPD2f/zKMu8QRjtRSVBVBi+Ogs3z/QtNgdEHc0Lc+mRVVQFP94Vv73Gf07wxgFoNvOhx/304vke5TsqNm8ENy2DMbRCV7N227+/Ua3G2Z3RNaZ7KbprUWd2EYlqqiKiv7lIrj7N3qnbGSmLXeEyfuMuitqawsAh1aZ57DYWdaFsOntVvwfPD4dcX1eeqSnW8OVlsjtnE+iRWmud+erLy+Z/U00NJrttlaI6/oqTmJ4GqCu/0HJqgIciEviowH2YtOF7kjmiZt/ag1/4SIkgVbusrDyXm3dqqf+7Nh/MZ3TWVyDAH152mfPMVVU4W3T2B6y+c5j7R3XuYff5In30owbAy7bl8LplrfKnhEglxuMXw+F54rDNhlUUM7m3k8rGKKyiL1+EZw+5FS4vbaekcT6t63Gz3+wLDSnY9UVgsdHvWz4oSb4t1x/f++5C1E/7dyZ1mOrmLWudgmQNx0cVYubztS/jfOZ77Etu7J9zDo5Uwmxa7uXrZdN2YeZCOG09BVhE2MVNZLHtBpaKwupmsRCWq15AwZYiYq3n3L1XX6bOb1PF5lqfFuZe702Nbf2/zb4V/d/S+qaw3/hbKCyHcCJE1J5+f6Ok7VYaV9y+Bf6VV38aOzRWoaboEl9DLuhH60ooqxj2+gEe/3sraA+5JuMU7sjzS504se4LuLePIj+nk2haGigz53zWnMKWviqIZ3VVVp0oyolQqqySpsRG07Tnc/aXRyd7pkg0izn8OLvkAhtsiOZKNfDumS6ai1Pekpik0hbaImopSCLWUzut5lvt9jDHOVpYi2QdXqzA/gD9thPGzYbIRymiKivn9FcXu8Xx1p+f3lhd6+6CrW8R0xOL3Rrj77FPox6vXTfO891nbO8KVWEYafTRLT5oL5Uzr9sBy5WLxZUWbff7x7+r1u7/56LxwX5OOo2Dw5e75iS2fwyNtYb0xqW3Pm5RhPG1Zf2+mi8tMnmfiWhhWop7AwH2DLctz7/fHTuNGG6h4r3pDpaAoDtzFqGk8gm/BlDhxof9p61H+/vlm+rdLYF92MS/97BnLnpYUxQuXDWH8/U/iwMlu2ZYNN44mTr7HgTeuov2xBYzq0YYrp48nJTaC2yf1QEoY001Zh4nRynquMNMPRNtcD37CO0OSOkCHkd4LfUzBM/235YXqnzwk1HPxWLRRBtEeJVJpE/quE92RMkkdoegYpPZw75dO2PEdxLRQ1jFA59PUqxmVYgpRebG6wfgqulJWWHPWTSuH0i0fpFuM7UIfHgcJ7dWEsa/zx7dzv3dEqOtmLoA7YlQVy96prGZz4duR9cqytp8vJFTNLTyY4N7mM8uoVPUNQqPg7DlqgtQ6aWwlc7vn5/BodWN9wceT3u6f3dfeSnmR29o/5mdNQHWUF7gn3KvjyzvUa1Gm99+xpskRfEJ/Aj767MIyYiJC+WrDEfZlF7Mv29uf+dLlQ+jbNoHIMAfv3H2pq+CGqiOaSIs/zuX7uU8x+sI/EROt8uT0ah3PK38Y5jqHGcZYWWWxmq78ouZ/LNO9MvQqyFjpztlir6hluhcS2nv6eE03hN39UFnq6Q5KsaT5NScKI+JgxnuQ2AFeOlWJf6KlTqx9QnLvEnj1DFeoKRhWZdfToddZykVzcI1aZeqLCX9TfvFtXyrrvKoS9i3x3dYq3Oc8p9JMCKH88IfT3fvaDlbnjLUUMwkNN4TesOitvvc1b0Gfc9WNo7xAuVTsQh8eo1wvgdJpjHoCO7LBfxt7fqNdC9wlKO0sfkI9dQy5Qt2YTCqKPfMt1RQCaqfkeM1/j1K6b4RV5dW31TQJgkzoax9143RKhv7T7VtNiApziXjLuAiOFah/mrHdWxBjlLdLS4omzRbwERkRwaQ/3FPtd7U0cq6brhwAOlezWtTEtLpDHDBillvo7TVyzcfvpE6eQm9OBhb5sOjN1aYAqd29vzssSkWqgBLFsnzPtQT2dQXF2e5QRavFOfxaJfQZq7z7YWX4H9ViJlArhaX0L/TWSc4hlgykyV08hb7DKCX01sVXjgjDdZPo+9yleerGkFOg2pXZhT6udk8lZrSOv3UYoNxH1rQZO6uZtwBY8TKkv+d5k3p/hqrDYOJv3mDJM+qpra9tNXhJLtj+tlnwL+XC63Ou+mwdt78JaE2TIgiFvnaumx9tFZYm9mrJPWf2wikhJsJB/wdVFSSzmMZvoW1iFAvuHE/7JD+ZMa10Hqfy24Cn1W3NqumrRi4oy3H3Avdn06L3ct2Uea5k9ZXHx/od8e0gM9+zD+Ex7vfdJnmKk1VEzZuSvxQSrnbRMP4e1bf+F3lbuVZCQuCMB6HdMM/t5tyFybA/Kkt39C3ubY4wdaOrsghVi96QaUzKFmVBbCu1Era8yHtOwTpuX4y5TQmi6aYxF5T5y4oKagK9RS+30NuJTPSeUC+3RcqU5ilXUVQSIFRMvcniJ2HM7bDwEXeUk5fQ2xaGleTCz0a6CLOwvdWF6G+hm6ZJEdSTsUfyShnxyA98teEw3246wss2n/u6A7lexTEuHt6elvGRtE6IJC4yjJ5GnnThL5tlLemcGkOoI4DL/vs33e+tkTFWobCKdIrFGk+yCZ1p+ZohhCYVJZ6P3h43DsN1Y31qMH3iVqs0Ik4J8pVfeMbOg3sS2HpuawqJVFtlLxGinl6ik9VahvBo903KH6fe7v1U1GOqZzGZqCQ4+1lIsLh6Qg2L3rTyz3oCLrDkts/c6nb1FGfjtX6gJqF3hHteT9MKrk7oK4qV2+S0u733pZ1S803SSnQKDLzEozALP/4D3r3QO5TVOgFrCn1ZIfwyxx35Y/2d51uiz7RF3ywILqG3+eifX7CTo/ll3PjuGq5/ezX/+nqrq4QewEerPeuoPjtjECO7pHhs++zmMaTfP6l+++0Lq5/UatG7xEMof3T3yTDlX55plZM6eZ4rKlFNUttj4J2W2OnT7/e8cZjXKdSX0FvESgi44L9KbO15WKwWvel+MgWyVX+47ifP9iGh3umhoz1/HwHR/hSYZVnVandxgRLio5tUiumOY+CU66B1P7jcSB3grFQ3nJBQd9RLnGXy1y709ogpR7jnRLd5natz3YD6vU+8F9rbJmCnPel9I60OR4T3gjKAXT96b9tt+T2YQv/zv+H7+9yrf63zN1ahz9ntKoCjaboEJPRCiKlCiG1CiJ1CiNl+2owXQqQLITYJIX6uzbF1hi3qZuku79jnt5bu5fwXfuGqN1bw+fpDnNajBesfnMxfpvbirP5tvNpHhjlc0TINwql3KHGxuqBCfVj05oKky/4PRt3oudjFLpYR8Z6iY6UkF4b8Acb+2Xac9PweUL5v8L9oasQs2/daXEFmv1sa4Zqdxyrr3kjfDPgpHFMLcfOHff0BqOvhrPCekDbHCBDXRt1YXULf2tIvm2XuJfRhnm1Ovd33cXbMG7z1aQjUjaM21yI0wn8CPisH18A7F7g/m64hc+LenG+xPvlZU2J8fRf879zA+1XfFOe4I6g0LmoUeiGEA3geOBPoA1wihOhja5MIvACcI6XsC/w+0GPrFGcV+3LLuPjlZRSWVbI7q4jbz+jB9ePc/7wPfr6Z7MJyFm7LJLe4grYJkcRHhnHD+K6EBeJSqW/OeADut63A9eWjH3mDZ5syS26cFNukakSc21q3u3XK8lTVq0AwFyPt/9X3/lE3wZ0W95BVmMwx9JoG92XBVGPCdeYCOM9YISp9CL39ptWqn3ebmvA1b+Ow3Pis4mt9Guo8TgmmObdhFXr7QjN7pIoj3N1m9K0w1MifVJPLxyX0Nms8NLzmYz3aRwTm6vnvBM/PZvI0E9P1Y/37sq/HgKaTbuG/E+GlMTW3K8w8qdYABKJspwA7pZS7pZTlwAeA/RZ+KfCJlHI/gJTyWC2OrTucVRzMq2D5nhz+9EE6UsKAtATumNSDP53hFr/3rhtBlxbqn6ZlvA9rr6lgLue3ikqIQwmluVDJxJyUu2MLtOyl2piERrhdMb5inn1Zmd2nqFeruLUZZOyb7L/PVivS6mrwN7cA/ou52LkvW9X4rQusfbC+F8I99nZD1Q2qwMhVE9vK3c7+lBDpw3VjhiBaI8ECtuhtQu8IV2UvAyU0wveNoc0gz5ucSZ9zodd02LVQ/a3Y1z9YP5cVqDTRVp4bVnM6jYbAjDaz5hHK2eOd3uGJbvB414brVyMTiNC3A6yZvDKMbVZ6AElCiIVCiNVCiD/U4ti6w1lJZIQSxR+2HGVg+0RGdU0hItTBbad356Hz+vH5zaeSlhRNRKiy8lrF+3FpNAXOf1lZyHar1hHmvc0MqYtt7W5jIoT70dvX6lu7SyAkFMb9Be7Y6pFTnxAH3LULfv8GfrEKoNWi9OU+MfGzItgLR2jtoqriq/lTs7qy7BOKF70Fd+5Q3xcW6XZnWM9n74cvH73pirL+LvxFSpn4FfoI6Hmm57bpz8AtfurfOiK8b6BhMXD1177deJGJat1C3n61bsDqhwcllOakbXkhxPiYO7FmA/VFdUnc6hqzPsL+5TBnkDsdtkd/algF3JD9rWcCEXpf4Sb2KxAKDAWmAVOA+4QQPQI8Vn2JEDOFEKuEEKsyM2tIm+sPWUUVIUzq04qf/jyOj2eNci1SEkLVKe2fpv6Rwh2qay3jmrBFHxoOsS0Ca3vJ+3DTSv/FU0yhN0MPEyy5T6xW5p82wJ+3qfPEe89ZEJNavVVqvQElWNIwV3dMoBZ9bbnhF7jVT3I461OSNS8PqL6aETfWG5T1pme/Ofiy6M3VyVaLvqbiNqbQ2+P7HWFqXcLMn9VN2OyPdfGaFV+um5hU4ynLx79laKT7XDl7fKzyle5Vz2WF3onaaiJ3P/w9UaV9yD+sVhTXdRUuK2Zf842Ai6O19NvvWqD6e6ya8N5mRCBx9BmANXF6GmAvupkBZEkpi4AiIcQiYGCAxwIgpXwFeAVg2LBhJ3YrdVZSKcOIDHPQpUX1/knTHx9TB/HxTYKIOGhhE8w/bXBHUZjWS7czoMeZ6rH+TSO3jVWEE2tIflUbrBOb1SVPq8mi/9NGVc+3tkQl+Y48AU+r1t/ksrVdaJSn28su9PablSPMnV8mkKeQqCTPValePnqjH20HqXmKtoPV79Jf2K+vyVizH74OCQ13W+lLnlLhoDEtPMMzywqMVNgFxtONwMNuq84CNpPDzb3cvfBq3Xsw4Pf+j/ktVJSoa2idW6gNPz9mvP5brea+a6fv6K1mQiAW/UqguxCisxAiHJgB2AuLfgaMFUKECiGigRHAlgCPrTucVVTIEMIDmFS956xedEqJpl9aAHk9miuJHbz9uuGx0GMytLDEsNvDMesKa8qB6tYh1GTRJ7ZXwlaXeFj01Qm9cROMTvG07u1J2Ow3KxHibh/IpGi3Mzw/+/LRu96HKjeO/ZpOf8bSbx8WvSuCyo9Fb4ay7lmkXIBdbBO1ZQWqoMyRDercXu44Q+gXPwXf2FI3WPtv1lauKXPqb8FcyGWtKVxlPGHJam5OFaXwygR3eotNn6gbW3WruZsBNVr0UspKIcTNwLeAA3hdSrlJCDHL2P+SlHKLEOIbYD3gBF6VUm4E8HVsPY3FJfQRYTUL/dCOySy8a0KN7YIO08qzxqfba6/WFYEuMqsv1011WEXGV7SPiWlJx6R4PvnYhd4rP4xU0TbOKpWjqCbOekK5TkxxtQt9IE8F3c5QN/bD63z76M3QY/P30mW8WktQlGksVDP+JqRTLS6z+/J//IdadQvq7yg0wrO84yfXqetgZvOsKIJpTys30LyZ3v21T8rXJeZTmtWiL81Tv0fr7668yPPJJ2s7HPIx73GiTwZNhIBSIEgpvwK+sm17yfb5ccCreoSvY+sNZyUVUgRk0Z+0mLnKrSJstbzrgvNfrl37miJR6gPr+oDfv+W/nWm11mTR28cgpfKHT/SsLubFOc+pvkQlwun3ubfb4+gDITTCHSobGlmNRW8w9VH48EpD6I32jgiVFiK+rXtMiR1VKuydlsVW4bFqvz0lw3sXud+vflOtH/j4Gu+wTfCs1lUTBUdVOoe4VuomaK5LABXum7nNHcIKFoveEm1TmquE3jonU3Lc5uLyV0GtFnmNmiDBletGVlHuDMyiP2mxhtyd+bh3sq66YOCM2rUXAgZe6k6e1hCY/vNT71DhqP4Iswi9h0Vv89HXJj32uNnu/DGDL/f95ONvbqE6QiPcfQwN97bI7a6bsGj3d4dGqvfRKaoecHw7t8Ud1wZOuwvm3+w+V0Sc/0V4VgqO2nLcW/z6dtfN4XVqorb7JFj+Egy92h2iu3exO28/qMV55lhfN8JhPYTel0Wfq16t7pyS4+6U2+CZ+M5KMxf6oFJE6axUrhtt0fvHar2MmKn+gZsC578Ivac33Pf5Cn30hRkxE9fGU9jOeNAz8sQeTVPdxOQES5ZTf+6tyESVdbM2OCKgxFgEFNNSnbv1APd6DLOPVnE3Rd8cm3k94tu5n2AcYd7uPUe49xOCiXXOJ/+gp2vMOqFtv/YvnwbvXwybP1XpmRc+4t5nf3I4lA57f/HcZr3mvnz0ZvEYq0VfU5I4VzsfQn90k1pZ7I9D6bWL2tnxAyyv5dNwgASXIlZVUiVDiAgLkkia+qA2ibHqgq4TVUbGpoav0Edf5BrLQFr184yB7zEF7rYkyTMzaJquMX8uAJORN1W/PyQErqqlxzM0wp1vyKy0NWsxjDYscVOYzRKQvvIpmTeXNgM9XVXWyXtQQuorZQV4rszOP+TZzvqk4m8y1nxaKrRE/Nizh741XUWNWdMxWJ+yrBa96SJyWfQWobdmdHVWwfZvffcpeyccNQq57FuqJnZfHK1WFvu7qX9+G/zwgO99vtj8qUofXQ8EldBLWUUlgUXdnLTUcU3dGrliHty0vOZ2DY1L6Gu4HtnG0v7W/aoPr0vqqNL4njPHaD/Af1uAqY+40/76o6aYeztCwADDbdayt3u7KUSme2nETPXd1vGYFv35L8HfMlW6C3/psUEJqb/cO6k2obcuTPIl9JVl7vBLcAuztfyh3aI2f3/WkpHWeYDyYsjepY4zs5aa57AKvXWR14JHYMUrvse06DF4cZTK5vnGmbDsP5Zz7FZPC4W29T9FmbWbxDXDV+uB4FLEqiqqcGgfvS/qOjyxuROoRd/1dPWa2qP6Va2maPX7Hdx7tHq/f31y3ovq+60uIVNofblazHZmWgQh3En0zBuBrxWkbQfDBD/Vr6xCv+Nbzxz3HkJvCPr3D8CzlhujeYOzJlKzC7056Wzd/sII9/tdP8J/hqgwSXPhni/XzfE97v5tCGAB16rXjeMsN6b9y+DZgSqtgpXiHM+oJH+Yq4610AeIs5IqbdH75qqvVPoCjcKshWtPAGfnnDnw5+1KlBzV3BQ8kqQ14sKakBDv7zfDJtOGe7c38TWxGmoTevNGMekh6H8h9DkHbvBRTjGhg8q5dPazyuVhXezmS+jt4YymIJtx7+At9K7axH4sZqulH5OqbsR2101sa0h/F/7dSUXt5O6zn8WbLZ+rV2vUVVGWt6+/okSJvL/JXVe7UvhXmkoJXZavhT4gpLbo/RJIEY+TicFXwLU/qfKG1REaoUL6aqKhXWK1IaWrSp0w+SEfO60TszbsQm8+tVjdQr5ulJEJKjxzyJWeaagBoqyTscb57KuxzaySpkX/w9/VwiVf2JOVDb/Wu014rFGdy7hZmBa8dTHh97XwpYOKEDKxivzB1Sq9g1nC0ZdF//b58KTxxGf2ac3/tEUfMM5Kw0ffhP/pNE0DISBtaN2erynTdpDvCCNXBE4AFr0pzNYQXV/nNCd5hfBOxGa16M0nBNOCN7HnwF/ylPd3mKx92/PzsGvU3EGr/u45hKhE1Sfze/YvVUVkpj2h2gNkrPQf0uqrrvCxze73VtfUOiMEdLORAMBXBa5dP6nC7Znb4EnjyVJKQ+gDTPBXS4JK6LP6Xcuvzj6EhwbVsDSa6pn1C1zx6W87hy/B9hJ6HwXOfd3grAne7OJpXQhmntcUdhNfxU4CJa4NnPucyrBq3piiktT3HtsCr01RKRi6TlRPEhONRWrFWf6t6dRq3HvRqZ5Cn7VdvZpzP/kHYf6tvo9Nf9f9XmoffcDsH3QHC5yDidBCr6kvLngNrvETgtdYtO4HXU80nUc1TyKmlW9G7bgseluI7tnPqjoB5jxFRDVCbz3WDLv0EnrDp19eVPviIBFx0O8CJc7mjSQyUf1kbYMDRtGcVn3c/fPVbyt215I5hogElbjPzN0DkLndcwwAa99Rk61SwreWldJmnQNQcw716KMPqpWx5ZXqF6stek290f9Cz89/+My7Vm5dcvazvl0HDYE/i94e9mnm8rnmGyV61lBMe9+t6TZkFWz/znsS1BT+0nx3XvxW/VTBm+rcONY+gjuyyrTorZhzBUKoOZjc/UroL3wd9i5RYr7UCJWNsaUK73QqbP9GfZe9uEuBkZw3z1KPWlYpqz9jBSx7zr19/Vzv/muhr5kyQ+i1Ra9pMLqMdy9Oqg8CSYj2WzjnWTURaUYhWTGjjEyhv+A1lb7XWmfASrsh6seK3aK3lrKUTnjPSFPcc5oKiawsdVvxRZluv/qUR9SNpyaht2IVenvSOavwx7UxhN54Guhn1NA1hd5cAd1lgnrKGT9bCX1xlmcaZyvWhVwAm+fBcj8x+lZqUwC+FgSVIpZpi16jqR3thsJVX/iejDUnS03XTftT4PKPapd10m5JW90gzip3zYIR18Mfv1PvTYu+ssRt7UfG1z7bpekaikr09KOD5w3ILJfpz5oeeLGy9qc8ApfOVeUY24+Ac1/wtNyt2HNIffln5TqqCetK3TokqBSxvEpb9BpNneES+hpK7lWHryLnJtKprPRe09VKXHOS11oI5tgW9eqVBjoAzBw7UUnqO/z1K7YGoU/sAPcccPv1hVA3pcGXwWl31r5fAH3O873dXpegjggqRXQ6leXhqO3ScY1G401cW/U64KLq21WHL4E2fd4Fh9WPOQnqK121GcYYmehZyrE2RCWpFcsP5HpuM6nJoq+O0bcot1Nt8ZX/6a7d6qmpHggqRXQaj5ghTTykWaNpFsSkwL1HYMxtJ36OEIdKyWDl9s0qhcHGj4188IbA+sqdY1r0EfFqIvfeI+48QjVVqOp9jnr1VYPBOkkcZ9RGttf9jQ/wxhJaQz98YXdp/fWw74LrdURQTcZWOU2h10qv0dQJdVEUxp6SITRc/ZhpDEyht0awRCQoH33BYXVTMCeGw6Lc7c96Qrk6Co+qLJJ2LnhV3Uh8PeFbxdll0duE/qblgcXyO3zMb4ByS1lTJQy6TMXKb5mvbmp37VLzCCGh9TYJ6+pKvZ69gTHnjEK0Sa/RNG2shVpMSzo0QqVqCI1QFveix2HVa97F203LPzxGZab0578PjXCLeHWYLiH7fIK9uLo/7BZ9QgfI26/6VWgR+tYD4ICRyTUsqkFTkgSV0GvXjUbTTLBm0rT6xtsOcr8f/kcl9Pbc/vbYdfOpI75dzd9723qVhMxKaneY8Z5aLXsimK6fMx+D5K6qeljefmNhlcVtFZngXjH7Wya4T4AgE3r1ql03Gk0Tx5oELtzPJGjLPr63m5a2mYUyxKFi/NuP8N3eSlJH9WPnt5SxHPtnFWs//I+qL58bKQ9SukGOJWNsZIJ73P6KttQTQSb0Sum1zms0TYyL3/H09/srQ2hFCLjobe/4edOXXmHJDGlfsdyQhEaoYi4m5mre8bNVCcbyQlUD12MtQA0VyOq6iw36bfWMlHoyVqNpkvQ+2/Oz1UdfXXGOPud4bzvtLrVidvBlddK1eqNVX7VSeMV/1efIBJh4v7LmzTq+DURQCb123Wg0zRD7YqaaiE5WxeSbKr/7r6ora6427jIeuk1S/vvwaDjvhQbvUlAJvTu8spE7otFoasCwyibep4Q7mBhwkecis9TuKnVEIxKcC6a00ms0TRtXLHRQ2ZpNlqASeqldNxpN88AML9RC3yAEldDrOHqNprlgWmW67GdDEGRCr161Ra/RNHG066ZBCTKh13H0Gk3zQFv0DUlQCb2Oo9domgnaR9+gBJXQV5l/O1roNZqmjem6EdqibwiCSuj1ZKxG01zQPvqGJCChF0JMFUJsE0LsFELM9rF/vBAiTwiRbvzcb9m3Vwixwdi+qi47b0dKiRAgtEWv0TRtpPbRNyQ13k6FEA7geWASkAGsFELMl1JutjVdLKX0t5Z5gpQyy8++OsMptdtGo2keaKFvSAKx6E8Bdkopd0spy4EPgHPrt1snhlNK7bbRaJoDOryyQQlE6NsBByyfM4xtdkYJIdYJIb4WQvS1bJfAd0KI1UKImT6OA0AIMVMIsUoIsSozMzOgzttxSu220WiaB1roG5JArrIv5bQnU14DdJRSFgohzgI+Bbob+8ZIKQ8JIVoC3wshtkopF3mdUMpXgFcAhg0bdkLJmqW26DWa5oG26BuUQCz6DKC95XMacMjaQEqZL6UsNN5/BYQJIVKNz4eM12PAPJQrqF5Qrhut9BpNk8cVXhlUgX9NlkCu8kqguxCisxAiHJgBzLc2EEK0FobPRAhxinHebCFEjBAiztgeA0wGNtblAKxUOfVkrEbTPNAWfUNS41WWUlYKIW4GvgUcwOtSyk1CiFnG/peAC4EbhBCVQAkwQ0ophRCtgHnGPSAUeE9K+U09jUVPxmo0zQXtumlQArrKhjvmK9u2lyzvnwOe83HcbmDgb+xjwEgpdS56jaY5oFMgNChB5SDTcfQaTXNBx9E3JEEm9Np1o9E0C/TK2AYlyIRex9FrNM0D7aNvSIJK6HUcvUbTTNDZKxuUoBL6KqeOo9domgfaom9Igkro9WSsRtNM0D76BiWohF6FVzZ2LzQaTY3o8MoGJahkUadA0GiaC9qib0iCTOi160ajaVZoi75BCDKhVxWmNBpNM0ELfYMQVEIvtUWv0TQvtOumQQgqodcrYzWaZoaOo28QgkrodRy9RtPM0K6bBiGohF5Pxmo0zQwt9A1CUAm9jqPXaJoZWugbhKCSRR1Hr9E0M7Rl1iAE1VXW2Ss1mmbCqJsbuwcnFUEm9DrqRqNpFkx5GB7Ma+xenDQEldDrOHqNRqPxJqiEXoVXNnYvNBqNpmkRVEKvJ2M1Go3Gm6ASeu260Wg0Gm+CSuidOo5eo9FovAgqWdSuG41Go/EmyIRex9FrNBqNnaASeqnj6DUajcaLoBL6Ku260Wg0Gi+CSuidTrRFr9FoNDaCS+i1Ra/RaDReBJXQ6zh6jUaj8SaohF7H0Ws0Go03AcmiEGKqEGKbEGKnEGK2j/3jhRB5Qoh04+f+QI+tS5xS6vBKjUajsVFjeRchhAN4HpgEZAArhRDzpZSbbU0XSymnn+CxdYJ23Wg0Go03gVj0pwA7pZS7pZTlwAfAuQGe/7ccW2t0PnqNRqPxJhChbwccsHzOMLbZGSWEWCeE+FoI0beWxyKEmCmEWCWEWJWZmRlAt7zRcfQajUbjTSBC70s5pe3zGqCjlHIg8B/g01ocqzZK+YqUcpiUcliLFi0C6JY3Ko5eC71Go9FYCUToM4D2ls9pwCFrAyllvpSy0Hj/FRAmhEgN5Ni6RKdA0Gg0Gm8CEfqVQHchRGchRDgwA5hvbSCEaC2McBchxCnGebMDObYucerJWI1Go/GixqgbKWWlEOJm4FvAAbwupdwkhJhl7H8JuBC4QQhRCZQAM6SUEvB5bD2NRcfRazQajQ9qFHpwuWO+sm17yfL+OeC5QI+tL3SaYo1Go/EmqOxf7aPXaDQab4JK6HV4pUaj0XgTVELvdGqh12g0GjtBJfQ6BYJGo9F4E1RCr1MgaDQajTdBJvQQopVeo9FoPAgqoZ/StxW928Q1djc0Go2mSRFQHH1z4ZkZgxu7CxqNRtPkCCqLXqPRaDTeaKHXaDSaIEcLvUaj0QQ5Wug1Go0myNFCr9FoNEGOFnqNRqMJcrTQazQaTZCjhV6j0WiCHKEKQTUthBCZwL4TPDwVyKrD7jQH9JhPDvSYTw5OdMwdpZQtfO1okkL/WxBCrJJSDmvsfjQkeswnB3rMJwf1MWbtutFoNJogRwu9RqPRBDnBKPSvNHYHGgE95pMDPeaTgzofc9D56DUajUbjSTBa9BqNRqOxoIVeo9FogpygEXohxFQhxDYhxE4hxOzG7k9dIYR4XQhxTAix0bItWQjxvRBih/GaZNl3j3ENtgkhpjROr38bQoj2QogFQogtQohNQojbjO1BO24hRKQQYoUQYp0x5r8b24N2zCZCCIcQYq0Q4gvjc1CPWQixVwixQQiRLoRYZWyr3zFLKZv9D+AAdgFdgHBgHdCnsftVR2M7DRgCbLRsewyYbbyfDfzbeN/HGHsE0Nm4Jo7GHsMJjLkNMMR4HwdsN8YWtOMGBBBrvA8DlgMjg3nMlrHfAbwHfGF8DuoxA3uBVNu2eh1zsFj0pwA7pZS7pZTlwAfAuY3cpzpBSrkIyLFtPhd4y3j/FnCeZfsHUsoyKeUeYCfq2jQrpJSHpZRrjPcFwBagHUE8bqkoND6GGT+SIB4zgBAiDZgGvGrZHNRj9kO9jjlYhL4dcMDyOcPYFqy0klIeBiWKQEtje9BdByFEJ2AwysIN6nEbLox04BjwvZQy6McMPAPcDTgt24J9zBL4TgixWggx09hWr2MOluLgwse2kzFuNKiugxAiFvgY+JOUMl8IX8NTTX1sa3bjllJWAYOEEInAPCFEv2qaN/sxCyGmA8eklKuFEOMDOcTHtmY1ZoMxUspDQoiWwPdCiK3VtK2TMQeLRZ8BtLd8TgMONVJfGoKjQog2AMbrMWN70FwHIUQYSuTflVJ+YmwO+nEDSClzgYXAVIJ7zGOAc4QQe1Hu1olCiHcI7jEjpTxkvB4D5qFcMfU65mAR+pVAdyFEZyFEODADmN/IfapP5gNXGu+vBD6zbJ8hhIgQQnQGugMrGqF/vwmhTPfXgC1Syqcsu4J23EKIFoYljxAiCjgD2EoQj1lKeY+UMk1K2Qn1P/uTlPJygnjMQogYIUSc+R6YDGykvsfc2DPQdTiTfRYqOmMXcG9j96cOx/U+cBioQN3d/wikAD8CO4zXZEv7e41rsA04s7H7f4JjPhX1eLoeSDd+zgrmcQMDgLXGmDcC9xvbg3bMtvGPxx11E7RjRkUGrjN+NplaVd9j1ikQNBqNJsgJFteNRqPRaPyghV6j0WiCHC30Go1GE+RooddoNJogRwu9RqPRBDla6DUajSbI0UKv0Wg0Qc7/A147X+XfraIuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc(hist_rnn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8250d4f-47d9-47de-83c7-dbdaea4252db",
   "metadata": {
    "id": "f8250d4f-47d9-47de-83c7-dbdaea4252db"
   },
   "source": [
    "### rnn3 <--rnn\n",
    "\n",
    "adding another GRU+dense layer to rnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc686e4a-53be-4357-8371-5ac52512d380",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:07:49.194633Z",
     "iopub.status.busy": "2021-08-27T04:07:49.194489Z",
     "iopub.status.idle": "2021-08-27T04:07:49.593011Z",
     "shell.execute_reply": "2021-08-27T04:07:49.592286Z",
     "shell.execute_reply.started": "2021-08-27T04:07:49.194615Z"
    },
    "id": "bc686e4a-53be-4357-8371-5ac52512d380",
    "outputId": "9770721f-68fc-4c2f-f18a-c2d9620b4e56",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 1, 8)              480       \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 1, 8)              432       \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 8)                 432       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 1,577\n",
      "Trainable params: 1,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model network \n",
    "\n",
    "rnn3 = Sequential()\n",
    "\n",
    "rnn3.add(GRU(8,input_shape=input_shape, return_sequences=True))\n",
    "rnn3.add(GRU(8,return_sequences=True))\n",
    "rnn3.add(GRU(8,return_sequences=False)) # false if next layer dense\n",
    "\n",
    "rnn3.add(Dense(10,activation='relu'))\n",
    "rnn3.add(Dense(10,activation='relu'))\n",
    "\n",
    "rnn3.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# compile model \n",
    "rnn3.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "# show summary \n",
    "rnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69266e33-1dc7-484a-b335-409599bbf22c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:07:49.594192Z",
     "iopub.status.busy": "2021-08-27T04:07:49.594053Z",
     "iopub.status.idle": "2021-08-27T04:08:19.426157Z",
     "shell.execute_reply": "2021-08-27T04:08:19.425431Z",
     "shell.execute_reply.started": "2021-08-27T04:07:49.594175Z"
    },
    "id": "69266e33-1dc7-484a-b335-409599bbf22c",
    "outputId": "80e6eb36-0421-452b-df86-fbd508e94f16",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 - 4s - loss: 1.0817 - acc: 0.4460 - val_loss: 1.0535 - val_acc: 0.5110\n",
      "Epoch 2/100\n",
      "46/46 - 0s - loss: 0.9929 - acc: 0.5495 - val_loss: 0.8891 - val_acc: 0.6370\n",
      "Epoch 3/100\n",
      "46/46 - 0s - loss: 0.7885 - acc: 0.6002 - val_loss: 0.7033 - val_acc: 0.6397\n",
      "Epoch 4/100\n",
      "46/46 - 0s - loss: 0.6944 - acc: 0.6002 - val_loss: 0.6799 - val_acc: 0.6370\n",
      "Epoch 5/100\n",
      "46/46 - 0s - loss: 0.6713 - acc: 0.6002 - val_loss: 0.6718 - val_acc: 0.6370\n",
      "Epoch 6/100\n",
      "46/46 - 0s - loss: 0.6603 - acc: 0.6016 - val_loss: 0.6670 - val_acc: 0.6301\n",
      "Epoch 7/100\n",
      "46/46 - 0s - loss: 0.6558 - acc: 0.6029 - val_loss: 0.6534 - val_acc: 0.6425\n",
      "Epoch 8/100\n",
      "46/46 - 0s - loss: 0.6537 - acc: 0.6043 - val_loss: 0.6503 - val_acc: 0.6452\n",
      "Epoch 9/100\n",
      "46/46 - 0s - loss: 0.6519 - acc: 0.6043 - val_loss: 0.6505 - val_acc: 0.6466\n",
      "Epoch 10/100\n",
      "46/46 - 0s - loss: 0.6498 - acc: 0.6040 - val_loss: 0.6465 - val_acc: 0.6466\n",
      "Epoch 11/100\n",
      "46/46 - 0s - loss: 0.6494 - acc: 0.6040 - val_loss: 0.6450 - val_acc: 0.6466\n",
      "Epoch 12/100\n",
      "46/46 - 0s - loss: 0.6496 - acc: 0.6043 - val_loss: 0.6522 - val_acc: 0.6466\n",
      "Epoch 13/100\n",
      "46/46 - 0s - loss: 0.6477 - acc: 0.6047 - val_loss: 0.6441 - val_acc: 0.6466\n",
      "Epoch 14/100\n",
      "46/46 - 0s - loss: 0.6470 - acc: 0.6043 - val_loss: 0.6484 - val_acc: 0.6466\n",
      "Epoch 15/100\n",
      "46/46 - 0s - loss: 0.6498 - acc: 0.6036 - val_loss: 0.6481 - val_acc: 0.6466\n",
      "Epoch 16/100\n",
      "46/46 - 0s - loss: 0.6469 - acc: 0.6043 - val_loss: 0.6424 - val_acc: 0.6466\n",
      "Epoch 17/100\n",
      "46/46 - 0s - loss: 0.6473 - acc: 0.6047 - val_loss: 0.6461 - val_acc: 0.6466\n",
      "Epoch 18/100\n",
      "46/46 - 0s - loss: 0.6474 - acc: 0.6047 - val_loss: 0.6474 - val_acc: 0.6466\n",
      "Epoch 19/100\n",
      "46/46 - 0s - loss: 0.6487 - acc: 0.6047 - val_loss: 0.6471 - val_acc: 0.6466\n",
      "Epoch 20/100\n",
      "46/46 - 0s - loss: 0.6454 - acc: 0.6047 - val_loss: 0.6453 - val_acc: 0.6466\n",
      "Epoch 21/100\n",
      "46/46 - 0s - loss: 0.6469 - acc: 0.6047 - val_loss: 0.6454 - val_acc: 0.6466\n",
      "Epoch 22/100\n",
      "46/46 - 0s - loss: 0.6469 - acc: 0.6047 - val_loss: 0.6499 - val_acc: 0.6466\n",
      "Epoch 23/100\n",
      "46/46 - 0s - loss: 0.6468 - acc: 0.6047 - val_loss: 0.6498 - val_acc: 0.6479\n",
      "Epoch 24/100\n",
      "46/46 - 0s - loss: 0.6460 - acc: 0.6047 - val_loss: 0.6490 - val_acc: 0.6466\n",
      "Epoch 25/100\n",
      "46/46 - 0s - loss: 0.6456 - acc: 0.6047 - val_loss: 0.6468 - val_acc: 0.6466\n",
      "Epoch 26/100\n",
      "46/46 - 0s - loss: 0.6467 - acc: 0.6047 - val_loss: 0.6536 - val_acc: 0.6466\n",
      "Epoch 27/100\n",
      "46/46 - 0s - loss: 0.6461 - acc: 0.6047 - val_loss: 0.6473 - val_acc: 0.6452\n",
      "Epoch 28/100\n",
      "46/46 - 0s - loss: 0.6460 - acc: 0.6047 - val_loss: 0.6504 - val_acc: 0.6452\n",
      "Epoch 29/100\n",
      "46/46 - 0s - loss: 0.6460 - acc: 0.6040 - val_loss: 0.6487 - val_acc: 0.6479\n",
      "Epoch 30/100\n",
      "46/46 - 0s - loss: 0.6455 - acc: 0.6043 - val_loss: 0.6524 - val_acc: 0.6452\n",
      "Epoch 31/100\n",
      "46/46 - 0s - loss: 0.6450 - acc: 0.6047 - val_loss: 0.6462 - val_acc: 0.6452\n",
      "Epoch 32/100\n",
      "46/46 - 0s - loss: 0.6459 - acc: 0.6047 - val_loss: 0.6506 - val_acc: 0.6452\n",
      "Epoch 33/100\n",
      "46/46 - 0s - loss: 0.6452 - acc: 0.6047 - val_loss: 0.6483 - val_acc: 0.6452\n",
      "Epoch 34/100\n",
      "46/46 - 0s - loss: 0.6458 - acc: 0.6050 - val_loss: 0.6505 - val_acc: 0.6466\n",
      "Epoch 35/100\n",
      "46/46 - 0s - loss: 0.6455 - acc: 0.6050 - val_loss: 0.6496 - val_acc: 0.6479\n",
      "Epoch 36/100\n",
      "46/46 - 0s - loss: 0.6449 - acc: 0.6050 - val_loss: 0.6492 - val_acc: 0.6452\n",
      "Epoch 37/100\n",
      "46/46 - 0s - loss: 0.6450 - acc: 0.6040 - val_loss: 0.6493 - val_acc: 0.6452\n",
      "Epoch 38/100\n",
      "46/46 - 0s - loss: 0.6457 - acc: 0.6050 - val_loss: 0.6473 - val_acc: 0.6452\n",
      "Epoch 39/100\n",
      "46/46 - 0s - loss: 0.6448 - acc: 0.6050 - val_loss: 0.6471 - val_acc: 0.6452\n",
      "Epoch 40/100\n",
      "46/46 - 0s - loss: 0.6445 - acc: 0.6047 - val_loss: 0.6506 - val_acc: 0.6466\n",
      "Epoch 41/100\n",
      "46/46 - 0s - loss: 0.6440 - acc: 0.6047 - val_loss: 0.6506 - val_acc: 0.6452\n",
      "Epoch 42/100\n",
      "46/46 - 0s - loss: 0.6450 - acc: 0.6043 - val_loss: 0.6540 - val_acc: 0.6452\n",
      "Epoch 43/100\n",
      "46/46 - 0s - loss: 0.6443 - acc: 0.6043 - val_loss: 0.6504 - val_acc: 0.6452\n",
      "Epoch 44/100\n",
      "46/46 - 0s - loss: 0.6452 - acc: 0.6060 - val_loss: 0.6481 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "46/46 - 0s - loss: 0.6456 - acc: 0.6047 - val_loss: 0.6482 - val_acc: 0.6452\n",
      "Epoch 46/100\n",
      "46/46 - 0s - loss: 0.6454 - acc: 0.6043 - val_loss: 0.6491 - val_acc: 0.6452\n",
      "Epoch 47/100\n",
      "46/46 - 0s - loss: 0.6445 - acc: 0.6050 - val_loss: 0.6483 - val_acc: 0.6452\n",
      "Epoch 48/100\n",
      "46/46 - 0s - loss: 0.6439 - acc: 0.6047 - val_loss: 0.6531 - val_acc: 0.6466\n",
      "Epoch 49/100\n",
      "46/46 - 0s - loss: 0.6444 - acc: 0.6043 - val_loss: 0.6539 - val_acc: 0.6397\n",
      "Epoch 50/100\n",
      "46/46 - 0s - loss: 0.6464 - acc: 0.6053 - val_loss: 0.6561 - val_acc: 0.6493\n",
      "Epoch 51/100\n",
      "46/46 - 0s - loss: 0.6458 - acc: 0.6036 - val_loss: 0.6514 - val_acc: 0.6452\n",
      "Epoch 52/100\n",
      "46/46 - 0s - loss: 0.6440 - acc: 0.6050 - val_loss: 0.6484 - val_acc: 0.6466\n",
      "Epoch 53/100\n",
      "46/46 - 0s - loss: 0.6441 - acc: 0.6047 - val_loss: 0.6558 - val_acc: 0.6411\n",
      "Epoch 54/100\n",
      "46/46 - 0s - loss: 0.6442 - acc: 0.6050 - val_loss: 0.6524 - val_acc: 0.6411\n",
      "Epoch 55/100\n",
      "46/46 - 0s - loss: 0.6439 - acc: 0.6057 - val_loss: 0.6493 - val_acc: 0.6452\n",
      "Epoch 56/100\n",
      "46/46 - 0s - loss: 0.6439 - acc: 0.6050 - val_loss: 0.6492 - val_acc: 0.6466\n",
      "Epoch 57/100\n",
      "46/46 - 0s - loss: 0.6436 - acc: 0.6050 - val_loss: 0.6534 - val_acc: 0.6466\n",
      "Epoch 58/100\n",
      "46/46 - 0s - loss: 0.6446 - acc: 0.6047 - val_loss: 0.6532 - val_acc: 0.6438\n",
      "Epoch 59/100\n",
      "46/46 - 0s - loss: 0.6462 - acc: 0.6050 - val_loss: 0.6517 - val_acc: 0.6411\n",
      "Epoch 60/100\n",
      "46/46 - 0s - loss: 0.6444 - acc: 0.6036 - val_loss: 0.6555 - val_acc: 0.6438\n",
      "Epoch 61/100\n",
      "46/46 - 0s - loss: 0.6437 - acc: 0.6033 - val_loss: 0.6492 - val_acc: 0.6466\n",
      "Epoch 62/100\n",
      "46/46 - 0s - loss: 0.6445 - acc: 0.6057 - val_loss: 0.6533 - val_acc: 0.6397\n",
      "Epoch 63/100\n",
      "46/46 - 0s - loss: 0.6428 - acc: 0.6057 - val_loss: 0.6501 - val_acc: 0.6452\n",
      "Epoch 64/100\n",
      "46/46 - 0s - loss: 0.6430 - acc: 0.6036 - val_loss: 0.6522 - val_acc: 0.6411\n",
      "Epoch 65/100\n",
      "46/46 - 0s - loss: 0.6439 - acc: 0.6053 - val_loss: 0.6550 - val_acc: 0.6466\n",
      "Epoch 66/100\n",
      "46/46 - 0s - loss: 0.6436 - acc: 0.6029 - val_loss: 0.6523 - val_acc: 0.6452\n",
      "Epoch 67/100\n",
      "46/46 - 0s - loss: 0.6449 - acc: 0.6036 - val_loss: 0.6499 - val_acc: 0.6466\n",
      "Epoch 68/100\n",
      "46/46 - 0s - loss: 0.6433 - acc: 0.6043 - val_loss: 0.6485 - val_acc: 0.6452\n",
      "Epoch 69/100\n",
      "46/46 - 0s - loss: 0.6434 - acc: 0.6047 - val_loss: 0.6517 - val_acc: 0.6479\n",
      "Epoch 70/100\n",
      "46/46 - 0s - loss: 0.6430 - acc: 0.6029 - val_loss: 0.6515 - val_acc: 0.6479\n",
      "Epoch 71/100\n",
      "46/46 - 0s - loss: 0.6436 - acc: 0.6043 - val_loss: 0.6509 - val_acc: 0.6466\n",
      "Epoch 72/100\n",
      "46/46 - 0s - loss: 0.6447 - acc: 0.6040 - val_loss: 0.6510 - val_acc: 0.6411\n",
      "Epoch 73/100\n",
      "46/46 - 0s - loss: 0.6422 - acc: 0.6033 - val_loss: 0.6506 - val_acc: 0.6466\n",
      "Epoch 74/100\n",
      "46/46 - 0s - loss: 0.6429 - acc: 0.6057 - val_loss: 0.6575 - val_acc: 0.6411\n",
      "Epoch 75/100\n",
      "46/46 - 0s - loss: 0.6430 - acc: 0.6036 - val_loss: 0.6490 - val_acc: 0.6466\n",
      "Epoch 76/100\n",
      "46/46 - 0s - loss: 0.6419 - acc: 0.6050 - val_loss: 0.6558 - val_acc: 0.6411\n",
      "Epoch 77/100\n",
      "46/46 - 0s - loss: 0.6430 - acc: 0.6036 - val_loss: 0.6521 - val_acc: 0.6466\n",
      "Epoch 78/100\n",
      "46/46 - 0s - loss: 0.6417 - acc: 0.6005 - val_loss: 0.6526 - val_acc: 0.6384\n",
      "Epoch 79/100\n",
      "46/46 - 0s - loss: 0.6423 - acc: 0.6047 - val_loss: 0.6521 - val_acc: 0.6452\n",
      "Epoch 80/100\n",
      "46/46 - 0s - loss: 0.6443 - acc: 0.6036 - val_loss: 0.6519 - val_acc: 0.6479\n",
      "Epoch 81/100\n",
      "46/46 - 0s - loss: 0.6430 - acc: 0.6033 - val_loss: 0.6518 - val_acc: 0.6466\n",
      "Epoch 82/100\n",
      "46/46 - 0s - loss: 0.6431 - acc: 0.6036 - val_loss: 0.6495 - val_acc: 0.6466\n",
      "Epoch 83/100\n",
      "46/46 - 0s - loss: 0.6425 - acc: 0.6043 - val_loss: 0.6517 - val_acc: 0.6466\n",
      "Epoch 84/100\n",
      "46/46 - 0s - loss: 0.6425 - acc: 0.6040 - val_loss: 0.6532 - val_acc: 0.6452\n",
      "Epoch 85/100\n",
      "46/46 - 0s - loss: 0.6424 - acc: 0.6009 - val_loss: 0.6538 - val_acc: 0.6384\n",
      "Epoch 86/100\n",
      "46/46 - 0s - loss: 0.6422 - acc: 0.6047 - val_loss: 0.6527 - val_acc: 0.6411\n",
      "Epoch 87/100\n",
      "46/46 - 0s - loss: 0.6432 - acc: 0.6043 - val_loss: 0.6528 - val_acc: 0.6479\n",
      "Epoch 88/100\n",
      "46/46 - 0s - loss: 0.6416 - acc: 0.6029 - val_loss: 0.6526 - val_acc: 0.6425\n",
      "Epoch 89/100\n",
      "46/46 - 0s - loss: 0.6430 - acc: 0.6033 - val_loss: 0.6516 - val_acc: 0.6466\n",
      "Epoch 90/100\n",
      "46/46 - 0s - loss: 0.6426 - acc: 0.6033 - val_loss: 0.6517 - val_acc: 0.6397\n",
      "Epoch 91/100\n",
      "46/46 - 0s - loss: 0.6437 - acc: 0.6064 - val_loss: 0.6560 - val_acc: 0.6356\n",
      "Epoch 92/100\n",
      "46/46 - 0s - loss: 0.6421 - acc: 0.6057 - val_loss: 0.6527 - val_acc: 0.6438\n",
      "Epoch 93/100\n",
      "46/46 - 0s - loss: 0.6419 - acc: 0.6043 - val_loss: 0.6537 - val_acc: 0.6397\n",
      "Epoch 94/100\n",
      "46/46 - 0s - loss: 0.6426 - acc: 0.6023 - val_loss: 0.6547 - val_acc: 0.6384\n",
      "Epoch 95/100\n",
      "46/46 - 0s - loss: 0.6423 - acc: 0.6043 - val_loss: 0.6545 - val_acc: 0.6384\n",
      "Epoch 96/100\n",
      "46/46 - 0s - loss: 0.6434 - acc: 0.5995 - val_loss: 0.6525 - val_acc: 0.6397\n",
      "Epoch 97/100\n",
      "46/46 - 0s - loss: 0.6417 - acc: 0.6026 - val_loss: 0.6538 - val_acc: 0.6425\n",
      "Epoch 98/100\n",
      "46/46 - 0s - loss: 0.6418 - acc: 0.6050 - val_loss: 0.6565 - val_acc: 0.6370\n",
      "Epoch 99/100\n",
      "46/46 - 0s - loss: 0.6419 - acc: 0.6026 - val_loss: 0.6516 - val_acc: 0.6466\n",
      "Epoch 100/100\n",
      "46/46 - 0s - loss: 0.6418 - acc: 0.6033 - val_loss: 0.6556 - val_acc: 0.6370\n"
     ]
    }
   ],
   "source": [
    "hist_rnn3 = rnn3.fit(train_sequences,validation_data=test_sequences,\n",
    "                  epochs=100,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3836a946-7b63-44e6-aac7-4a638575d877",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:08:19.427294Z",
     "iopub.status.busy": "2021-08-27T04:08:19.427154Z",
     "iopub.status.idle": "2021-08-27T04:08:19.527164Z",
     "shell.execute_reply": "2021-08-27T04:08:19.526467Z",
     "shell.execute_reply.started": "2021-08-27T04:08:19.427277Z"
    },
    "id": "3836a946-7b63-44e6-aac7-4a638575d877",
    "outputId": "a7787238-1c64-4cdb-cb53-a6908008bb5d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc(hist_rnn3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc271875-55d7-4fea-bece-9f70d8ce7835",
   "metadata": {
    "id": "dc271875-55d7-4fea-bece-9f70d8ce7835"
   },
   "source": [
    "Got higher peak test accuracy and much better overall \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c06eb-5971-4eb0-b3c0-91ea7c00e1af",
   "metadata": {
    "id": "415c06eb-5971-4eb0-b3c0-91ea7c00e1af"
   },
   "source": [
    "### rnn4 <--rnn3\n",
    "add another GRU layer + dense layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "70d1f3c2-72d6-4717-8025-acec13038a73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:08:19.528081Z",
     "iopub.status.busy": "2021-08-27T04:08:19.527946Z",
     "iopub.status.idle": "2021-08-27T04:08:20.036259Z",
     "shell.execute_reply": "2021-08-27T04:08:20.035563Z",
     "shell.execute_reply.started": "2021-08-27T04:08:19.528063Z"
    },
    "id": "70d1f3c2-72d6-4717-8025-acec13038a73",
    "outputId": "f3b0ac0d-5641-4231-9e1f-2d7384d69506",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 1, 8)              480       \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (None, 1, 8)              432       \n",
      "_________________________________________________________________\n",
      "gru_9 (GRU)                  (None, 1, 8)              432       \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 8)                 432       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                90        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 2,119\n",
      "Trainable params: 2,119\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model network \n",
    "\n",
    "rnn4 = Sequential()\n",
    "\n",
    "rnn4.add(GRU(8,input_shape=input_shape, return_sequences=True))\n",
    "rnn4.add(GRU(8,return_sequences=True))\n",
    "rnn4.add(GRU(8,return_sequences=True))\n",
    "rnn4.add(GRU(8,return_sequences=False)) # false if next layer dense\n",
    "\n",
    "rnn4.add(Dense(10,activation='relu'))\n",
    "rnn4.add(Dense(10,activation='relu'))\n",
    "rnn4.add(Dense(10,activation='relu'))\n",
    "\n",
    "rnn4.add(Dense(3,activation='softmax'))\n",
    "\n",
    "# compile model \n",
    "rnn4.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "# show summary \n",
    "rnn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7026d5c9-f633-44a8-a13f-176ce33c04a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:08:20.037081Z",
     "iopub.status.busy": "2021-08-27T04:08:20.036971Z",
     "iopub.status.idle": "2021-08-27T04:09:00.063964Z",
     "shell.execute_reply": "2021-08-27T04:09:00.063432Z",
     "shell.execute_reply.started": "2021-08-27T04:08:20.037065Z"
    },
    "id": "7026d5c9-f633-44a8-a13f-176ce33c04a8",
    "outputId": "220a1949-3f62-4e0e-e819-fda385c52712",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 - 5s - loss: 1.0764 - acc: 0.4539 - val_loss: 1.0336 - val_acc: 0.5110\n",
      "Epoch 2/100\n",
      "46/46 - 0s - loss: 0.9690 - acc: 0.5135 - val_loss: 0.8376 - val_acc: 0.6342\n",
      "Epoch 3/100\n",
      "46/46 - 0s - loss: 0.7623 - acc: 0.5995 - val_loss: 0.6804 - val_acc: 0.6384\n",
      "Epoch 4/100\n",
      "46/46 - 0s - loss: 0.6894 - acc: 0.6012 - val_loss: 0.6601 - val_acc: 0.6438\n",
      "Epoch 5/100\n",
      "46/46 - 0s - loss: 0.6729 - acc: 0.6036 - val_loss: 0.6588 - val_acc: 0.6438\n",
      "Epoch 6/100\n",
      "46/46 - 0s - loss: 0.6620 - acc: 0.6074 - val_loss: 0.6473 - val_acc: 0.6452\n",
      "Epoch 7/100\n",
      "46/46 - 0s - loss: 0.6552 - acc: 0.5999 - val_loss: 0.6494 - val_acc: 0.6233\n",
      "Epoch 8/100\n",
      "46/46 - 0s - loss: 0.6510 - acc: 0.6019 - val_loss: 0.6401 - val_acc: 0.6342\n",
      "Epoch 9/100\n",
      "46/46 - 0s - loss: 0.6528 - acc: 0.6060 - val_loss: 0.6471 - val_acc: 0.6260\n",
      "Epoch 10/100\n",
      "46/46 - 0s - loss: 0.6498 - acc: 0.6016 - val_loss: 0.6509 - val_acc: 0.6219\n",
      "Epoch 11/100\n",
      "46/46 - 0s - loss: 0.6491 - acc: 0.5988 - val_loss: 0.6440 - val_acc: 0.6288\n",
      "Epoch 12/100\n",
      "46/46 - 0s - loss: 0.6486 - acc: 0.6016 - val_loss: 0.6423 - val_acc: 0.6315\n",
      "Epoch 13/100\n",
      "46/46 - 0s - loss: 0.6487 - acc: 0.6033 - val_loss: 0.6444 - val_acc: 0.6247\n",
      "Epoch 14/100\n",
      "46/46 - 0s - loss: 0.6491 - acc: 0.6043 - val_loss: 0.6421 - val_acc: 0.6370\n",
      "Epoch 15/100\n",
      "46/46 - 0s - loss: 0.6484 - acc: 0.6108 - val_loss: 0.6427 - val_acc: 0.6425\n",
      "Epoch 16/100\n",
      "46/46 - 0s - loss: 0.6483 - acc: 0.6043 - val_loss: 0.6438 - val_acc: 0.6479\n",
      "Epoch 17/100\n",
      "46/46 - 0s - loss: 0.6481 - acc: 0.6053 - val_loss: 0.6426 - val_acc: 0.6466\n",
      "Epoch 18/100\n",
      "46/46 - 0s - loss: 0.6489 - acc: 0.6040 - val_loss: 0.6475 - val_acc: 0.6411\n",
      "Epoch 19/100\n",
      "46/46 - 0s - loss: 0.6472 - acc: 0.6064 - val_loss: 0.6409 - val_acc: 0.6466\n",
      "Epoch 20/100\n",
      "46/46 - 0s - loss: 0.6484 - acc: 0.6043 - val_loss: 0.6432 - val_acc: 0.6479\n",
      "Epoch 21/100\n",
      "46/46 - 0s - loss: 0.6477 - acc: 0.6064 - val_loss: 0.6414 - val_acc: 0.6466\n",
      "Epoch 22/100\n",
      "46/46 - 0s - loss: 0.6471 - acc: 0.6047 - val_loss: 0.6464 - val_acc: 0.6411\n",
      "Epoch 23/100\n",
      "46/46 - 0s - loss: 0.6474 - acc: 0.6060 - val_loss: 0.6433 - val_acc: 0.6466\n",
      "Epoch 24/100\n",
      "46/46 - 0s - loss: 0.6478 - acc: 0.6043 - val_loss: 0.6439 - val_acc: 0.6466\n",
      "Epoch 25/100\n",
      "46/46 - 0s - loss: 0.6480 - acc: 0.6053 - val_loss: 0.6425 - val_acc: 0.6466\n",
      "Epoch 26/100\n",
      "46/46 - 0s - loss: 0.6481 - acc: 0.6095 - val_loss: 0.6416 - val_acc: 0.6466\n",
      "Epoch 27/100\n",
      "46/46 - 0s - loss: 0.6475 - acc: 0.6071 - val_loss: 0.6447 - val_acc: 0.6466\n",
      "Epoch 28/100\n",
      "46/46 - 0s - loss: 0.6464 - acc: 0.6050 - val_loss: 0.6422 - val_acc: 0.6466\n",
      "Epoch 29/100\n",
      "46/46 - 0s - loss: 0.6460 - acc: 0.6050 - val_loss: 0.6441 - val_acc: 0.6466\n",
      "Epoch 30/100\n",
      "46/46 - 0s - loss: 0.6461 - acc: 0.6057 - val_loss: 0.6416 - val_acc: 0.6466\n",
      "Epoch 31/100\n",
      "46/46 - 0s - loss: 0.6465 - acc: 0.6040 - val_loss: 0.6433 - val_acc: 0.6466\n",
      "Epoch 32/100\n",
      "46/46 - 0s - loss: 0.6463 - acc: 0.6060 - val_loss: 0.6468 - val_acc: 0.6411\n",
      "Epoch 33/100\n",
      "46/46 - 0s - loss: 0.6465 - acc: 0.6047 - val_loss: 0.6415 - val_acc: 0.6466\n",
      "Epoch 34/100\n",
      "46/46 - 0s - loss: 0.6467 - acc: 0.6036 - val_loss: 0.6535 - val_acc: 0.6384\n",
      "Epoch 35/100\n",
      "46/46 - 0s - loss: 0.6455 - acc: 0.6047 - val_loss: 0.6463 - val_acc: 0.6425\n",
      "Epoch 36/100\n",
      "46/46 - 0s - loss: 0.6455 - acc: 0.6047 - val_loss: 0.6451 - val_acc: 0.6438\n",
      "Epoch 37/100\n",
      "46/46 - 0s - loss: 0.6454 - acc: 0.6057 - val_loss: 0.6489 - val_acc: 0.6425\n",
      "Epoch 38/100\n",
      "46/46 - 0s - loss: 0.6457 - acc: 0.6053 - val_loss: 0.6467 - val_acc: 0.6438\n",
      "Epoch 39/100\n",
      "46/46 - 0s - loss: 0.6468 - acc: 0.6071 - val_loss: 0.6456 - val_acc: 0.6466\n",
      "Epoch 40/100\n",
      "46/46 - 0s - loss: 0.6460 - acc: 0.6047 - val_loss: 0.6470 - val_acc: 0.6425\n",
      "Epoch 41/100\n",
      "46/46 - 0s - loss: 0.6452 - acc: 0.6050 - val_loss: 0.6455 - val_acc: 0.6466\n",
      "Epoch 42/100\n",
      "46/46 - 0s - loss: 0.6454 - acc: 0.6050 - val_loss: 0.6437 - val_acc: 0.6466\n",
      "Epoch 43/100\n",
      "46/46 - 0s - loss: 0.6471 - acc: 0.6050 - val_loss: 0.6490 - val_acc: 0.6466\n",
      "Epoch 44/100\n",
      "46/46 - 0s - loss: 0.6452 - acc: 0.6050 - val_loss: 0.6475 - val_acc: 0.6452\n",
      "Epoch 45/100\n",
      "46/46 - 0s - loss: 0.6447 - acc: 0.6047 - val_loss: 0.6462 - val_acc: 0.6466\n",
      "Epoch 46/100\n",
      "46/46 - 0s - loss: 0.6446 - acc: 0.6033 - val_loss: 0.6448 - val_acc: 0.6466\n",
      "Epoch 47/100\n",
      "46/46 - 0s - loss: 0.6452 - acc: 0.6050 - val_loss: 0.6458 - val_acc: 0.6466\n",
      "Epoch 48/100\n",
      "46/46 - 0s - loss: 0.6443 - acc: 0.6047 - val_loss: 0.6494 - val_acc: 0.6466\n",
      "Epoch 49/100\n",
      "46/46 - 0s - loss: 0.6448 - acc: 0.6036 - val_loss: 0.6499 - val_acc: 0.6342\n",
      "Epoch 50/100\n",
      "46/46 - 0s - loss: 0.6459 - acc: 0.6057 - val_loss: 0.6481 - val_acc: 0.6466\n",
      "Epoch 51/100\n",
      "46/46 - 0s - loss: 0.6449 - acc: 0.6033 - val_loss: 0.6441 - val_acc: 0.6466\n",
      "Epoch 52/100\n",
      "46/46 - 0s - loss: 0.6468 - acc: 0.6047 - val_loss: 0.6453 - val_acc: 0.6466\n",
      "Epoch 53/100\n",
      "46/46 - 0s - loss: 0.6442 - acc: 0.6043 - val_loss: 0.6504 - val_acc: 0.6466\n",
      "Epoch 54/100\n",
      "46/46 - 0s - loss: 0.6466 - acc: 0.6043 - val_loss: 0.6473 - val_acc: 0.6452\n",
      "Epoch 55/100\n",
      "46/46 - 0s - loss: 0.6442 - acc: 0.6040 - val_loss: 0.6471 - val_acc: 0.6466\n",
      "Epoch 56/100\n",
      "46/46 - 0s - loss: 0.6442 - acc: 0.6047 - val_loss: 0.6485 - val_acc: 0.6466\n",
      "Epoch 57/100\n",
      "46/46 - 0s - loss: 0.6442 - acc: 0.6050 - val_loss: 0.6449 - val_acc: 0.6466\n",
      "Epoch 58/100\n",
      "46/46 - 0s - loss: 0.6436 - acc: 0.6050 - val_loss: 0.6489 - val_acc: 0.6466\n",
      "Epoch 59/100\n",
      "46/46 - 0s - loss: 0.6439 - acc: 0.6036 - val_loss: 0.6464 - val_acc: 0.6466\n",
      "Epoch 60/100\n",
      "46/46 - 0s - loss: 0.6444 - acc: 0.6050 - val_loss: 0.6470 - val_acc: 0.6466\n",
      "Epoch 61/100\n",
      "46/46 - 0s - loss: 0.6443 - acc: 0.6043 - val_loss: 0.6458 - val_acc: 0.6466\n",
      "Epoch 62/100\n",
      "46/46 - 0s - loss: 0.6428 - acc: 0.6050 - val_loss: 0.6476 - val_acc: 0.6466\n",
      "Epoch 63/100\n",
      "46/46 - 0s - loss: 0.6445 - acc: 0.6047 - val_loss: 0.6490 - val_acc: 0.6466\n",
      "Epoch 64/100\n",
      "46/46 - 0s - loss: 0.6432 - acc: 0.6047 - val_loss: 0.6469 - val_acc: 0.6466\n",
      "Epoch 65/100\n",
      "46/46 - 0s - loss: 0.6422 - acc: 0.6047 - val_loss: 0.6493 - val_acc: 0.6466\n",
      "Epoch 66/100\n",
      "46/46 - 0s - loss: 0.6437 - acc: 0.6050 - val_loss: 0.6494 - val_acc: 0.6466\n",
      "Epoch 67/100\n",
      "46/46 - 0s - loss: 0.6433 - acc: 0.6053 - val_loss: 0.6464 - val_acc: 0.6466\n",
      "Epoch 68/100\n",
      "46/46 - 0s - loss: 0.6425 - acc: 0.6050 - val_loss: 0.6498 - val_acc: 0.6466\n",
      "Epoch 69/100\n",
      "46/46 - 0s - loss: 0.6424 - acc: 0.6047 - val_loss: 0.6481 - val_acc: 0.6452\n",
      "Epoch 70/100\n",
      "46/46 - 0s - loss: 0.6423 - acc: 0.6053 - val_loss: 0.6461 - val_acc: 0.6466\n",
      "Epoch 71/100\n",
      "46/46 - 0s - loss: 0.6445 - acc: 0.6047 - val_loss: 0.6486 - val_acc: 0.6466\n",
      "Epoch 72/100\n",
      "46/46 - 0s - loss: 0.6430 - acc: 0.6053 - val_loss: 0.6457 - val_acc: 0.6466\n",
      "Epoch 73/100\n",
      "46/46 - 0s - loss: 0.6425 - acc: 0.6053 - val_loss: 0.6477 - val_acc: 0.6466\n",
      "Epoch 74/100\n",
      "46/46 - 0s - loss: 0.6443 - acc: 0.6047 - val_loss: 0.6492 - val_acc: 0.6452\n",
      "Epoch 75/100\n",
      "46/46 - 0s - loss: 0.6428 - acc: 0.6050 - val_loss: 0.6472 - val_acc: 0.6466\n",
      "Epoch 76/100\n",
      "46/46 - 0s - loss: 0.6420 - acc: 0.6053 - val_loss: 0.6495 - val_acc: 0.6466\n",
      "Epoch 77/100\n",
      "46/46 - 0s - loss: 0.6428 - acc: 0.6060 - val_loss: 0.6483 - val_acc: 0.6466\n",
      "Epoch 78/100\n",
      "46/46 - 0s - loss: 0.6426 - acc: 0.6040 - val_loss: 0.6482 - val_acc: 0.6452\n",
      "Epoch 79/100\n",
      "46/46 - 0s - loss: 0.6420 - acc: 0.6064 - val_loss: 0.6477 - val_acc: 0.6466\n",
      "Epoch 80/100\n",
      "46/46 - 0s - loss: 0.6426 - acc: 0.6043 - val_loss: 0.6472 - val_acc: 0.6452\n",
      "Epoch 81/100\n",
      "46/46 - 0s - loss: 0.6413 - acc: 0.6064 - val_loss: 0.6468 - val_acc: 0.6466\n",
      "Epoch 82/100\n",
      "46/46 - 0s - loss: 0.6417 - acc: 0.6064 - val_loss: 0.6461 - val_acc: 0.6466\n",
      "Epoch 83/100\n",
      "46/46 - 0s - loss: 0.6416 - acc: 0.6067 - val_loss: 0.6499 - val_acc: 0.6452\n",
      "Epoch 84/100\n",
      "46/46 - 0s - loss: 0.6421 - acc: 0.6060 - val_loss: 0.6500 - val_acc: 0.6466\n",
      "Epoch 85/100\n",
      "46/46 - 0s - loss: 0.6416 - acc: 0.6064 - val_loss: 0.6502 - val_acc: 0.6452\n",
      "Epoch 86/100\n",
      "46/46 - 0s - loss: 0.6412 - acc: 0.6057 - val_loss: 0.6522 - val_acc: 0.6466\n",
      "Epoch 87/100\n",
      "46/46 - 0s - loss: 0.6422 - acc: 0.6071 - val_loss: 0.6504 - val_acc: 0.6438\n",
      "Epoch 88/100\n",
      "46/46 - 0s - loss: 0.6411 - acc: 0.6060 - val_loss: 0.6470 - val_acc: 0.6452\n",
      "Epoch 89/100\n",
      "46/46 - 0s - loss: 0.6412 - acc: 0.6064 - val_loss: 0.6475 - val_acc: 0.6438\n",
      "Epoch 90/100\n",
      "46/46 - 0s - loss: 0.6424 - acc: 0.6064 - val_loss: 0.6484 - val_acc: 0.6452\n",
      "Epoch 91/100\n",
      "46/46 - 0s - loss: 0.6410 - acc: 0.6074 - val_loss: 0.6480 - val_acc: 0.6452\n",
      "Epoch 92/100\n",
      "46/46 - 0s - loss: 0.6426 - acc: 0.6057 - val_loss: 0.6534 - val_acc: 0.6452\n",
      "Epoch 93/100\n",
      "46/46 - 0s - loss: 0.6411 - acc: 0.6067 - val_loss: 0.6484 - val_acc: 0.6452\n",
      "Epoch 94/100\n",
      "46/46 - 0s - loss: 0.6422 - acc: 0.6057 - val_loss: 0.6574 - val_acc: 0.6452\n",
      "Epoch 95/100\n",
      "46/46 - 0s - loss: 0.6411 - acc: 0.6064 - val_loss: 0.6537 - val_acc: 0.6452\n",
      "Epoch 96/100\n",
      "46/46 - 0s - loss: 0.6410 - acc: 0.6071 - val_loss: 0.6499 - val_acc: 0.6466\n",
      "Epoch 97/100\n",
      "46/46 - 0s - loss: 0.6415 - acc: 0.6057 - val_loss: 0.6504 - val_acc: 0.6452\n",
      "Epoch 98/100\n",
      "46/46 - 0s - loss: 0.6398 - acc: 0.6064 - val_loss: 0.6498 - val_acc: 0.6452\n",
      "Epoch 99/100\n",
      "46/46 - 0s - loss: 0.6417 - acc: 0.6064 - val_loss: 0.6525 - val_acc: 0.6452\n",
      "Epoch 100/100\n",
      "46/46 - 0s - loss: 0.6414 - acc: 0.6047 - val_loss: 0.6509 - val_acc: 0.6452\n"
     ]
    }
   ],
   "source": [
    "hist_rnn4 = rnn4.fit(train_sequences,validation_data=test_sequences,\n",
    "                  epochs=100,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad8b227c-6d19-4160-93c4-d602dea8a0b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:00.065110Z",
     "iopub.status.busy": "2021-08-27T04:09:00.064880Z",
     "iopub.status.idle": "2021-08-27T04:09:00.166125Z",
     "shell.execute_reply": "2021-08-27T04:09:00.165534Z",
     "shell.execute_reply.started": "2021-08-27T04:09:00.065092Z"
    },
    "id": "ad8b227c-6d19-4160-93c4-d602dea8a0b8",
    "outputId": "9a4f49f0-ec5f-4ff5-bef1-e126360b9526"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc(hist_rnn4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a755811-1d81-438a-841e-5caf4b63a39e",
   "metadata": {
    "id": "0a755811-1d81-438a-841e-5caf4b63a39e"
   },
   "source": [
    "CAN PROBABLY OPTIMIZE THIS MORE WILL COME BACK "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463654d-5e96-4890-ac9a-f7a81170bd32",
   "metadata": {
    "id": "7463654d-5e96-4890-ac9a-f7a81170bd32"
   },
   "source": [
    "## LTSM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a0706690-3a44-4fb6-83f0-e672fac566ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:00.167009Z",
     "iopub.status.busy": "2021-08-27T04:09:00.166798Z",
     "iopub.status.idle": "2021-08-27T04:09:00.170749Z",
     "shell.execute_reply": "2021-08-27T04:09:00.170410Z",
     "shell.execute_reply.started": "2021-08-27T04:09:00.166990Z"
    },
    "id": "a0706690-3a44-4fb6-83f0-e672fac566ca",
    "outputId": "291cd591-a0f0-40af-fe8f-371e1cb517e6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2920, 10)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2c97810f-c297-45e8-bdb4-c307baab3521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:00.171499Z",
     "iopub.status.busy": "2021-08-27T04:09:00.171287Z",
     "iopub.status.idle": "2021-08-27T04:09:00.176220Z",
     "shell.execute_reply": "2021-08-27T04:09:00.175456Z",
     "shell.execute_reply.started": "2021-08-27T04:09:00.171483Z"
    },
    "id": "2c97810f-c297-45e8-bdb4-c307baab3521",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make df? \n",
    "X_train_lstm= np.reshape(Xs_train,(Xs_train.shape[0],1,Xs_train.shape[1]))\n",
    "X_test_lstm = np.reshape(Xs_test,(Xs_test.shape[0],1,Xs_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c52776f5-dd27-4feb-a4de-40faa7006d3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:00.177156Z",
     "iopub.status.busy": "2021-08-27T04:09:00.176937Z",
     "iopub.status.idle": "2021-08-27T04:09:00.180713Z",
     "shell.execute_reply": "2021-08-27T04:09:00.180412Z",
     "shell.execute_reply.started": "2021-08-27T04:09:00.177139Z"
    },
    "id": "c52776f5-dd27-4feb-a4de-40faa7006d3a",
    "outputId": "5bfdb7e9-da75-49ab-eb77-661bff851ec5",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2920, 1, 10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c0448f0b-a12a-4c61-99d6-22f89a823e29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:00.181409Z",
     "iopub.status.busy": "2021-08-27T04:09:00.181208Z",
     "iopub.status.idle": "2021-08-27T04:09:00.185046Z",
     "shell.execute_reply": "2021-08-27T04:09:00.184499Z",
     "shell.execute_reply.started": "2021-08-27T04:09:00.181394Z"
    },
    "id": "c0448f0b-a12a-4c61-99d6-22f89a823e29",
    "outputId": "260dd07a-c27a-42f4-dde5-6b60d95e7d2b",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 1, 10)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3b0cbc45-538e-4c5a-b906-de35bb5efcf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T11:24:24.816570Z",
     "iopub.status.busy": "2021-08-27T11:24:24.816376Z",
     "iopub.status.idle": "2021-08-27T11:24:25.004756Z",
     "shell.execute_reply": "2021-08-27T11:24:25.004089Z",
     "shell.execute_reply.started": "2021-08-27T11:24:24.816553Z"
    },
    "id": "3b0cbc45-538e-4c5a-b906-de35bb5efcf2",
    "outputId": "4d580bef-5640-4beb-aecf-92caf419a43c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_207\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_202 (LSTM)              (None, 40)                8160      \n",
      "_________________________________________________________________\n",
      "dense_621 (Dense)            (None, 30)                1230      \n",
      "_________________________________________________________________\n",
      "dense_622 (Dense)            (None, 3)                 93        \n",
      "=================================================================\n",
      "Total params: 9,483\n",
      "Trainable params: 9,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model network \n",
    "\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(40,input_shape=(1,10)))\n",
    "lstm.add(Dense(30,activation='relu'))\n",
    "lstm.add(Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "# compile model \n",
    "lstm.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2a78b401-3bdd-4719-b5d7-dd6a7329a7bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T11:24:33.754476Z",
     "iopub.status.busy": "2021-08-27T11:24:33.754281Z",
     "iopub.status.idle": "2021-08-27T11:24:57.570597Z",
     "shell.execute_reply": "2021-08-27T11:24:57.569817Z",
     "shell.execute_reply.started": "2021-08-27T11:24:33.754459Z"
    },
    "id": "2a78b401-3bdd-4719-b5d7-dd6a7329a7bc",
    "outputId": "5563b0cb-28ec-4850-ed57-de8a6f336b5d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 - 1s - loss: 0.9281 - acc: 0.6298 - val_loss: 0.7032 - val_acc: 0.7497\n",
      "Epoch 2/100\n",
      "92/92 - 0s - loss: 0.5597 - acc: 0.7818 - val_loss: 0.5019 - val_acc: 0.7811\n",
      "Epoch 3/100\n",
      "92/92 - 0s - loss: 0.4025 - acc: 0.8243 - val_loss: 0.5251 - val_acc: 0.7661\n",
      "Epoch 4/100\n",
      "92/92 - 0s - loss: 0.3713 - acc: 0.8168 - val_loss: 0.5381 - val_acc: 0.7866\n",
      "Epoch 5/100\n",
      "92/92 - 0s - loss: 0.3638 - acc: 0.8271 - val_loss: 0.5426 - val_acc: 0.7880\n",
      "Epoch 6/100\n",
      "92/92 - 0s - loss: 0.3587 - acc: 0.8288 - val_loss: 0.5472 - val_acc: 0.7866\n",
      "Epoch 7/100\n",
      "92/92 - 0s - loss: 0.3569 - acc: 0.8322 - val_loss: 0.5448 - val_acc: 0.7715\n",
      "Epoch 8/100\n",
      "92/92 - 0s - loss: 0.3544 - acc: 0.8260 - val_loss: 0.5334 - val_acc: 0.7825\n",
      "Epoch 9/100\n",
      "92/92 - 0s - loss: 0.3519 - acc: 0.8308 - val_loss: 0.5380 - val_acc: 0.7839\n",
      "Epoch 10/100\n",
      "92/92 - 0s - loss: 0.3498 - acc: 0.8267 - val_loss: 0.5319 - val_acc: 0.7702\n",
      "Epoch 11/100\n",
      "92/92 - 0s - loss: 0.3474 - acc: 0.8349 - val_loss: 0.5299 - val_acc: 0.7907\n",
      "Epoch 12/100\n",
      "92/92 - 0s - loss: 0.3452 - acc: 0.8332 - val_loss: 0.5289 - val_acc: 0.7729\n",
      "Epoch 13/100\n",
      "92/92 - 0s - loss: 0.3439 - acc: 0.8380 - val_loss: 0.5204 - val_acc: 0.7729\n",
      "Epoch 14/100\n",
      "92/92 - 0s - loss: 0.3437 - acc: 0.8277 - val_loss: 0.5144 - val_acc: 0.7866\n",
      "Epoch 15/100\n",
      "92/92 - 0s - loss: 0.3410 - acc: 0.8370 - val_loss: 0.5155 - val_acc: 0.7907\n",
      "Epoch 16/100\n",
      "92/92 - 0s - loss: 0.3408 - acc: 0.8353 - val_loss: 0.5096 - val_acc: 0.7934\n",
      "Epoch 17/100\n",
      "92/92 - 0s - loss: 0.3399 - acc: 0.8366 - val_loss: 0.5076 - val_acc: 0.7921\n",
      "Epoch 18/100\n",
      "92/92 - 0s - loss: 0.3382 - acc: 0.8325 - val_loss: 0.5039 - val_acc: 0.7921\n",
      "Epoch 19/100\n",
      "92/92 - 0s - loss: 0.3379 - acc: 0.8349 - val_loss: 0.5052 - val_acc: 0.7948\n",
      "Epoch 20/100\n",
      "92/92 - 0s - loss: 0.3362 - acc: 0.8356 - val_loss: 0.5010 - val_acc: 0.7948\n",
      "Epoch 21/100\n",
      "92/92 - 0s - loss: 0.3350 - acc: 0.8394 - val_loss: 0.4961 - val_acc: 0.8016\n",
      "Epoch 22/100\n",
      "92/92 - 0s - loss: 0.3347 - acc: 0.8346 - val_loss: 0.5015 - val_acc: 0.7893\n",
      "Epoch 23/100\n",
      "92/92 - 0s - loss: 0.3331 - acc: 0.8384 - val_loss: 0.5026 - val_acc: 0.7839\n",
      "Epoch 24/100\n",
      "92/92 - 0s - loss: 0.3344 - acc: 0.8295 - val_loss: 0.5059 - val_acc: 0.7880\n",
      "Epoch 25/100\n",
      "92/92 - 0s - loss: 0.3317 - acc: 0.8394 - val_loss: 0.5012 - val_acc: 0.7839\n",
      "Epoch 26/100\n",
      "92/92 - 0s - loss: 0.3325 - acc: 0.8346 - val_loss: 0.5040 - val_acc: 0.7962\n",
      "Epoch 27/100\n",
      "92/92 - 0s - loss: 0.3308 - acc: 0.8401 - val_loss: 0.4976 - val_acc: 0.8030\n",
      "Epoch 28/100\n",
      "92/92 - 0s - loss: 0.3308 - acc: 0.8366 - val_loss: 0.4952 - val_acc: 0.8085\n",
      "Epoch 29/100\n",
      "92/92 - 0s - loss: 0.3308 - acc: 0.8394 - val_loss: 0.4926 - val_acc: 0.8057\n",
      "Epoch 30/100\n",
      "92/92 - 0s - loss: 0.3298 - acc: 0.8394 - val_loss: 0.5043 - val_acc: 0.7962\n",
      "Epoch 31/100\n",
      "92/92 - 0s - loss: 0.3291 - acc: 0.8373 - val_loss: 0.4996 - val_acc: 0.7962\n",
      "Epoch 32/100\n",
      "92/92 - 0s - loss: 0.3289 - acc: 0.8349 - val_loss: 0.4971 - val_acc: 0.7962\n",
      "Epoch 33/100\n",
      "92/92 - 0s - loss: 0.3281 - acc: 0.8380 - val_loss: 0.4937 - val_acc: 0.8003\n",
      "Epoch 34/100\n",
      "92/92 - 0s - loss: 0.3282 - acc: 0.8394 - val_loss: 0.4941 - val_acc: 0.7975\n",
      "Epoch 35/100\n",
      "92/92 - 0s - loss: 0.3266 - acc: 0.8384 - val_loss: 0.4972 - val_acc: 0.7975\n",
      "Epoch 36/100\n",
      "92/92 - 0s - loss: 0.3293 - acc: 0.8360 - val_loss: 0.5043 - val_acc: 0.7975\n",
      "Epoch 37/100\n",
      "92/92 - 0s - loss: 0.3263 - acc: 0.8390 - val_loss: 0.4995 - val_acc: 0.7975\n",
      "Epoch 38/100\n",
      "92/92 - 0s - loss: 0.3259 - acc: 0.8411 - val_loss: 0.4945 - val_acc: 0.7962\n",
      "Epoch 39/100\n",
      "92/92 - 0s - loss: 0.3266 - acc: 0.8418 - val_loss: 0.4963 - val_acc: 0.7989\n",
      "Epoch 40/100\n",
      "92/92 - 0s - loss: 0.3265 - acc: 0.8336 - val_loss: 0.4949 - val_acc: 0.7893\n",
      "Epoch 41/100\n",
      "92/92 - 0s - loss: 0.3256 - acc: 0.8418 - val_loss: 0.5043 - val_acc: 0.7852\n",
      "Epoch 42/100\n",
      "92/92 - 0s - loss: 0.3257 - acc: 0.8377 - val_loss: 0.4995 - val_acc: 0.8016\n",
      "Epoch 43/100\n",
      "92/92 - 0s - loss: 0.3248 - acc: 0.8397 - val_loss: 0.4993 - val_acc: 0.7975\n",
      "Epoch 44/100\n",
      "92/92 - 0s - loss: 0.3238 - acc: 0.8373 - val_loss: 0.4939 - val_acc: 0.7975\n",
      "Epoch 45/100\n",
      "92/92 - 0s - loss: 0.3268 - acc: 0.8394 - val_loss: 0.4899 - val_acc: 0.7989\n",
      "Epoch 46/100\n",
      "92/92 - 0s - loss: 0.3248 - acc: 0.8353 - val_loss: 0.4916 - val_acc: 0.7921\n",
      "Epoch 47/100\n",
      "92/92 - 0s - loss: 0.3238 - acc: 0.8363 - val_loss: 0.4900 - val_acc: 0.8003\n",
      "Epoch 48/100\n",
      "92/92 - 0s - loss: 0.3238 - acc: 0.8384 - val_loss: 0.4901 - val_acc: 0.8016\n",
      "Epoch 49/100\n",
      "92/92 - 0s - loss: 0.3237 - acc: 0.8377 - val_loss: 0.4965 - val_acc: 0.7989\n",
      "Epoch 50/100\n",
      "92/92 - 0s - loss: 0.3232 - acc: 0.8408 - val_loss: 0.4939 - val_acc: 0.7921\n",
      "Epoch 51/100\n",
      "92/92 - 0s - loss: 0.3230 - acc: 0.8428 - val_loss: 0.4976 - val_acc: 0.7811\n",
      "Epoch 52/100\n",
      "92/92 - 0s - loss: 0.3229 - acc: 0.8373 - val_loss: 0.4923 - val_acc: 0.7962\n",
      "Epoch 53/100\n",
      "92/92 - 0s - loss: 0.3225 - acc: 0.8373 - val_loss: 0.4922 - val_acc: 0.7934\n",
      "Epoch 54/100\n",
      "92/92 - 0s - loss: 0.3232 - acc: 0.8387 - val_loss: 0.4933 - val_acc: 0.7852\n",
      "Epoch 55/100\n",
      "92/92 - 0s - loss: 0.3219 - acc: 0.8411 - val_loss: 0.4990 - val_acc: 0.7948\n",
      "Epoch 56/100\n",
      "92/92 - 0s - loss: 0.3217 - acc: 0.8432 - val_loss: 0.4982 - val_acc: 0.7975\n",
      "Epoch 57/100\n",
      "92/92 - 0s - loss: 0.3213 - acc: 0.8394 - val_loss: 0.4962 - val_acc: 0.7839\n",
      "Epoch 58/100\n",
      "92/92 - 0s - loss: 0.3216 - acc: 0.8363 - val_loss: 0.4978 - val_acc: 0.7866\n",
      "Epoch 59/100\n",
      "92/92 - 0s - loss: 0.3220 - acc: 0.8394 - val_loss: 0.4926 - val_acc: 0.7975\n",
      "Epoch 60/100\n",
      "92/92 - 0s - loss: 0.3208 - acc: 0.8428 - val_loss: 0.4982 - val_acc: 0.7989\n",
      "Epoch 61/100\n",
      "92/92 - 0s - loss: 0.3210 - acc: 0.8322 - val_loss: 0.4980 - val_acc: 0.8016\n",
      "Epoch 62/100\n",
      "92/92 - 0s - loss: 0.3206 - acc: 0.8408 - val_loss: 0.5040 - val_acc: 0.7948\n",
      "Epoch 63/100\n",
      "92/92 - 0s - loss: 0.3205 - acc: 0.8387 - val_loss: 0.4957 - val_acc: 0.7975\n",
      "Epoch 64/100\n",
      "92/92 - 0s - loss: 0.3211 - acc: 0.8377 - val_loss: 0.4906 - val_acc: 0.7934\n",
      "Epoch 65/100\n",
      "92/92 - 0s - loss: 0.3203 - acc: 0.8401 - val_loss: 0.5023 - val_acc: 0.7975\n",
      "Epoch 66/100\n",
      "92/92 - 0s - loss: 0.3192 - acc: 0.8425 - val_loss: 0.4998 - val_acc: 0.7866\n",
      "Epoch 67/100\n",
      "92/92 - 0s - loss: 0.3197 - acc: 0.8370 - val_loss: 0.4950 - val_acc: 0.7934\n",
      "Epoch 68/100\n",
      "92/92 - 0s - loss: 0.3192 - acc: 0.8425 - val_loss: 0.4970 - val_acc: 0.7907\n",
      "Epoch 69/100\n",
      "92/92 - 0s - loss: 0.3201 - acc: 0.8425 - val_loss: 0.5022 - val_acc: 0.8003\n",
      "Epoch 70/100\n",
      "92/92 - 0s - loss: 0.3188 - acc: 0.8370 - val_loss: 0.5050 - val_acc: 0.7975\n",
      "Epoch 71/100\n",
      "92/92 - 0s - loss: 0.3197 - acc: 0.8421 - val_loss: 0.4995 - val_acc: 0.7839\n",
      "Epoch 72/100\n",
      "92/92 - 0s - loss: 0.3188 - acc: 0.8408 - val_loss: 0.4914 - val_acc: 0.8003\n",
      "Epoch 73/100\n",
      "92/92 - 0s - loss: 0.3181 - acc: 0.8380 - val_loss: 0.4993 - val_acc: 0.7825\n",
      "Epoch 74/100\n",
      "92/92 - 0s - loss: 0.3204 - acc: 0.8387 - val_loss: 0.4941 - val_acc: 0.7989\n",
      "Epoch 75/100\n",
      "92/92 - 0s - loss: 0.3186 - acc: 0.8438 - val_loss: 0.4992 - val_acc: 0.8003\n",
      "Epoch 76/100\n",
      "92/92 - 0s - loss: 0.3186 - acc: 0.8373 - val_loss: 0.5003 - val_acc: 0.7948\n",
      "Epoch 77/100\n",
      "92/92 - 0s - loss: 0.3177 - acc: 0.8394 - val_loss: 0.4933 - val_acc: 0.7934\n",
      "Epoch 78/100\n",
      "92/92 - 0s - loss: 0.3175 - acc: 0.8408 - val_loss: 0.4919 - val_acc: 0.7852\n",
      "Epoch 79/100\n",
      "92/92 - 0s - loss: 0.3176 - acc: 0.8421 - val_loss: 0.5016 - val_acc: 0.7962\n",
      "Epoch 80/100\n",
      "92/92 - 0s - loss: 0.3177 - acc: 0.8366 - val_loss: 0.4976 - val_acc: 0.7839\n",
      "Epoch 81/100\n",
      "92/92 - 0s - loss: 0.3178 - acc: 0.8445 - val_loss: 0.4963 - val_acc: 0.7962\n",
      "Epoch 82/100\n",
      "92/92 - 0s - loss: 0.3182 - acc: 0.8414 - val_loss: 0.4925 - val_acc: 0.8016\n",
      "Epoch 83/100\n",
      "92/92 - 0s - loss: 0.3181 - acc: 0.8384 - val_loss: 0.4954 - val_acc: 0.7989\n",
      "Epoch 84/100\n",
      "92/92 - 0s - loss: 0.3163 - acc: 0.8432 - val_loss: 0.4935 - val_acc: 0.8030\n",
      "Epoch 85/100\n",
      "92/92 - 0s - loss: 0.3175 - acc: 0.8421 - val_loss: 0.4939 - val_acc: 0.7962\n",
      "Epoch 86/100\n",
      "92/92 - 0s - loss: 0.3159 - acc: 0.8432 - val_loss: 0.4995 - val_acc: 0.7975\n",
      "Epoch 87/100\n",
      "92/92 - 0s - loss: 0.3165 - acc: 0.8360 - val_loss: 0.5036 - val_acc: 0.7784\n",
      "Epoch 88/100\n",
      "92/92 - 0s - loss: 0.3155 - acc: 0.8363 - val_loss: 0.5004 - val_acc: 0.7975\n",
      "Epoch 89/100\n",
      "92/92 - 0s - loss: 0.3168 - acc: 0.8449 - val_loss: 0.5033 - val_acc: 0.7989\n",
      "Epoch 90/100\n",
      "92/92 - 0s - loss: 0.3153 - acc: 0.8459 - val_loss: 0.4927 - val_acc: 0.8016\n",
      "Epoch 91/100\n",
      "92/92 - 0s - loss: 0.3162 - acc: 0.8411 - val_loss: 0.5061 - val_acc: 0.7975\n",
      "Epoch 92/100\n",
      "92/92 - 0s - loss: 0.3158 - acc: 0.8418 - val_loss: 0.5023 - val_acc: 0.8030\n",
      "Epoch 93/100\n",
      "92/92 - 0s - loss: 0.3163 - acc: 0.8452 - val_loss: 0.4992 - val_acc: 0.8030\n",
      "Epoch 94/100\n",
      "92/92 - 0s - loss: 0.3153 - acc: 0.8421 - val_loss: 0.5013 - val_acc: 0.7852\n",
      "Epoch 95/100\n",
      "92/92 - 0s - loss: 0.3156 - acc: 0.8332 - val_loss: 0.4994 - val_acc: 0.8016\n",
      "Epoch 96/100\n",
      "92/92 - 0s - loss: 0.3150 - acc: 0.8459 - val_loss: 0.4950 - val_acc: 0.8003\n",
      "Epoch 97/100\n",
      "92/92 - 0s - loss: 0.3146 - acc: 0.8421 - val_loss: 0.4996 - val_acc: 0.8044\n",
      "Epoch 98/100\n",
      "92/92 - 0s - loss: 0.3142 - acc: 0.8353 - val_loss: 0.4936 - val_acc: 0.7975\n",
      "Epoch 99/100\n",
      "92/92 - 0s - loss: 0.3139 - acc: 0.8408 - val_loss: 0.4986 - val_acc: 0.7811\n",
      "Epoch 100/100\n",
      "92/92 - 0s - loss: 0.3152 - acc: 0.8401 - val_loss: 0.4918 - val_acc: 0.7934\n"
     ]
    }
   ],
   "source": [
    "# fit model \n",
    "hist_lstm = lstm.fit(X_train_lstm,y_train_nn,\n",
    "                     validation_data=(X_test_lstm,y_test_nn),\n",
    "                  epochs=100,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "fe2e7f29-0d2e-4522-bb18-a0c3ea697e28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T11:27:37.758172Z",
     "iopub.status.busy": "2021-08-27T11:27:37.757975Z",
     "iopub.status.idle": "2021-08-27T11:27:37.848600Z",
     "shell.execute_reply": "2021-08-27T11:27:37.847817Z",
     "shell.execute_reply.started": "2021-08-27T11:27:37.758155Z"
    },
    "id": "fe2e7f29-0d2e-4522-bb18-a0c3ea697e28",
    "outputId": "26533696-4388-4f12-833b-40af2e7d5cdb",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc(hist_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349f3f7-c720-49d2-8e67-4f382771b480",
   "metadata": {
    "id": "b349f3f7-c720-49d2-8e67-4f382771b480"
   },
   "source": [
    "- Try more complex model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897fd3ed-3e7e-4dcd-b26f-09a25c5fa12e",
   "metadata": {
    "id": "897fd3ed-3e7e-4dcd-b26f-09a25c5fa12e"
   },
   "source": [
    "### GridSearch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "811d43bd-650b-4cc7-826b-9e84254e23bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:42.361867Z",
     "iopub.status.busy": "2021-08-27T04:09:42.361714Z",
     "iopub.status.idle": "2021-08-27T04:09:42.366875Z",
     "shell.execute_reply": "2021-08-27T04:09:42.366181Z",
     "shell.execute_reply.started": "2021-08-27T04:09:42.361851Z"
    },
    "id": "811d43bd-650b-4cc7-826b-9e84254e23bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to make models \n",
    "def model_func_lstm(nodes_lstm,nodes_dense):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nodes_lstm,input_shape=(1,10)))\n",
    "    model.add(Dense(nodes_dense,activation='relu'))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6da509a7-b46f-4591-8caf-37885fc46b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:42.368133Z",
     "iopub.status.busy": "2021-08-27T04:09:42.367929Z",
     "iopub.status.idle": "2021-08-27T04:09:42.372201Z",
     "shell.execute_reply": "2021-08-27T04:09:42.371253Z",
     "shell.execute_reply.started": "2021-08-27T04:09:42.368101Z"
    },
    "id": "6da509a7-b46f-4591-8caf-37885fc46b6d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wrapper \n",
    "lstm_modeler = KerasClassifier(build_fn=model_func_lstm,epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2eda344e-905f-4402-851b-4f2b5bc32401",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:42.373396Z",
     "iopub.status.busy": "2021-08-27T04:09:42.373215Z",
     "iopub.status.idle": "2021-08-27T04:09:42.377412Z",
     "shell.execute_reply": "2021-08-27T04:09:42.376242Z",
     "shell.execute_reply.started": "2021-08-27T04:09:42.373378Z"
    },
    "id": "2eda344e-905f-4402-851b-4f2b5bc32401",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# params to search over \n",
    "params_lstm = {\n",
    "    'nodes_lstm':[8,64,120,240],\n",
    "    'nodes_dense':[8,64,120,240]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "32aa986a-2a9b-491c-bf6c-343a138cdd5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:42.378786Z",
     "iopub.status.busy": "2021-08-27T04:09:42.378581Z",
     "iopub.status.idle": "2021-08-27T04:09:42.383054Z",
     "shell.execute_reply": "2021-08-27T04:09:42.382268Z",
     "shell.execute_reply.started": "2021-08-27T04:09:42.378766Z"
    },
    "id": "32aa986a-2a9b-491c-bf6c-343a138cdd5c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate grid search \n",
    "lstm_gs = GridSearchCV(lstm_modeler,params_lstm,cv=3,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fec257b4-9ec2-4b6e-821b-3b74d94fc586",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:09:42.384475Z",
     "iopub.status.busy": "2021-08-27T04:09:42.384289Z",
     "iopub.status.idle": "2021-08-27T04:18:17.310822Z",
     "shell.execute_reply": "2021-08-27T04:18:17.309372Z",
     "shell.execute_reply.started": "2021-08-27T04:09:42.384456Z"
    },
    "id": "fec257b4-9ec2-4b6e-821b-3b74d94fc586",
    "outputId": "ad2e72a9-a40b-4f00-c40f-d2eb67d0cb59",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/61 [==============================] - 1s 2ms/step - loss: 1.0974 - acc: 0.3417\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.0322 - acc: 0.4923\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.9657 - acc: 0.5252\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8719 - acc: 0.5884\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7419 - acc: 0.7194\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6348 - acc: 0.7333\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5626 - acc: 0.7441\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5034 - acc: 0.7631\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4570 - acc: 0.7785\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4251 - acc: 0.7914\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4052 - acc: 0.7955\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3938 - acc: 0.8027\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3855 - acc: 0.8001\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3795 - acc: 0.8016\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3758 - acc: 0.8119\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3717 - acc: 0.8088\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3690 - acc: 0.8088\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3669 - acc: 0.8109\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3644 - acc: 0.8083\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3623 - acc: 0.8083\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3606 - acc: 0.8140\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3594 - acc: 0.8124\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3575 - acc: 0.8160\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3575 - acc: 0.8094\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3562 - acc: 0.8104\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3545 - acc: 0.8160\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3541 - acc: 0.8160\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3528 - acc: 0.8150\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3524 - acc: 0.8068\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3521 - acc: 0.8088\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3507 - acc: 0.8150\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3515 - acc: 0.8094\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3498 - acc: 0.8155\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3487 - acc: 0.8165\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3488 - acc: 0.8155\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3491 - acc: 0.8145\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3480 - acc: 0.8135\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3464 - acc: 0.8160\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3469 - acc: 0.8160\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3458 - acc: 0.8165\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3458 - acc: 0.8176\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3450 - acc: 0.8165\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3447 - acc: 0.8150\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3443 - acc: 0.8186\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3443 - acc: 0.8222\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3436 - acc: 0.8196\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3427 - acc: 0.8114\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3424 - acc: 0.8176\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3419 - acc: 0.8181\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3419 - acc: 0.8212\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4554 - acc: 0.8573\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 1.0844 - acc: 0.4263\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 1.0049 - acc: 0.5213\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.9162 - acc: 0.5244\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8149 - acc: 0.6677\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7151 - acc: 0.7021\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6285 - acc: 0.7411\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5590 - acc: 0.7612\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5076 - acc: 0.7786\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4722 - acc: 0.7915\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4490 - acc: 0.7899\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4317 - acc: 0.7966\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4200 - acc: 0.8079\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4112 - acc: 0.8141\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4039 - acc: 0.8115\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3992 - acc: 0.8130\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3948 - acc: 0.8202\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3919 - acc: 0.8218\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3888 - acc: 0.8207\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3868 - acc: 0.8197\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3838 - acc: 0.8141\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3820 - acc: 0.8207\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3804 - acc: 0.8207\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3791 - acc: 0.8202\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3775 - acc: 0.8218\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3765 - acc: 0.8223\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3741 - acc: 0.8249\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3739 - acc: 0.8202\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3727 - acc: 0.8223\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3716 - acc: 0.8264\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3709 - acc: 0.8254\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3697 - acc: 0.8223\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3685 - acc: 0.8243\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3681 - acc: 0.8254\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3675 - acc: 0.8259\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3667 - acc: 0.8274\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3660 - acc: 0.8274\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3654 - acc: 0.8279\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3652 - acc: 0.8254\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3647 - acc: 0.8269\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3638 - acc: 0.8264\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3635 - acc: 0.8285\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3636 - acc: 0.8197\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3620 - acc: 0.8285\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3621 - acc: 0.8274\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3618 - acc: 0.8249\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3608 - acc: 0.8285\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3617 - acc: 0.8305\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3604 - acc: 0.8300\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3599 - acc: 0.8274\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3596 - acc: 0.8274\n",
      "31/31 [==============================] - 0s 961us/step - loss: 0.2938 - acc: 0.8479\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 1.0728 - acc: 0.4093\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.9968 - acc: 0.4977\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.9132 - acc: 0.5516\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8122 - acc: 0.7088\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6891 - acc: 0.7750\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5656 - acc: 0.8177\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4714 - acc: 0.8295\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4065 - acc: 0.8382\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3679 - acc: 0.8377\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3452 - acc: 0.8392\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3306 - acc: 0.8449\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3207 - acc: 0.8505\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3145 - acc: 0.8557\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3092 - acc: 0.8562\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3058 - acc: 0.8531\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3031 - acc: 0.8577\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3019 - acc: 0.8572\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2988 - acc: 0.8531\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2978 - acc: 0.8531\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2963 - acc: 0.8593\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2952 - acc: 0.8552\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2939 - acc: 0.8613\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2932 - acc: 0.8557\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2906 - acc: 0.8603\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2899 - acc: 0.8582\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2891 - acc: 0.8567\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2877 - acc: 0.8567\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2874 - acc: 0.8536\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2866 - acc: 0.8541\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2854 - acc: 0.8552\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2840 - acc: 0.8608\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2830 - acc: 0.8552\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2816 - acc: 0.8603\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2804 - acc: 0.8613\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2798 - acc: 0.8603\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2799 - acc: 0.8608\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2782 - acc: 0.8598\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2775 - acc: 0.8582\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2775 - acc: 0.8659\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2765 - acc: 0.8731\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2765 - acc: 0.8685\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2760 - acc: 0.8731\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2742 - acc: 0.8757\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2757 - acc: 0.8726\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2742 - acc: 0.8685\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2732 - acc: 0.8665\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2728 - acc: 0.8757\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2722 - acc: 0.8757\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2719 - acc: 0.8654\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2716 - acc: 0.8757\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6390 - acc: 0.7513\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 1.0284 - acc: 0.6269\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8177 - acc: 0.7667\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.6103 - acc: 0.7893\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4766 - acc: 0.8001\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4217 - acc: 0.8016\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3978 - acc: 0.8058\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3862 - acc: 0.8119\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3772 - acc: 0.8094\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3727 - acc: 0.8022\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3680 - acc: 0.8073\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3657 - acc: 0.8083\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3627 - acc: 0.8114\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3600 - acc: 0.8155\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3579 - acc: 0.8155\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3577 - acc: 0.7991\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3544 - acc: 0.8160\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3529 - acc: 0.8145\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3520 - acc: 0.8140\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3513 - acc: 0.8212\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3508 - acc: 0.8165\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3495 - acc: 0.8155\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3470 - acc: 0.8196\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3470 - acc: 0.8129\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3462 - acc: 0.8119\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3463 - acc: 0.8191\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3446 - acc: 0.8119\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3437 - acc: 0.8181\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3425 - acc: 0.8135\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3412 - acc: 0.8207\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3414 - acc: 0.8160\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3410 - acc: 0.8109\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3403 - acc: 0.8165\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3398 - acc: 0.8191\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3393 - acc: 0.8176\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3376 - acc: 0.8248\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3423 - acc: 0.8135\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3391 - acc: 0.8104\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3384 - acc: 0.8201\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3380 - acc: 0.8191\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3369 - acc: 0.8212\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3388 - acc: 0.8083\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3365 - acc: 0.8191\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3342 - acc: 0.8176\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3356 - acc: 0.8145\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3349 - acc: 0.8181\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3341 - acc: 0.8068\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3330 - acc: 0.8232\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3337 - acc: 0.8165\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3334 - acc: 0.8222\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3340 - acc: 0.8150\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4842 - acc: 0.8491\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 1.0133 - acc: 0.6620\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.7911 - acc: 0.7689\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.5721 - acc: 0.7812\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4663 - acc: 0.7966\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4369 - acc: 0.7976\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4235 - acc: 0.7987\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4162 - acc: 0.8002\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4127 - acc: 0.8007\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4071 - acc: 0.8059\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4045 - acc: 0.8043\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4011 - acc: 0.8079\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4004 - acc: 0.8023\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3959 - acc: 0.8064\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3943 - acc: 0.8074\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3937 - acc: 0.8023\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3905 - acc: 0.8033\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3884 - acc: 0.8182\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3853 - acc: 0.8197\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3793 - acc: 0.8182\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3745 - acc: 0.8182\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3722 - acc: 0.8207\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3715 - acc: 0.8177\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3704 - acc: 0.8254\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3698 - acc: 0.8172\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3679 - acc: 0.8151\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3666 - acc: 0.8249\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3668 - acc: 0.8269\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3657 - acc: 0.8213\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3643 - acc: 0.8254\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3628 - acc: 0.8233\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3615 - acc: 0.8238\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3611 - acc: 0.8274\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3612 - acc: 0.8254\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3601 - acc: 0.8285\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3586 - acc: 0.8243\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3583 - acc: 0.8223\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3584 - acc: 0.8279\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3580 - acc: 0.8187\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3568 - acc: 0.8310\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3559 - acc: 0.8310\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3550 - acc: 0.8310\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3550 - acc: 0.8202\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3555 - acc: 0.8279\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3549 - acc: 0.8290\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3549 - acc: 0.8207\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3548 - acc: 0.8254\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3522 - acc: 0.8264\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3525 - acc: 0.8305\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3531 - acc: 0.8300\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3506 - acc: 0.8362\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2972 - acc: 0.8520\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.9726 - acc: 0.6420\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.7079 - acc: 0.7627\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4783 - acc: 0.8418\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3697 - acc: 0.8588\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3230 - acc: 0.8608\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3011 - acc: 0.8670\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2902 - acc: 0.8629\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2844 - acc: 0.8629\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2782 - acc: 0.8685\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2758 - acc: 0.8629\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2728 - acc: 0.8680\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2712 - acc: 0.8695\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2706 - acc: 0.8665\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2694 - acc: 0.8711\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2686 - acc: 0.8675\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2690 - acc: 0.8726\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2681 - acc: 0.8711\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2655 - acc: 0.8680\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2650 - acc: 0.8742\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2651 - acc: 0.8695\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2633 - acc: 0.8783\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2634 - acc: 0.8731\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2631 - acc: 0.8690\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2631 - acc: 0.8690\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2614 - acc: 0.8711\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2610 - acc: 0.8762\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2601 - acc: 0.8716\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2610 - acc: 0.8721\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2604 - acc: 0.8629\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2585 - acc: 0.8721\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2584 - acc: 0.8716\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2588 - acc: 0.8716\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2589 - acc: 0.8742\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2580 - acc: 0.8716\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2575 - acc: 0.8665\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2571 - acc: 0.8706\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2581 - acc: 0.8726\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2591 - acc: 0.8680\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2554 - acc: 0.8757\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2553 - acc: 0.8644\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2564 - acc: 0.8711\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2558 - acc: 0.8706\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2554 - acc: 0.8706\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2544 - acc: 0.8690\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2542 - acc: 0.8690\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2551 - acc: 0.8721\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2536 - acc: 0.8747\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2543 - acc: 0.8649\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2540 - acc: 0.8726\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2526 - acc: 0.8772\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6559 - acc: 0.7749\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.9770 - acc: 0.5668\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.7596 - acc: 0.6151\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.6441 - acc: 0.7035\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.5033 - acc: 0.7857\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4144 - acc: 0.8016\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3905 - acc: 0.8063\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3792 - acc: 0.8022\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3748 - acc: 0.8099\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3714 - acc: 0.8022\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3650 - acc: 0.8129\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3638 - acc: 0.8129\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3606 - acc: 0.8129\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3587 - acc: 0.8124\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3573 - acc: 0.8129\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3546 - acc: 0.8099\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3540 - acc: 0.8088\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3543 - acc: 0.8145\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3514 - acc: 0.8094\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3509 - acc: 0.8160\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3513 - acc: 0.8171\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3492 - acc: 0.8135\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3477 - acc: 0.8165\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3483 - acc: 0.8171\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3450 - acc: 0.8109\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3476 - acc: 0.8171\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3441 - acc: 0.8217\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3441 - acc: 0.8196\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3429 - acc: 0.8186\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3430 - acc: 0.8109\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3410 - acc: 0.8212\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3412 - acc: 0.8124\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3422 - acc: 0.8145\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3410 - acc: 0.8165\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3383 - acc: 0.8165\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3401 - acc: 0.8186\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3368 - acc: 0.8160\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3362 - acc: 0.8129\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3367 - acc: 0.8171\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3362 - acc: 0.8150\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3354 - acc: 0.8165\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3357 - acc: 0.8145\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3354 - acc: 0.8150\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3335 - acc: 0.8191\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3346 - acc: 0.8145\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3335 - acc: 0.8196\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3332 - acc: 0.8181\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3335 - acc: 0.8196\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3335 - acc: 0.8171\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3336 - acc: 0.8155\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3325 - acc: 0.8140\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5029 - acc: 0.8460\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.9791 - acc: 0.6497\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6730 - acc: 0.7345\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4908 - acc: 0.7961\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4286 - acc: 0.8130\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4111 - acc: 0.8084\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4040 - acc: 0.8166\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3987 - acc: 0.8079\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3946 - acc: 0.8130\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3932 - acc: 0.8089\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3893 - acc: 0.8207\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3890 - acc: 0.8228\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3863 - acc: 0.8187\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3837 - acc: 0.8177\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3833 - acc: 0.8213\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3803 - acc: 0.8177\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3780 - acc: 0.8161\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3770 - acc: 0.8156\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3760 - acc: 0.8161\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3754 - acc: 0.8213\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3730 - acc: 0.8218\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3740 - acc: 0.8172\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3729 - acc: 0.8141\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3688 - acc: 0.8223\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3680 - acc: 0.8187\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3672 - acc: 0.8264\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3666 - acc: 0.8279\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3662 - acc: 0.8207\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3656 - acc: 0.8259\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3638 - acc: 0.8228\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3632 - acc: 0.8249\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3633 - acc: 0.8249\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3635 - acc: 0.8254\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3598 - acc: 0.8228\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3603 - acc: 0.8207\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3596 - acc: 0.8279\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3572 - acc: 0.8228\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3588 - acc: 0.8300\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3585 - acc: 0.8161\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3557 - acc: 0.8274\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3563 - acc: 0.8290\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3559 - acc: 0.8254\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3561 - acc: 0.8310\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3547 - acc: 0.8223\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3542 - acc: 0.8269\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3537 - acc: 0.8300\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3514 - acc: 0.8320\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3510 - acc: 0.8269\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3529 - acc: 0.8295\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3515 - acc: 0.8238\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3506 - acc: 0.8315\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2895 - acc: 0.8489\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.9786 - acc: 0.6133\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6494 - acc: 0.7432\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4291 - acc: 0.8356\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3383 - acc: 0.8634\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3052 - acc: 0.8531\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2899 - acc: 0.8706\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2811 - acc: 0.8675\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2770 - acc: 0.8659\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2775 - acc: 0.8680\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2755 - acc: 0.8675\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2712 - acc: 0.8716\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2706 - acc: 0.8695\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2693 - acc: 0.8654\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2684 - acc: 0.8675\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2673 - acc: 0.8747\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2669 - acc: 0.8695\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2670 - acc: 0.8680\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2651 - acc: 0.8695\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2635 - acc: 0.8685\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2620 - acc: 0.8726\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2633 - acc: 0.8721\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2615 - acc: 0.8701\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2629 - acc: 0.8726\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2619 - acc: 0.8685\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2599 - acc: 0.8690\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2592 - acc: 0.8711\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2595 - acc: 0.8716\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2605 - acc: 0.8634\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2616 - acc: 0.8695\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2588 - acc: 0.8665\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2578 - acc: 0.8721\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2576 - acc: 0.8711\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2567 - acc: 0.8721\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2561 - acc: 0.8690\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2559 - acc: 0.8731\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2564 - acc: 0.8711\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2558 - acc: 0.8690\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2544 - acc: 0.8747\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2551 - acc: 0.8706\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2551 - acc: 0.8752\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2542 - acc: 0.8706\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2537 - acc: 0.8695\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2544 - acc: 0.8742\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2530 - acc: 0.8675\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2535 - acc: 0.8778\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2519 - acc: 0.8752\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2528 - acc: 0.8767\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2533 - acc: 0.8798\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2527 - acc: 0.8731\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2526 - acc: 0.8752\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6562 - acc: 0.7708\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.9165 - acc: 0.6285\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.5536 - acc: 0.7862\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.4224 - acc: 0.7929\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3956 - acc: 0.8001\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3819 - acc: 0.7980\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3775 - acc: 0.8037\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3718 - acc: 0.8088\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3675 - acc: 0.8068\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3634 - acc: 0.8140\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3611 - acc: 0.8109\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3624 - acc: 0.8171\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3580 - acc: 0.8124\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3587 - acc: 0.8109\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3579 - acc: 0.8104\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3554 - acc: 0.8119\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3543 - acc: 0.8135\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3514 - acc: 0.8114\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3501 - acc: 0.8109\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3512 - acc: 0.8145\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3527 - acc: 0.8140\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3502 - acc: 0.8140\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3479 - acc: 0.8068\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3477 - acc: 0.8078\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3482 - acc: 0.8155\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3449 - acc: 0.8129\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3450 - acc: 0.8129\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3447 - acc: 0.8099\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3444 - acc: 0.8094\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3433 - acc: 0.8114\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3429 - acc: 0.8088\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3414 - acc: 0.8176\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3417 - acc: 0.8073\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3405 - acc: 0.8114\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3399 - acc: 0.8140\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3406 - acc: 0.8083\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3391 - acc: 0.8160\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3373 - acc: 0.8176\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3380 - acc: 0.8135\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3402 - acc: 0.8150\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3372 - acc: 0.8212\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3372 - acc: 0.8150\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3379 - acc: 0.8135\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3371 - acc: 0.8155\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3358 - acc: 0.8140\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3368 - acc: 0.8145\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3377 - acc: 0.8253\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3345 - acc: 0.8160\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3370 - acc: 0.8078\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3345 - acc: 0.8129\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3347 - acc: 0.8135\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5825 - acc: 0.8532\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.9238 - acc: 0.5706\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.5896 - acc: 0.7530\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4480 - acc: 0.7925\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4232 - acc: 0.7940\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4148 - acc: 0.8028\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4127 - acc: 0.8023\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4090 - acc: 0.7971\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4064 - acc: 0.8028\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4013 - acc: 0.8048\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3993 - acc: 0.8028\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3987 - acc: 0.7935\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3969 - acc: 0.8053\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3929 - acc: 0.8048\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3945 - acc: 0.8028\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3907 - acc: 0.8038\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3891 - acc: 0.8053\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3872 - acc: 0.8115\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3872 - acc: 0.8048\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3854 - acc: 0.8202\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3842 - acc: 0.8156\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3845 - acc: 0.8202\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3816 - acc: 0.8259\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3805 - acc: 0.8228\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3781 - acc: 0.8207\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3798 - acc: 0.8269\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3772 - acc: 0.8207\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3777 - acc: 0.8259\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3764 - acc: 0.8243\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3744 - acc: 0.8269\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3727 - acc: 0.8197\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3735 - acc: 0.8223\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3720 - acc: 0.8274\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3729 - acc: 0.8269\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3715 - acc: 0.8264\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3723 - acc: 0.8238\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3698 - acc: 0.8269\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3707 - acc: 0.8223\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3678 - acc: 0.8254\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3679 - acc: 0.8274\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3683 - acc: 0.8223\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3667 - acc: 0.8320\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3666 - acc: 0.8285\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3652 - acc: 0.8290\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3640 - acc: 0.8295\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3653 - acc: 0.8351\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3647 - acc: 0.8300\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3626 - acc: 0.8243\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3637 - acc: 0.8254\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3625 - acc: 0.8310\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3623 - acc: 0.8310\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.3029 - acc: 0.8530\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.9730 - acc: 0.6436\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.6265 - acc: 0.7714\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3816 - acc: 0.8541\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3093 - acc: 0.8577\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2893 - acc: 0.8649\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2816 - acc: 0.8567\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2785 - acc: 0.8695\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2748 - acc: 0.8639\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2750 - acc: 0.8618\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2728 - acc: 0.8608\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2720 - acc: 0.8680\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2693 - acc: 0.8737\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2678 - acc: 0.8685\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2653 - acc: 0.8665\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2663 - acc: 0.8706\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2661 - acc: 0.8695\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2656 - acc: 0.8706\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2652 - acc: 0.8690\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2643 - acc: 0.8726\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2636 - acc: 0.8659\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2635 - acc: 0.8690\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2622 - acc: 0.8675\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2629 - acc: 0.8721\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2618 - acc: 0.8716\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2614 - acc: 0.8690\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2602 - acc: 0.8675\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2604 - acc: 0.8649\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2601 - acc: 0.8721\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2593 - acc: 0.8690\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2596 - acc: 0.8680\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2597 - acc: 0.8706\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2574 - acc: 0.8685\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2572 - acc: 0.8695\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2571 - acc: 0.8737\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2567 - acc: 0.8731\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2576 - acc: 0.8706\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2587 - acc: 0.8690\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2560 - acc: 0.8659\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2554 - acc: 0.8767\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2552 - acc: 0.8706\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2561 - acc: 0.8685\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2547 - acc: 0.8721\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2553 - acc: 0.8670\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2545 - acc: 0.8731\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2539 - acc: 0.8685\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2548 - acc: 0.8716\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2551 - acc: 0.8706\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2547 - acc: 0.8757\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2526 - acc: 0.8726\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2537 - acc: 0.8695\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6645 - acc: 0.7533\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 1.0195 - acc: 0.5005\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7984 - acc: 0.6300\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6397 - acc: 0.6578\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5598 - acc: 0.7379\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4809 - acc: 0.7760\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4231 - acc: 0.8001\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3965 - acc: 0.7991\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3824 - acc: 0.8068\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3753 - acc: 0.8114\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3697 - acc: 0.8109\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3666 - acc: 0.8052\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3653 - acc: 0.8129\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3619 - acc: 0.8114\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3591 - acc: 0.8135\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3574 - acc: 0.8176\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3562 - acc: 0.8124\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3547 - acc: 0.8165\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3535 - acc: 0.8186\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3521 - acc: 0.8176\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3517 - acc: 0.8124\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3505 - acc: 0.8186\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3499 - acc: 0.8150\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3485 - acc: 0.8176\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3488 - acc: 0.8160\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3483 - acc: 0.8114\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3477 - acc: 0.8083\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3459 - acc: 0.8160\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3460 - acc: 0.8135\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3458 - acc: 0.8207\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3441 - acc: 0.8104\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3444 - acc: 0.8165\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3440 - acc: 0.8047\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3435 - acc: 0.8150\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3421 - acc: 0.8207\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3448 - acc: 0.8109\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3419 - acc: 0.8181\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3407 - acc: 0.8186\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3409 - acc: 0.8140\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3399 - acc: 0.8207\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3402 - acc: 0.8171\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3409 - acc: 0.8140\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3399 - acc: 0.8171\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3383 - acc: 0.8140\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3384 - acc: 0.8207\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3387 - acc: 0.8150\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3377 - acc: 0.8109\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3368 - acc: 0.8201\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3370 - acc: 0.8201\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3380 - acc: 0.8155\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3366 - acc: 0.8181\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5144 - acc: 0.8542\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 1.0287 - acc: 0.5763\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8435 - acc: 0.6703\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6450 - acc: 0.7304\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5074 - acc: 0.7920\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4393 - acc: 0.8074\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4150 - acc: 0.8115\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4018 - acc: 0.8161\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3947 - acc: 0.8125\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3919 - acc: 0.8151\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3888 - acc: 0.8202\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3862 - acc: 0.8207\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3829 - acc: 0.8156\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3821 - acc: 0.8161\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3815 - acc: 0.8238\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3790 - acc: 0.8254\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3770 - acc: 0.8228\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3758 - acc: 0.8233\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3746 - acc: 0.8110\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3750 - acc: 0.8161\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3735 - acc: 0.8238\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3718 - acc: 0.8228\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3717 - acc: 0.8218\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3700 - acc: 0.8254\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3691 - acc: 0.8259\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3704 - acc: 0.8172\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3680 - acc: 0.8259\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3669 - acc: 0.8238\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3665 - acc: 0.8254\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3681 - acc: 0.8207\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3656 - acc: 0.8228\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3651 - acc: 0.8223\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3638 - acc: 0.8285\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3631 - acc: 0.8274\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3644 - acc: 0.8254\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3614 - acc: 0.8264\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3619 - acc: 0.8310\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3613 - acc: 0.8238\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3614 - acc: 0.8238\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3598 - acc: 0.8290\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3599 - acc: 0.8274\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3589 - acc: 0.8279\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3585 - acc: 0.8238\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3597 - acc: 0.8249\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3581 - acc: 0.8320\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3582 - acc: 0.8264\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3564 - acc: 0.8305\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3571 - acc: 0.8320\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3566 - acc: 0.8249\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3549 - acc: 0.8351\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3560 - acc: 0.8285\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2879 - acc: 0.8561\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 1.0300 - acc: 0.5306\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.8021 - acc: 0.7011\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5738 - acc: 0.7709\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4424 - acc: 0.8290\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3663 - acc: 0.8454\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3278 - acc: 0.8557\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3058 - acc: 0.8634\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2955 - acc: 0.8593\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2873 - acc: 0.8618\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2841 - acc: 0.8567\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2818 - acc: 0.8608\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2779 - acc: 0.8654\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2748 - acc: 0.8711\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2720 - acc: 0.8618\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2715 - acc: 0.8716\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2701 - acc: 0.8680\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2696 - acc: 0.8711\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2694 - acc: 0.8670\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2690 - acc: 0.8690\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2670 - acc: 0.8670\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2660 - acc: 0.8701\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2656 - acc: 0.8701\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2653 - acc: 0.8685\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2662 - acc: 0.8726\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2645 - acc: 0.8695\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2653 - acc: 0.8695\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2623 - acc: 0.8762\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2626 - acc: 0.8711\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2625 - acc: 0.8690\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2628 - acc: 0.8716\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2625 - acc: 0.8670\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2616 - acc: 0.8757\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2619 - acc: 0.8706\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2599 - acc: 0.8721\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2609 - acc: 0.8721\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2587 - acc: 0.8747\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2592 - acc: 0.8690\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2593 - acc: 0.8772\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2590 - acc: 0.8747\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2585 - acc: 0.8767\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2575 - acc: 0.8737\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2581 - acc: 0.8711\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2570 - acc: 0.8757\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2559 - acc: 0.8690\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2556 - acc: 0.8767\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2564 - acc: 0.8752\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2559 - acc: 0.8665\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2558 - acc: 0.8731\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2546 - acc: 0.8767\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2569 - acc: 0.8757\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6270 - acc: 0.7533\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.9350 - acc: 0.6721\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5542 - acc: 0.7749\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4160 - acc: 0.7960\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3872 - acc: 0.8001\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3792 - acc: 0.8088\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3696 - acc: 0.8129\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3655 - acc: 0.8140\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3652 - acc: 0.7996\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3598 - acc: 0.8094\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3572 - acc: 0.8176\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3557 - acc: 0.8104\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3556 - acc: 0.8078\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3525 - acc: 0.8145\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3523 - acc: 0.8135\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3514 - acc: 0.8109\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3495 - acc: 0.8176\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3469 - acc: 0.8129\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3456 - acc: 0.8119\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3458 - acc: 0.8129\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3443 - acc: 0.8124\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3436 - acc: 0.8109\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3418 - acc: 0.8160\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3418 - acc: 0.8181\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3416 - acc: 0.8083\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3437 - acc: 0.8145\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3398 - acc: 0.8145\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3392 - acc: 0.8165\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3378 - acc: 0.8217\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3394 - acc: 0.8165\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3365 - acc: 0.8145\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3346 - acc: 0.8237\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3372 - acc: 0.8150\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3372 - acc: 0.8145\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3356 - acc: 0.8094\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3353 - acc: 0.8129\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3327 - acc: 0.8171\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3342 - acc: 0.8155\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3339 - acc: 0.8186\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3326 - acc: 0.8191\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3344 - acc: 0.8171\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3334 - acc: 0.8227\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3310 - acc: 0.8222\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3331 - acc: 0.8135\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3309 - acc: 0.8099\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3346 - acc: 0.8160\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3313 - acc: 0.8088\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3290 - acc: 0.8155\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3297 - acc: 0.8099\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3293 - acc: 0.8212\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3299 - acc: 0.8191\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5453 - acc: 0.8480\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.9088 - acc: 0.6841\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5415 - acc: 0.7822\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4275 - acc: 0.8059\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4086 - acc: 0.8074\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4009 - acc: 0.8161\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3968 - acc: 0.8166\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3908 - acc: 0.8218\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3913 - acc: 0.8074\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3880 - acc: 0.8136\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3857 - acc: 0.8197\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3843 - acc: 0.8207\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3810 - acc: 0.8197\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3779 - acc: 0.8223\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3773 - acc: 0.8202\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3750 - acc: 0.8305\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3731 - acc: 0.8187\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3719 - acc: 0.8238\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3700 - acc: 0.8295\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3737 - acc: 0.8213\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3703 - acc: 0.8223\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3661 - acc: 0.8259\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3653 - acc: 0.8249\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3636 - acc: 0.8254\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3629 - acc: 0.8259\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3650 - acc: 0.8187\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3620 - acc: 0.8290\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3610 - acc: 0.8207\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3591 - acc: 0.8259\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3581 - acc: 0.8264\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3584 - acc: 0.8269\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3605 - acc: 0.8259\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3563 - acc: 0.8305\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3569 - acc: 0.8285\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3560 - acc: 0.8279\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3561 - acc: 0.8290\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3558 - acc: 0.8259\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3541 - acc: 0.8310\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3550 - acc: 0.8213\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3538 - acc: 0.8305\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3528 - acc: 0.8269\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3538 - acc: 0.8192\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3526 - acc: 0.8300\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3518 - acc: 0.8285\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3509 - acc: 0.8259\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3505 - acc: 0.8346\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3503 - acc: 0.8279\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3502 - acc: 0.8295\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3509 - acc: 0.8351\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3493 - acc: 0.8300\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3500 - acc: 0.8228\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2909 - acc: 0.8510\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.9081 - acc: 0.7021\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4814 - acc: 0.8392\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3259 - acc: 0.8624\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2963 - acc: 0.8577\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2845 - acc: 0.8618\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2792 - acc: 0.8690\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2750 - acc: 0.8695\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2762 - acc: 0.8613\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2722 - acc: 0.8665\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2714 - acc: 0.8659\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2692 - acc: 0.8670\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2689 - acc: 0.8701\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2663 - acc: 0.8685\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2686 - acc: 0.8665\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2656 - acc: 0.8670\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2646 - acc: 0.8695\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2641 - acc: 0.8726\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2616 - acc: 0.8726\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2643 - acc: 0.8670\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2632 - acc: 0.8634\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2612 - acc: 0.8659\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2616 - acc: 0.8726\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2588 - acc: 0.8680\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2612 - acc: 0.8726\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2615 - acc: 0.8603\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2573 - acc: 0.8711\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2588 - acc: 0.8762\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2577 - acc: 0.8737\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2594 - acc: 0.8670\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2580 - acc: 0.8706\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2562 - acc: 0.8747\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2560 - acc: 0.8701\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2556 - acc: 0.8675\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2562 - acc: 0.8731\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2550 - acc: 0.8731\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2551 - acc: 0.8711\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2543 - acc: 0.8742\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2572 - acc: 0.8685\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2539 - acc: 0.8711\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2547 - acc: 0.8701\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2553 - acc: 0.8716\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2526 - acc: 0.8721\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2531 - acc: 0.8757\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2522 - acc: 0.8701\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2523 - acc: 0.8737\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2523 - acc: 0.8737\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2514 - acc: 0.8814\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2555 - acc: 0.8659\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2516 - acc: 0.8721\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2518 - acc: 0.8695\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6634 - acc: 0.7708\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.8454 - acc: 0.6896\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4830 - acc: 0.7831\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3983 - acc: 0.8006\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3794 - acc: 0.8129\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3741 - acc: 0.8094\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3731 - acc: 0.8042\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3672 - acc: 0.8094\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3633 - acc: 0.8119\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3608 - acc: 0.8181\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3571 - acc: 0.8171\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3567 - acc: 0.8186\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3549 - acc: 0.8073\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3536 - acc: 0.8104\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3529 - acc: 0.8047\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3507 - acc: 0.8140\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3502 - acc: 0.8052\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3490 - acc: 0.8088\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3473 - acc: 0.8150\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3484 - acc: 0.8171\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3466 - acc: 0.8176\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3469 - acc: 0.8104\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3432 - acc: 0.8196\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3483 - acc: 0.8099\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3434 - acc: 0.8078\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3405 - acc: 0.8119\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3419 - acc: 0.8201\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3414 - acc: 0.8109\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3413 - acc: 0.8114\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3383 - acc: 0.8104\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3409 - acc: 0.8135\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3377 - acc: 0.8207\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3369 - acc: 0.8119\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3368 - acc: 0.8124\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3358 - acc: 0.8171\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3360 - acc: 0.8094\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3368 - acc: 0.8119\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3342 - acc: 0.8155\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3357 - acc: 0.8155\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3335 - acc: 0.8212\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3328 - acc: 0.8191\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3322 - acc: 0.8176\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3317 - acc: 0.8186\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3326 - acc: 0.8114\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3305 - acc: 0.8165\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3305 - acc: 0.8186\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3315 - acc: 0.8058\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3317 - acc: 0.8094\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3325 - acc: 0.8140\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3313 - acc: 0.8160\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3295 - acc: 0.8253\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6031 - acc: 0.8491\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.8717 - acc: 0.7165\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4787 - acc: 0.7915\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4150 - acc: 0.8110\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4025 - acc: 0.8141\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3985 - acc: 0.8172\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3926 - acc: 0.8146\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3909 - acc: 0.8130\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3880 - acc: 0.8136\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3838 - acc: 0.8130\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3839 - acc: 0.8223\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3794 - acc: 0.8207\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3782 - acc: 0.8192\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3779 - acc: 0.8202\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3782 - acc: 0.8130\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3771 - acc: 0.8213\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3721 - acc: 0.8295\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3717 - acc: 0.8243\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3709 - acc: 0.8218\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3687 - acc: 0.8243\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3677 - acc: 0.8233\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3681 - acc: 0.8192\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3669 - acc: 0.8274\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3644 - acc: 0.8207\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3641 - acc: 0.8233\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3637 - acc: 0.8259\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3624 - acc: 0.8274\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3628 - acc: 0.8213\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3601 - acc: 0.8238\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3599 - acc: 0.8300\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3585 - acc: 0.8274\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3568 - acc: 0.8249\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3575 - acc: 0.8254\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3578 - acc: 0.8269\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3556 - acc: 0.8300\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3554 - acc: 0.8218\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3557 - acc: 0.8320\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3567 - acc: 0.8166\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3541 - acc: 0.8238\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3537 - acc: 0.8300\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3544 - acc: 0.8300\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3521 - acc: 0.8249\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3553 - acc: 0.8249\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3518 - acc: 0.8264\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3524 - acc: 0.8305\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3518 - acc: 0.8274\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3514 - acc: 0.8269\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3481 - acc: 0.8331\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3492 - acc: 0.8351\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3489 - acc: 0.8218\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3496 - acc: 0.8274\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2924 - acc: 0.8530\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.7930 - acc: 0.7750\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3770 - acc: 0.8464\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3039 - acc: 0.8629\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2874 - acc: 0.8649\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2812 - acc: 0.8649\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2758 - acc: 0.8654\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2738 - acc: 0.8665\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2738 - acc: 0.8680\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2731 - acc: 0.8659\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2683 - acc: 0.8639\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2696 - acc: 0.8613\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2697 - acc: 0.8649\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2666 - acc: 0.8680\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2680 - acc: 0.8665\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2642 - acc: 0.8629\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2668 - acc: 0.8726\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2658 - acc: 0.8608\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2630 - acc: 0.8695\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2623 - acc: 0.8649\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2602 - acc: 0.8706\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2597 - acc: 0.8701\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2596 - acc: 0.8680\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2568 - acc: 0.8772\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2578 - acc: 0.8670\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2571 - acc: 0.8711\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2581 - acc: 0.8726\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2567 - acc: 0.8685\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2559 - acc: 0.8680\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2560 - acc: 0.8731\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2553 - acc: 0.8654\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2535 - acc: 0.8757\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2571 - acc: 0.8737\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2558 - acc: 0.8695\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2538 - acc: 0.8726\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2548 - acc: 0.8721\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2574 - acc: 0.8695\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2530 - acc: 0.8721\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2537 - acc: 0.8783\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2550 - acc: 0.8675\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2567 - acc: 0.8644\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2523 - acc: 0.8757\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2524 - acc: 0.8752\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2503 - acc: 0.8706\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2540 - acc: 0.8737\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2489 - acc: 0.8819\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2521 - acc: 0.8721\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2510 - acc: 0.8680\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2484 - acc: 0.8798\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2501 - acc: 0.8731\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2510 - acc: 0.8772\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6606 - acc: 0.7739\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7589 - acc: 0.7261\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4178 - acc: 0.7955\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3840 - acc: 0.8052\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3807 - acc: 0.7950\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3719 - acc: 0.8063\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3693 - acc: 0.8119\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3662 - acc: 0.8063\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3616 - acc: 0.8119\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3623 - acc: 0.8094\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3622 - acc: 0.8119\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3565 - acc: 0.8135\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3549 - acc: 0.8088\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3576 - acc: 0.8094\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3530 - acc: 0.8119\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3510 - acc: 0.8135\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3481 - acc: 0.8119\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3527 - acc: 0.8109\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3481 - acc: 0.8073\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3475 - acc: 0.8073\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3462 - acc: 0.8176\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3461 - acc: 0.8135\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3464 - acc: 0.8145\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3448 - acc: 0.8119\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3419 - acc: 0.8104\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3421 - acc: 0.8124\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3399 - acc: 0.8165\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3491 - acc: 0.8104\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3391 - acc: 0.8124\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3442 - acc: 0.8073\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3409 - acc: 0.8124\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3416 - acc: 0.8078\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3385 - acc: 0.8145\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3349 - acc: 0.8135\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3374 - acc: 0.8058\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3379 - acc: 0.8099\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3377 - acc: 0.8124\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3336 - acc: 0.8176\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3357 - acc: 0.8124\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3333 - acc: 0.8186\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3319 - acc: 0.8150\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3370 - acc: 0.8155\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3350 - acc: 0.8083\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3302 - acc: 0.8232\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3367 - acc: 0.8165\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3310 - acc: 0.8212\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3323 - acc: 0.8232\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3324 - acc: 0.8160\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3301 - acc: 0.8135\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3316 - acc: 0.8165\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3289 - acc: 0.8222\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5985 - acc: 0.8501\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7570 - acc: 0.7386\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4381 - acc: 0.7987\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4098 - acc: 0.8115\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4002 - acc: 0.8177\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3941 - acc: 0.8136\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3956 - acc: 0.8115\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3910 - acc: 0.8146\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3850 - acc: 0.8218\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3826 - acc: 0.8172\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3784 - acc: 0.8249\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3786 - acc: 0.8223\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3786 - acc: 0.8187\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3739 - acc: 0.8238\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3740 - acc: 0.8269\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3750 - acc: 0.8192\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3706 - acc: 0.8136\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3733 - acc: 0.8156\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3717 - acc: 0.8218\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3718 - acc: 0.8187\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3680 - acc: 0.8207\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3651 - acc: 0.8243\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3676 - acc: 0.8223\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3657 - acc: 0.8187\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3632 - acc: 0.8197\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3610 - acc: 0.8233\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3616 - acc: 0.8285\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3642 - acc: 0.8218\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3626 - acc: 0.8243\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3570 - acc: 0.8279\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3592 - acc: 0.8192\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3602 - acc: 0.8166\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3598 - acc: 0.8300\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3549 - acc: 0.8285\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3547 - acc: 0.8305\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3558 - acc: 0.8305\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3536 - acc: 0.8259\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3553 - acc: 0.8233\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3543 - acc: 0.8290\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3515 - acc: 0.8192\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3531 - acc: 0.8295\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3502 - acc: 0.8305\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3508 - acc: 0.8300\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3542 - acc: 0.8223\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3493 - acc: 0.8300\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3498 - acc: 0.8300\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3483 - acc: 0.8300\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3494 - acc: 0.8243\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3480 - acc: 0.8326\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3497 - acc: 0.8331\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3461 - acc: 0.8310\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2867 - acc: 0.8530\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7336 - acc: 0.7869\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3348 - acc: 0.8552\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2953 - acc: 0.8572\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2839 - acc: 0.8629\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2813 - acc: 0.8685\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2758 - acc: 0.8690\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2729 - acc: 0.8716\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2754 - acc: 0.8582\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2703 - acc: 0.8665\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2708 - acc: 0.8680\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2686 - acc: 0.8737\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2688 - acc: 0.8685\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2679 - acc: 0.8618\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2629 - acc: 0.8742\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2631 - acc: 0.8690\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2637 - acc: 0.8726\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2610 - acc: 0.8670\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2643 - acc: 0.8654\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2622 - acc: 0.8731\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2611 - acc: 0.8639\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2619 - acc: 0.8706\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2602 - acc: 0.8665\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2591 - acc: 0.8726\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2576 - acc: 0.8731\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2578 - acc: 0.8721\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2599 - acc: 0.8634\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2564 - acc: 0.8665\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2563 - acc: 0.8654\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2564 - acc: 0.8675\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2570 - acc: 0.8629\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2568 - acc: 0.8665\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2565 - acc: 0.8695\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2559 - acc: 0.8767\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2570 - acc: 0.8685\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2564 - acc: 0.8731\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2549 - acc: 0.8711\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2540 - acc: 0.8731\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2529 - acc: 0.8711\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2540 - acc: 0.8737\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2530 - acc: 0.8659\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2530 - acc: 0.8762\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2550 - acc: 0.8670\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2510 - acc: 0.8737\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2514 - acc: 0.8767\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2536 - acc: 0.8690\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2526 - acc: 0.8788\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2520 - acc: 0.8695\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2517 - acc: 0.8731\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2523 - acc: 0.8767\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2505 - acc: 0.8731\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6988 - acc: 0.7544\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.9806 - acc: 0.6701\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6953 - acc: 0.7503\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5227 - acc: 0.7816\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4389 - acc: 0.7955\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4005 - acc: 0.8063\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3854 - acc: 0.8063\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3772 - acc: 0.8104\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3724 - acc: 0.8129\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3700 - acc: 0.8042\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3666 - acc: 0.8124\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3645 - acc: 0.8124\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3633 - acc: 0.8140\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3617 - acc: 0.8114\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3607 - acc: 0.8124\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3598 - acc: 0.8124\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3594 - acc: 0.8160\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3574 - acc: 0.8114\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3559 - acc: 0.8135\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3548 - acc: 0.8171\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3544 - acc: 0.8181\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3540 - acc: 0.8150\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3533 - acc: 0.8104\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3520 - acc: 0.8119\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3523 - acc: 0.8145\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3511 - acc: 0.8181\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3498 - acc: 0.8140\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3501 - acc: 0.8119\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3501 - acc: 0.8099\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3485 - acc: 0.8181\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3484 - acc: 0.8114\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3481 - acc: 0.8140\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3465 - acc: 0.8212\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3464 - acc: 0.8155\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3461 - acc: 0.8160\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3475 - acc: 0.8217\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3460 - acc: 0.8114\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3447 - acc: 0.8160\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3451 - acc: 0.8160\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3431 - acc: 0.8160\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3443 - acc: 0.8212\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3442 - acc: 0.8135\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3436 - acc: 0.8119\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3425 - acc: 0.8191\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3430 - acc: 0.8176\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3423 - acc: 0.8099\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3423 - acc: 0.8124\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3405 - acc: 0.8201\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3407 - acc: 0.8078\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3411 - acc: 0.8186\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3403 - acc: 0.8171\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4842 - acc: 0.8522\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.9958 - acc: 0.5532\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.7420 - acc: 0.6574\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5560 - acc: 0.7499\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4565 - acc: 0.8089\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4191 - acc: 0.8028\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4053 - acc: 0.8125\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3998 - acc: 0.8125\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3960 - acc: 0.8151\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3927 - acc: 0.8218\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3913 - acc: 0.8110\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3878 - acc: 0.8218\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3863 - acc: 0.8182\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3847 - acc: 0.8161\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3832 - acc: 0.8141\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3817 - acc: 0.8172\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3789 - acc: 0.8233\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3785 - acc: 0.8249\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3784 - acc: 0.8187\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3768 - acc: 0.8172\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3746 - acc: 0.8207\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3751 - acc: 0.8218\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3741 - acc: 0.8192\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3722 - acc: 0.8279\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3718 - acc: 0.8197\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3706 - acc: 0.8166\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3690 - acc: 0.8213\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3686 - acc: 0.8305\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3683 - acc: 0.8223\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3683 - acc: 0.8202\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3665 - acc: 0.8228\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3671 - acc: 0.8254\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3654 - acc: 0.8202\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3638 - acc: 0.8259\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3663 - acc: 0.8202\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3641 - acc: 0.8213\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3632 - acc: 0.8233\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3633 - acc: 0.8228\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3630 - acc: 0.8290\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3628 - acc: 0.8274\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3632 - acc: 0.8223\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3612 - acc: 0.8233\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3601 - acc: 0.8264\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3582 - acc: 0.8269\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3612 - acc: 0.8151\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3600 - acc: 0.8315\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3590 - acc: 0.8295\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3571 - acc: 0.8274\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3572 - acc: 0.8285\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3585 - acc: 0.8300\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3584 - acc: 0.8177\n",
      "31/31 [==============================] - 0s 970us/step - loss: 0.2946 - acc: 0.8448\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.9781 - acc: 0.5840\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6850 - acc: 0.7442\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4498 - acc: 0.8310\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3534 - acc: 0.8449\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3174 - acc: 0.8572\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3021 - acc: 0.8572\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2941 - acc: 0.8603\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2885 - acc: 0.8639\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2838 - acc: 0.8624\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2814 - acc: 0.8665\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2783 - acc: 0.8701\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2759 - acc: 0.8675\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2749 - acc: 0.8675\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2741 - acc: 0.8659\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2723 - acc: 0.8690\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2713 - acc: 0.8711\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2697 - acc: 0.8659\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2694 - acc: 0.8742\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2680 - acc: 0.8752\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2689 - acc: 0.8690\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2677 - acc: 0.8690\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2662 - acc: 0.8706\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2649 - acc: 0.8711\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2656 - acc: 0.8747\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2655 - acc: 0.8731\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2641 - acc: 0.8716\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2630 - acc: 0.8665\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2652 - acc: 0.8659\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2630 - acc: 0.8695\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2626 - acc: 0.8716\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2622 - acc: 0.8706\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2619 - acc: 0.8665\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2616 - acc: 0.8711\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2623 - acc: 0.8695\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2607 - acc: 0.8747\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2603 - acc: 0.8711\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2593 - acc: 0.8762\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2595 - acc: 0.8685\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2577 - acc: 0.8767\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2579 - acc: 0.8690\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2579 - acc: 0.8747\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2583 - acc: 0.8731\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2588 - acc: 0.8644\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2562 - acc: 0.8752\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2591 - acc: 0.8731\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2570 - acc: 0.8757\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2562 - acc: 0.8685\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2555 - acc: 0.8716\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2554 - acc: 0.8747\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2550 - acc: 0.8767\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6269 - acc: 0.7533\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.8664 - acc: 0.6608\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4773 - acc: 0.7878\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3959 - acc: 0.7914\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3789 - acc: 0.8022\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3720 - acc: 0.8088\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3702 - acc: 0.7991\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3680 - acc: 0.8104\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3589 - acc: 0.8145\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3588 - acc: 0.8140\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3585 - acc: 0.8119\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3546 - acc: 0.8078\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3541 - acc: 0.8104\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3518 - acc: 0.8196\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3502 - acc: 0.8207\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3482 - acc: 0.8094\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3466 - acc: 0.8212\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3467 - acc: 0.8083\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3457 - acc: 0.8124\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3446 - acc: 0.8032\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3433 - acc: 0.8160\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3438 - acc: 0.8222\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3429 - acc: 0.8099\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3413 - acc: 0.8094\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3424 - acc: 0.8109\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3400 - acc: 0.8145\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3376 - acc: 0.8181\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3381 - acc: 0.8155\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3377 - acc: 0.8155\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3347 - acc: 0.8150\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3376 - acc: 0.8135\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3343 - acc: 0.8207\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3356 - acc: 0.8201\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3366 - acc: 0.8150\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3335 - acc: 0.8181\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3358 - acc: 0.8119\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3344 - acc: 0.8263\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3333 - acc: 0.8171\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3345 - acc: 0.8181\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3325 - acc: 0.8155\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3323 - acc: 0.8227\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3344 - acc: 0.8135\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3300 - acc: 0.8181\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3317 - acc: 0.8181\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3309 - acc: 0.8135\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3327 - acc: 0.8037\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3292 - acc: 0.8140\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3286 - acc: 0.8124\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3285 - acc: 0.8227\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3283 - acc: 0.8171\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3279 - acc: 0.8165\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.5860 - acc: 0.8511\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.8426 - acc: 0.7093\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4685 - acc: 0.7956\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4150 - acc: 0.8105\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4033 - acc: 0.8043\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3962 - acc: 0.8197\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3973 - acc: 0.8089\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3890 - acc: 0.8136\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3847 - acc: 0.8228\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3843 - acc: 0.8100\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3813 - acc: 0.8141\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3793 - acc: 0.8136\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3752 - acc: 0.8238\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3746 - acc: 0.8166\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3724 - acc: 0.8218\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3698 - acc: 0.8156\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3697 - acc: 0.8274\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3696 - acc: 0.8243\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3658 - acc: 0.8233\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3671 - acc: 0.8213\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3649 - acc: 0.8141\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3660 - acc: 0.8207\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3645 - acc: 0.8269\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3640 - acc: 0.8238\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3621 - acc: 0.8274\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3617 - acc: 0.8218\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3632 - acc: 0.8197\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3573 - acc: 0.8259\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3580 - acc: 0.8279\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3577 - acc: 0.8259\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3569 - acc: 0.8264\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3548 - acc: 0.8326\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3539 - acc: 0.8305\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3537 - acc: 0.8310\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3542 - acc: 0.8305\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3560 - acc: 0.8238\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3530 - acc: 0.8197\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3538 - acc: 0.8295\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3522 - acc: 0.8300\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3521 - acc: 0.8305\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3506 - acc: 0.8341\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3500 - acc: 0.8305\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3507 - acc: 0.8315\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3485 - acc: 0.8326\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3503 - acc: 0.8305\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3495 - acc: 0.8218\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3492 - acc: 0.8331\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3488 - acc: 0.8300\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3474 - acc: 0.8285\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3487 - acc: 0.8320\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3498 - acc: 0.8259\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2933 - acc: 0.8417\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.8290 - acc: 0.7576\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3901 - acc: 0.8480\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3040 - acc: 0.8613\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2883 - acc: 0.8552\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2829 - acc: 0.8634\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2804 - acc: 0.8613\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2749 - acc: 0.8659\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2712 - acc: 0.8701\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2712 - acc: 0.8654\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2699 - acc: 0.8721\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2703 - acc: 0.8608\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2686 - acc: 0.8644\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2672 - acc: 0.8690\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2677 - acc: 0.8665\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2681 - acc: 0.8624\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2624 - acc: 0.8737\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2648 - acc: 0.8726\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2640 - acc: 0.8721\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2632 - acc: 0.8685\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2609 - acc: 0.8624\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2611 - acc: 0.8737\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2607 - acc: 0.8711\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2602 - acc: 0.8742\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2599 - acc: 0.8695\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2599 - acc: 0.8772\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2585 - acc: 0.8721\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2558 - acc: 0.8721\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2603 - acc: 0.8670\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2572 - acc: 0.8706\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2566 - acc: 0.8685\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2595 - acc: 0.8639\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2551 - acc: 0.8737\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2552 - acc: 0.8757\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2544 - acc: 0.8752\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2555 - acc: 0.8726\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2553 - acc: 0.8757\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2548 - acc: 0.8695\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2550 - acc: 0.8721\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2523 - acc: 0.8731\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2530 - acc: 0.8778\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2507 - acc: 0.8788\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2548 - acc: 0.8680\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2530 - acc: 0.8731\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2528 - acc: 0.8721\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2505 - acc: 0.8690\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2504 - acc: 0.8803\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2519 - acc: 0.8747\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2486 - acc: 0.8747\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2491 - acc: 0.8778\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2483 - acc: 0.8803\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6655 - acc: 0.7533\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7691 - acc: 0.7133\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4242 - acc: 0.7965\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3850 - acc: 0.8165\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3785 - acc: 0.8078\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3714 - acc: 0.8099\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3690 - acc: 0.8145\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3665 - acc: 0.8114\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3657 - acc: 0.8047\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3618 - acc: 0.8114\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3589 - acc: 0.8094\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3566 - acc: 0.8083\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3581 - acc: 0.8104\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3550 - acc: 0.8186\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3549 - acc: 0.8058\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3532 - acc: 0.8088\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3517 - acc: 0.8129\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3507 - acc: 0.8099\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3507 - acc: 0.8073\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3444 - acc: 0.8165\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3461 - acc: 0.8094\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3440 - acc: 0.8129\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3441 - acc: 0.8181\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3427 - acc: 0.8135\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3432 - acc: 0.8124\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3421 - acc: 0.8094\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3417 - acc: 0.8068\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3428 - acc: 0.8145\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3425 - acc: 0.8109\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3398 - acc: 0.8094\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3374 - acc: 0.8155\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3376 - acc: 0.8140\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3397 - acc: 0.8135\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3361 - acc: 0.8135\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3362 - acc: 0.8114\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3350 - acc: 0.8083\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3355 - acc: 0.8124\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3324 - acc: 0.8099\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3327 - acc: 0.8124\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3339 - acc: 0.8212\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3336 - acc: 0.8160\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3313 - acc: 0.8181\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3312 - acc: 0.8083\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3326 - acc: 0.8114\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3321 - acc: 0.8129\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3295 - acc: 0.8191\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3314 - acc: 0.8165\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3308 - acc: 0.8160\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3288 - acc: 0.8129\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3283 - acc: 0.8165\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3296 - acc: 0.8176\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6147 - acc: 0.8439\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7821 - acc: 0.7304\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4386 - acc: 0.7987\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4048 - acc: 0.8166\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4002 - acc: 0.8105\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3956 - acc: 0.8125\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3897 - acc: 0.8166\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3875 - acc: 0.8105\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3841 - acc: 0.8151\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3824 - acc: 0.8166\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3791 - acc: 0.8192\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3776 - acc: 0.8269\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3770 - acc: 0.8151\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3756 - acc: 0.8166\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3715 - acc: 0.8207\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3736 - acc: 0.8166\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3695 - acc: 0.8213\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3702 - acc: 0.8218\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3707 - acc: 0.8223\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3656 - acc: 0.8249\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3666 - acc: 0.8264\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3632 - acc: 0.8161\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3645 - acc: 0.8192\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3647 - acc: 0.8223\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3603 - acc: 0.8279\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3591 - acc: 0.8269\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3606 - acc: 0.8285\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3600 - acc: 0.8228\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3585 - acc: 0.8243\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3568 - acc: 0.8254\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3584 - acc: 0.8300\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3565 - acc: 0.8290\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3567 - acc: 0.8326\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3583 - acc: 0.8249\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3556 - acc: 0.8290\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3545 - acc: 0.8351\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3561 - acc: 0.8279\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3534 - acc: 0.8264\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3545 - acc: 0.8285\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3515 - acc: 0.8269\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3527 - acc: 0.8305\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3522 - acc: 0.8269\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3495 - acc: 0.8346\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3500 - acc: 0.8300\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3504 - acc: 0.8238\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3486 - acc: 0.8300\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3503 - acc: 0.8259\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3476 - acc: 0.8320\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3483 - acc: 0.8310\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3471 - acc: 0.8305\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3474 - acc: 0.8254\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2916 - acc: 0.8489\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7776 - acc: 0.7750\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3561 - acc: 0.8521\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2958 - acc: 0.8562\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2814 - acc: 0.8618\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2803 - acc: 0.8624\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2764 - acc: 0.8670\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2747 - acc: 0.8613\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2703 - acc: 0.8659\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2729 - acc: 0.8670\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2709 - acc: 0.8634\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2666 - acc: 0.8721\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2681 - acc: 0.8593\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2639 - acc: 0.8701\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2653 - acc: 0.8788\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2672 - acc: 0.8613\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2650 - acc: 0.8685\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2619 - acc: 0.8634\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2638 - acc: 0.8690\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2613 - acc: 0.8726\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2591 - acc: 0.8716\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2583 - acc: 0.8757\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2595 - acc: 0.8701\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2573 - acc: 0.8675\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2592 - acc: 0.8639\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2566 - acc: 0.8747\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2573 - acc: 0.8675\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2570 - acc: 0.8690\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2585 - acc: 0.8670\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2550 - acc: 0.8654\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2567 - acc: 0.8747\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2558 - acc: 0.8690\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2539 - acc: 0.8737\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2539 - acc: 0.8778\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2552 - acc: 0.8711\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2538 - acc: 0.8716\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2568 - acc: 0.8701\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2506 - acc: 0.8716\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2528 - acc: 0.8737\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2518 - acc: 0.8695\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2525 - acc: 0.8772\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2533 - acc: 0.8757\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2508 - acc: 0.8762\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2509 - acc: 0.8737\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2500 - acc: 0.8778\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2529 - acc: 0.8737\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2534 - acc: 0.8685\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2500 - acc: 0.8680\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2494 - acc: 0.8716\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2480 - acc: 0.8757\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2484 - acc: 0.8695\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6959 - acc: 0.7575\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.7075 - acc: 0.7220\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4033 - acc: 0.8099\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3866 - acc: 0.7975\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3799 - acc: 0.8052\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3773 - acc: 0.7991\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3688 - acc: 0.8006\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3645 - acc: 0.8006\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3638 - acc: 0.8068\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3602 - acc: 0.8099\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3557 - acc: 0.8083\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3539 - acc: 0.8099\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3560 - acc: 0.8119\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3530 - acc: 0.8027\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3535 - acc: 0.8145\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3481 - acc: 0.8083\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3499 - acc: 0.8073\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3477 - acc: 0.8124\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3472 - acc: 0.8129\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3460 - acc: 0.8145\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3455 - acc: 0.8027\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3453 - acc: 0.8124\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3441 - acc: 0.8104\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3447 - acc: 0.8104\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3433 - acc: 0.8109\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3407 - acc: 0.8094\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3386 - acc: 0.8114\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3381 - acc: 0.8171\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3380 - acc: 0.8145\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3383 - acc: 0.8155\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3402 - acc: 0.8052\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3372 - acc: 0.8104\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3353 - acc: 0.8099\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3349 - acc: 0.8099\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3328 - acc: 0.8207\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3329 - acc: 0.8212\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3340 - acc: 0.8099\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3340 - acc: 0.8129\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3317 - acc: 0.8165\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3325 - acc: 0.8160\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3292 - acc: 0.8155\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3295 - acc: 0.8124\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3332 - acc: 0.8171\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3318 - acc: 0.8114\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3287 - acc: 0.8160\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3303 - acc: 0.8212\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3323 - acc: 0.8124\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3279 - acc: 0.8155\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3274 - acc: 0.8201\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3297 - acc: 0.8109\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3292 - acc: 0.8073\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6080 - acc: 0.8460\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.7401 - acc: 0.7268\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.4281 - acc: 0.7982\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.4042 - acc: 0.8120\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.4012 - acc: 0.8141\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3921 - acc: 0.8192\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3903 - acc: 0.8207\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3892 - acc: 0.8161\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3849 - acc: 0.8177\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3847 - acc: 0.8084\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3797 - acc: 0.8223\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3738 - acc: 0.8218\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3770 - acc: 0.8177\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3741 - acc: 0.8228\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3731 - acc: 0.8254\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3706 - acc: 0.8238\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3716 - acc: 0.8151\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3683 - acc: 0.8166\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3660 - acc: 0.8300\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3645 - acc: 0.8238\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3666 - acc: 0.8197\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3616 - acc: 0.8243\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3624 - acc: 0.8218\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3601 - acc: 0.8243\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3610 - acc: 0.8274\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3590 - acc: 0.8279\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3573 - acc: 0.8269\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3560 - acc: 0.8254\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3544 - acc: 0.8310\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3555 - acc: 0.8228\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3556 - acc: 0.8233\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3532 - acc: 0.8233\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3521 - acc: 0.8290\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3502 - acc: 0.8315\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3484 - acc: 0.8300\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3501 - acc: 0.8295\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3506 - acc: 0.8300\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3478 - acc: 0.8346\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3466 - acc: 0.8351\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3503 - acc: 0.8279\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3462 - acc: 0.8315\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3486 - acc: 0.8331\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3471 - acc: 0.8310\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3433 - acc: 0.8279\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3443 - acc: 0.8341\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3450 - acc: 0.8362\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3437 - acc: 0.8351\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3436 - acc: 0.8300\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3431 - acc: 0.8336\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3429 - acc: 0.8300\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3446 - acc: 0.8290\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2921 - acc: 0.8489\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.6942 - acc: 0.7786\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3180 - acc: 0.8613\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2883 - acc: 0.8618\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2865 - acc: 0.8577\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2777 - acc: 0.8654\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2814 - acc: 0.8634\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2759 - acc: 0.8629\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2735 - acc: 0.8716\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2746 - acc: 0.8659\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2767 - acc: 0.8629\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2681 - acc: 0.8659\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2689 - acc: 0.8624\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2653 - acc: 0.8670\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2658 - acc: 0.8588\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2644 - acc: 0.8613\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2635 - acc: 0.8742\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2618 - acc: 0.8665\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2629 - acc: 0.8675\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2596 - acc: 0.8721\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2634 - acc: 0.8685\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2641 - acc: 0.8731\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2644 - acc: 0.8695\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2599 - acc: 0.8706\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2583 - acc: 0.8737\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2583 - acc: 0.8742\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2582 - acc: 0.8721\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2594 - acc: 0.8608\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2562 - acc: 0.8757\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2566 - acc: 0.8706\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2539 - acc: 0.8726\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2560 - acc: 0.8695\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2550 - acc: 0.8731\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2547 - acc: 0.8675\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2525 - acc: 0.8721\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2550 - acc: 0.8711\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2566 - acc: 0.8711\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2539 - acc: 0.8690\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2510 - acc: 0.8711\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2523 - acc: 0.8721\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2563 - acc: 0.8737\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2528 - acc: 0.8731\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2520 - acc: 0.8778\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2521 - acc: 0.8793\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2510 - acc: 0.8721\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2496 - acc: 0.8742\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2515 - acc: 0.8742\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2497 - acc: 0.8793\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2518 - acc: 0.8752\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2538 - acc: 0.8675\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2486 - acc: 0.8762\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6783 - acc: 0.7749\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 2ms/step - loss: 0.9632 - acc: 0.5663\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.6435 - acc: 0.7097\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4809 - acc: 0.7744\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4189 - acc: 0.7873\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3999 - acc: 0.7903\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3898 - acc: 0.7909\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3843 - acc: 0.8006\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3762 - acc: 0.8094\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3732 - acc: 0.8104\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3715 - acc: 0.8011\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3659 - acc: 0.8078\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3642 - acc: 0.8140\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3626 - acc: 0.8150\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3595 - acc: 0.8068\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3573 - acc: 0.8150\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3565 - acc: 0.8073\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3550 - acc: 0.8042\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3547 - acc: 0.8145\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3542 - acc: 0.8083\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3510 - acc: 0.8099\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3507 - acc: 0.8165\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3506 - acc: 0.8073\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3501 - acc: 0.8083\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3473 - acc: 0.8150\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3465 - acc: 0.8078\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3471 - acc: 0.8176\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3453 - acc: 0.8140\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3454 - acc: 0.8058\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3438 - acc: 0.8155\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3433 - acc: 0.8217\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3428 - acc: 0.8165\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3436 - acc: 0.8145\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3414 - acc: 0.8145\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3427 - acc: 0.8109\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3417 - acc: 0.8171\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3425 - acc: 0.8150\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3414 - acc: 0.8109\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3395 - acc: 0.8176\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3399 - acc: 0.8150\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3420 - acc: 0.8171\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3407 - acc: 0.8114\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3390 - acc: 0.8119\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3389 - acc: 0.8176\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3389 - acc: 0.8135\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3393 - acc: 0.8119\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3379 - acc: 0.8119\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3367 - acc: 0.8196\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3390 - acc: 0.8160\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3403 - acc: 0.8145\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3430 - acc: 0.8078\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.4814 - acc: 0.8563\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.9494 - acc: 0.6266\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.6720 - acc: 0.6754\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.5515 - acc: 0.7365\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4629 - acc: 0.7874\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4240 - acc: 0.8053\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4133 - acc: 0.8120\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.4065 - acc: 0.8156\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4024 - acc: 0.8130\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3972 - acc: 0.8115\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3933 - acc: 0.8141\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3903 - acc: 0.8177\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3882 - acc: 0.8187\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3847 - acc: 0.8156\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3825 - acc: 0.8202\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3803 - acc: 0.8192\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3792 - acc: 0.8213\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3765 - acc: 0.8233\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3745 - acc: 0.8254\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3723 - acc: 0.8279\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3723 - acc: 0.8223\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3713 - acc: 0.8074\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3692 - acc: 0.8243\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3703 - acc: 0.8146\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3666 - acc: 0.8300\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3688 - acc: 0.8125\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3658 - acc: 0.8182\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3649 - acc: 0.8356\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3648 - acc: 0.8279\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3638 - acc: 0.8279\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3614 - acc: 0.8290\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3614 - acc: 0.8243\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3631 - acc: 0.8274\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3594 - acc: 0.8228\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3581 - acc: 0.8356\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3605 - acc: 0.8207\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3588 - acc: 0.8269\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3590 - acc: 0.8228\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3574 - acc: 0.8259\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3579 - acc: 0.8305\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3577 - acc: 0.8300\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3561 - acc: 0.8305\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3564 - acc: 0.8228\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3553 - acc: 0.8295\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3555 - acc: 0.8279\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3546 - acc: 0.8326\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3533 - acc: 0.8341\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3537 - acc: 0.8192\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3539 - acc: 0.8285\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3515 - acc: 0.8341\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3522 - acc: 0.8202\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2993 - acc: 0.8489\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.9367 - acc: 0.7072\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.5474 - acc: 0.8002\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3626 - acc: 0.8500\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3130 - acc: 0.8629\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2958 - acc: 0.8593\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2861 - acc: 0.8665\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2842 - acc: 0.8634\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2803 - acc: 0.8659\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2785 - acc: 0.8706\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2748 - acc: 0.8670\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2741 - acc: 0.8737\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2711 - acc: 0.8731\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2713 - acc: 0.8685\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2713 - acc: 0.8711\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2699 - acc: 0.8716\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2644 - acc: 0.8762\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2716 - acc: 0.8608\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2675 - acc: 0.8685\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2669 - acc: 0.8721\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2684 - acc: 0.8675\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2640 - acc: 0.8762\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2654 - acc: 0.8654\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2652 - acc: 0.8654\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2637 - acc: 0.8598\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2637 - acc: 0.8752\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2627 - acc: 0.8685\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2621 - acc: 0.8726\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2633 - acc: 0.8706\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2621 - acc: 0.8721\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2612 - acc: 0.8716\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2597 - acc: 0.8649\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2599 - acc: 0.8716\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2588 - acc: 0.8726\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2588 - acc: 0.8767\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2584 - acc: 0.8752\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2584 - acc: 0.8716\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2577 - acc: 0.8721\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2586 - acc: 0.8716\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2576 - acc: 0.8721\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2563 - acc: 0.8762\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2573 - acc: 0.8767\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2570 - acc: 0.8675\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2577 - acc: 0.8695\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2552 - acc: 0.8716\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2554 - acc: 0.8742\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2562 - acc: 0.8726\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2567 - acc: 0.8721\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2543 - acc: 0.8726\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2543 - acc: 0.8742\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2545 - acc: 0.8690\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6514 - acc: 0.7482\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7947 - acc: 0.7205\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4372 - acc: 0.8001\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3913 - acc: 0.8027\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3777 - acc: 0.8088\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3754 - acc: 0.8078\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3697 - acc: 0.8094\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3640 - acc: 0.8155\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3650 - acc: 0.8099\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3572 - acc: 0.8088\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3566 - acc: 0.8109\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3563 - acc: 0.8150\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3548 - acc: 0.8124\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3548 - acc: 0.8073\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3502 - acc: 0.8140\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3512 - acc: 0.8145\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3531 - acc: 0.8150\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3469 - acc: 0.8155\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3464 - acc: 0.8088\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3450 - acc: 0.8078\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3432 - acc: 0.8047\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3425 - acc: 0.8176\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3406 - acc: 0.8227\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3400 - acc: 0.8104\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3401 - acc: 0.8119\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3392 - acc: 0.8186\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3375 - acc: 0.8165\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3380 - acc: 0.8135\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3347 - acc: 0.8124\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3375 - acc: 0.8186\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3365 - acc: 0.8135\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3350 - acc: 0.8155\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3349 - acc: 0.8119\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3333 - acc: 0.8135\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3343 - acc: 0.8176\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3334 - acc: 0.8083\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3323 - acc: 0.8191\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3299 - acc: 0.8191\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3319 - acc: 0.8171\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.3325 - acc: 0.8109\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3282 - acc: 0.8279\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3323 - acc: 0.8104\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3271 - acc: 0.8191\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3308 - acc: 0.8114\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3292 - acc: 0.8150\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3288 - acc: 0.8186\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3273 - acc: 0.8078\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3229 - acc: 0.8196\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3276 - acc: 0.8176\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3273 - acc: 0.8083\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3264 - acc: 0.8145\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6031 - acc: 0.8491\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7607 - acc: 0.7072\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4377 - acc: 0.8043\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4110 - acc: 0.8125\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3996 - acc: 0.8146\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3961 - acc: 0.8172\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3925 - acc: 0.8151\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3882 - acc: 0.8156\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3843 - acc: 0.8243\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3838 - acc: 0.8141\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3788 - acc: 0.8177\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3766 - acc: 0.8202\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3739 - acc: 0.8192\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3730 - acc: 0.8233\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3713 - acc: 0.8213\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3700 - acc: 0.8172\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3670 - acc: 0.8228\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3663 - acc: 0.8249\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3633 - acc: 0.8249\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3640 - acc: 0.8207\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3616 - acc: 0.8264\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3612 - acc: 0.8207\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3601 - acc: 0.8274\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3607 - acc: 0.8326\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3587 - acc: 0.8254\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3581 - acc: 0.8269\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3582 - acc: 0.8172\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3599 - acc: 0.8218\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3555 - acc: 0.8285\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3578 - acc: 0.8249\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3539 - acc: 0.8223\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3582 - acc: 0.8177\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3538 - acc: 0.8274\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3512 - acc: 0.8346\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3558 - acc: 0.8249\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3529 - acc: 0.8320\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3512 - acc: 0.8254\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3525 - acc: 0.8295\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3490 - acc: 0.8320\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3505 - acc: 0.8264\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3489 - acc: 0.8331\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3498 - acc: 0.8300\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3495 - acc: 0.8279\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3471 - acc: 0.8300\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3480 - acc: 0.8264\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3475 - acc: 0.8269\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3487 - acc: 0.8336\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3460 - acc: 0.8254\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3475 - acc: 0.8315\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3437 - acc: 0.8310\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3455 - acc: 0.8336\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2967 - acc: 0.8510\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7438 - acc: 0.7648\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3484 - acc: 0.8531\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2950 - acc: 0.8552\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2851 - acc: 0.8593\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2764 - acc: 0.8685\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2763 - acc: 0.8634\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2734 - acc: 0.8644\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2718 - acc: 0.8716\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2697 - acc: 0.8659\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2718 - acc: 0.8649\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2664 - acc: 0.8634\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2666 - acc: 0.8716\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2650 - acc: 0.8649\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2671 - acc: 0.8598\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2646 - acc: 0.8767\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2657 - acc: 0.8690\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2601 - acc: 0.8726\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2602 - acc: 0.8685\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2611 - acc: 0.8757\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2604 - acc: 0.8695\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2594 - acc: 0.8701\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2606 - acc: 0.8690\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2559 - acc: 0.8680\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2577 - acc: 0.8675\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2581 - acc: 0.8747\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2571 - acc: 0.8680\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2537 - acc: 0.8737\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2561 - acc: 0.8706\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2538 - acc: 0.8737\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2571 - acc: 0.8690\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2526 - acc: 0.8737\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2570 - acc: 0.8695\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2539 - acc: 0.8752\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2577 - acc: 0.8706\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2532 - acc: 0.8711\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2517 - acc: 0.8690\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2529 - acc: 0.8757\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2575 - acc: 0.8762\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2533 - acc: 0.8711\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2505 - acc: 0.8803\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2496 - acc: 0.8788\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 2ms/step - loss: 0.2500 - acc: 0.8711\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2506 - acc: 0.8706\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2510 - acc: 0.8690\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2470 - acc: 0.8788\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2510 - acc: 0.8757\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2485 - acc: 0.8803\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2483 - acc: 0.8695\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2475 - acc: 0.8762\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2470 - acc: 0.8731\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6659 - acc: 0.7575\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7368 - acc: 0.7220\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4106 - acc: 0.7955\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3842 - acc: 0.8032\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3751 - acc: 0.8037\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3692 - acc: 0.8145\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3711 - acc: 0.8058\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3663 - acc: 0.8099\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3639 - acc: 0.8124\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3610 - acc: 0.8094\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3602 - acc: 0.8088\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3580 - acc: 0.8109\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3534 - acc: 0.8129\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3523 - acc: 0.8083\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3527 - acc: 0.8058\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3507 - acc: 0.8124\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3496 - acc: 0.8032\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3482 - acc: 0.8186\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3465 - acc: 0.8094\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3440 - acc: 0.8150\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3431 - acc: 0.8109\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3434 - acc: 0.8119\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3448 - acc: 0.8104\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3413 - acc: 0.8181\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3387 - acc: 0.8099\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3406 - acc: 0.8135\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3380 - acc: 0.8212\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3399 - acc: 0.8145\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3370 - acc: 0.8207\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3355 - acc: 0.8160\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3352 - acc: 0.8171\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3377 - acc: 0.8119\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3352 - acc: 0.8119\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3353 - acc: 0.8088\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3334 - acc: 0.8145\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3334 - acc: 0.8088\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3310 - acc: 0.8237\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3327 - acc: 0.8150\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3338 - acc: 0.8104\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3310 - acc: 0.8243\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3332 - acc: 0.8145\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3293 - acc: 0.8165\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3308 - acc: 0.8109\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3296 - acc: 0.8181\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3297 - acc: 0.8109\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3284 - acc: 0.8140\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3319 - acc: 0.8073\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3289 - acc: 0.8150\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3258 - acc: 0.8201\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3301 - acc: 0.8160\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3268 - acc: 0.8191\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6295 - acc: 0.8480\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.7104 - acc: 0.7432\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4238 - acc: 0.8028\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.4070 - acc: 0.8074\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3966 - acc: 0.8043\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3943 - acc: 0.8120\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3880 - acc: 0.8192\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3870 - acc: 0.8182\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3842 - acc: 0.8172\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3821 - acc: 0.8192\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3764 - acc: 0.8249\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3762 - acc: 0.8213\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3745 - acc: 0.8192\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3719 - acc: 0.8218\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3712 - acc: 0.8228\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3721 - acc: 0.8136\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3716 - acc: 0.8207\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3709 - acc: 0.8207\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3690 - acc: 0.8141\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3637 - acc: 0.8202\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3628 - acc: 0.8238\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3605 - acc: 0.8218\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3615 - acc: 0.8218\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3603 - acc: 0.8233\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3585 - acc: 0.8274\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3574 - acc: 0.8207\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3596 - acc: 0.8259\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3559 - acc: 0.8264\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3553 - acc: 0.8279\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3548 - acc: 0.8274\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3535 - acc: 0.8290\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3517 - acc: 0.8305\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3562 - acc: 0.8238\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3517 - acc: 0.8274\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3514 - acc: 0.8259\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3506 - acc: 0.8310\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3488 - acc: 0.8243\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3488 - acc: 0.8310\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3523 - acc: 0.8187\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3506 - acc: 0.8218\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3474 - acc: 0.8331\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3470 - acc: 0.8285\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3462 - acc: 0.8341\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3454 - acc: 0.8310\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3452 - acc: 0.8331\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3428 - acc: 0.8305\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3440 - acc: 0.8341\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3460 - acc: 0.8269\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3437 - acc: 0.8315\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3433 - acc: 0.8259\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3399 - acc: 0.8367\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.2896 - acc: 0.8499\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 3ms/step - loss: 0.6959 - acc: 0.7802\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.3212 - acc: 0.8552\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2880 - acc: 0.8629\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2830 - acc: 0.8567\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2808 - acc: 0.8654\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2798 - acc: 0.8629\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2735 - acc: 0.8711\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2720 - acc: 0.8588\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2702 - acc: 0.8659\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2688 - acc: 0.8644\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2732 - acc: 0.8690\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2662 - acc: 0.8649\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2645 - acc: 0.8649\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2673 - acc: 0.8716\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2643 - acc: 0.8634\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2614 - acc: 0.8690\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2627 - acc: 0.8675\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2606 - acc: 0.8654\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2593 - acc: 0.8629\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2578 - acc: 0.8747\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2577 - acc: 0.8711\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2593 - acc: 0.8685\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2621 - acc: 0.8706\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2597 - acc: 0.8772\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2563 - acc: 0.8695\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2584 - acc: 0.8757\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2565 - acc: 0.8716\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2591 - acc: 0.8747\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2557 - acc: 0.8731\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2549 - acc: 0.8706\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2549 - acc: 0.8798\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2575 - acc: 0.8716\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2545 - acc: 0.8752\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2566 - acc: 0.8757\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2574 - acc: 0.8644\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2534 - acc: 0.8711\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2529 - acc: 0.8706\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2504 - acc: 0.8762\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2528 - acc: 0.8731\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2501 - acc: 0.8778\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2488 - acc: 0.8793\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2497 - acc: 0.8752\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2499 - acc: 0.8752\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2479 - acc: 0.8798\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2513 - acc: 0.8716\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2486 - acc: 0.8767\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2468 - acc: 0.8742\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2510 - acc: 0.8778\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2474 - acc: 0.8783\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 3ms/step - loss: 0.2475 - acc: 0.8762\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6972 - acc: 0.7688\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.6626 - acc: 0.7307\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3988 - acc: 0.7980\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3885 - acc: 0.7991\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3740 - acc: 0.8078\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3735 - acc: 0.8037\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3647 - acc: 0.8135\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3672 - acc: 0.8032\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3616 - acc: 0.8083\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3595 - acc: 0.8145\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3548 - acc: 0.8109\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3561 - acc: 0.8150\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3549 - acc: 0.8047\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3563 - acc: 0.8094\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3527 - acc: 0.8058\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3520 - acc: 0.8094\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3452 - acc: 0.8140\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3460 - acc: 0.8124\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3444 - acc: 0.8222\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3438 - acc: 0.8181\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3479 - acc: 0.8037\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3434 - acc: 0.8068\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3475 - acc: 0.8042\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3409 - acc: 0.8145\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3414 - acc: 0.8196\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3379 - acc: 0.8207\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3410 - acc: 0.8073\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3367 - acc: 0.8083\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3381 - acc: 0.8155\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3377 - acc: 0.8145\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3340 - acc: 0.8207\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3353 - acc: 0.8191\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3354 - acc: 0.8063\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3321 - acc: 0.8145\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3343 - acc: 0.8068\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3351 - acc: 0.8181\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3379 - acc: 0.8201\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3302 - acc: 0.8109\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3298 - acc: 0.8212\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3309 - acc: 0.8227\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3294 - acc: 0.8099\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3299 - acc: 0.8212\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3272 - acc: 0.8114\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3305 - acc: 0.8124\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3277 - acc: 0.8207\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3314 - acc: 0.8129\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3270 - acc: 0.8165\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3267 - acc: 0.8171\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3328 - acc: 0.8145\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3269 - acc: 0.8171\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3256 - acc: 0.8212\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 0.6446 - acc: 0.8419\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.6549 - acc: 0.7586\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.4208 - acc: 0.8095\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.4051 - acc: 0.8002\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.4012 - acc: 0.8038\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3935 - acc: 0.8182\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3882 - acc: 0.8130\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3836 - acc: 0.8192\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3812 - acc: 0.8202\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3803 - acc: 0.8172\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3783 - acc: 0.8197\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3775 - acc: 0.8213\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3802 - acc: 0.8177\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3728 - acc: 0.8141\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3720 - acc: 0.8177\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3745 - acc: 0.8238\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3685 - acc: 0.8228\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3681 - acc: 0.8146\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3666 - acc: 0.8269\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3623 - acc: 0.8233\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3641 - acc: 0.8269\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3657 - acc: 0.8207\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3627 - acc: 0.8177\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3600 - acc: 0.8187\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3592 - acc: 0.8259\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3583 - acc: 0.8279\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3627 - acc: 0.8269\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3595 - acc: 0.8249\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3567 - acc: 0.8274\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3548 - acc: 0.8300\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3570 - acc: 0.8218\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3538 - acc: 0.8290\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3523 - acc: 0.8249\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3521 - acc: 0.8326\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3531 - acc: 0.8207\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3522 - acc: 0.8305\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3500 - acc: 0.8315\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3510 - acc: 0.8285\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3489 - acc: 0.8290\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3479 - acc: 0.8254\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3489 - acc: 0.8305\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3488 - acc: 0.8326\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3473 - acc: 0.8259\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3434 - acc: 0.8269\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3475 - acc: 0.8310\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3469 - acc: 0.8207\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3486 - acc: 0.8315\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3445 - acc: 0.8367\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3457 - acc: 0.8300\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3485 - acc: 0.8305\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3473 - acc: 0.8264\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.2895 - acc: 0.8602\n",
      "Epoch 1/50\n",
      "61/61 [==============================] - 1s 4ms/step - loss: 0.6147 - acc: 0.7956\n",
      "Epoch 2/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.3122 - acc: 0.8428\n",
      "Epoch 3/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2874 - acc: 0.8598\n",
      "Epoch 4/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2869 - acc: 0.8618\n",
      "Epoch 5/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2744 - acc: 0.8639\n",
      "Epoch 6/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2804 - acc: 0.8613\n",
      "Epoch 7/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2744 - acc: 0.8644\n",
      "Epoch 8/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2708 - acc: 0.8685\n",
      "Epoch 9/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2703 - acc: 0.8659\n",
      "Epoch 10/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2712 - acc: 0.8577\n",
      "Epoch 11/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2671 - acc: 0.8690\n",
      "Epoch 12/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2697 - acc: 0.8618\n",
      "Epoch 13/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2639 - acc: 0.8757\n",
      "Epoch 14/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2631 - acc: 0.8752\n",
      "Epoch 15/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2658 - acc: 0.8546\n",
      "Epoch 16/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2622 - acc: 0.8716\n",
      "Epoch 17/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2620 - acc: 0.8654\n",
      "Epoch 18/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2611 - acc: 0.8721\n",
      "Epoch 19/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2578 - acc: 0.8639\n",
      "Epoch 20/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2585 - acc: 0.8706\n",
      "Epoch 21/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2589 - acc: 0.8737\n",
      "Epoch 22/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2589 - acc: 0.8726\n",
      "Epoch 23/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2550 - acc: 0.8742\n",
      "Epoch 24/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2582 - acc: 0.8634\n",
      "Epoch 25/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2550 - acc: 0.8731\n",
      "Epoch 26/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2557 - acc: 0.8665\n",
      "Epoch 27/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2583 - acc: 0.8711\n",
      "Epoch 28/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2551 - acc: 0.8731\n",
      "Epoch 29/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2543 - acc: 0.8706\n",
      "Epoch 30/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2515 - acc: 0.8737\n",
      "Epoch 31/50\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2522 - acc: 0.8819\n",
      "Epoch 32/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2520 - acc: 0.8757\n",
      "Epoch 33/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2530 - acc: 0.8675\n",
      "Epoch 34/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2503 - acc: 0.8834\n",
      "Epoch 35/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2495 - acc: 0.8711\n",
      "Epoch 36/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2498 - acc: 0.8634\n",
      "Epoch 37/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2499 - acc: 0.8783\n",
      "Epoch 38/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2514 - acc: 0.8695\n",
      "Epoch 39/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2486 - acc: 0.8747\n",
      "Epoch 40/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2489 - acc: 0.8762\n",
      "Epoch 41/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2496 - acc: 0.8767\n",
      "Epoch 42/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2465 - acc: 0.8762\n",
      "Epoch 43/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2472 - acc: 0.8726\n",
      "Epoch 44/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2455 - acc: 0.8731\n",
      "Epoch 45/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2497 - acc: 0.8757\n",
      "Epoch 46/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2468 - acc: 0.8757\n",
      "Epoch 47/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2450 - acc: 0.8772\n",
      "Epoch 48/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2444 - acc: 0.8772\n",
      "Epoch 49/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2457 - acc: 0.8731\n",
      "Epoch 50/50\n",
      "61/61 [==============================] - 0s 4ms/step - loss: 0.2462 - acc: 0.8798\n",
      "31/31 [==============================] - 0s 2ms/step - loss: 0.7210 - acc: 0.7554\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 1s 3ms/step - loss: 0.9642 - acc: 0.7144\n",
      "Epoch 2/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.6205 - acc: 0.7969\n",
      "Epoch 3/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.4249 - acc: 0.8223\n",
      "Epoch 4/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3789 - acc: 0.8274\n",
      "Epoch 5/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3686 - acc: 0.8233\n",
      "Epoch 6/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3623 - acc: 0.8264\n",
      "Epoch 7/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3582 - acc: 0.8308\n",
      "Epoch 8/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3570 - acc: 0.8240\n",
      "Epoch 9/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3537 - acc: 0.8308\n",
      "Epoch 10/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3514 - acc: 0.8257\n",
      "Epoch 11/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3506 - acc: 0.8380\n",
      "Epoch 12/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3486 - acc: 0.8264\n",
      "Epoch 13/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3473 - acc: 0.8277\n",
      "Epoch 14/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3458 - acc: 0.8291\n",
      "Epoch 15/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3441 - acc: 0.8336\n",
      "Epoch 16/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3425 - acc: 0.8353\n",
      "Epoch 17/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3422 - acc: 0.8360\n",
      "Epoch 18/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3417 - acc: 0.8281\n",
      "Epoch 19/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3401 - acc: 0.8240\n",
      "Epoch 20/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3390 - acc: 0.8390\n",
      "Epoch 21/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3376 - acc: 0.8332\n",
      "Epoch 22/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3371 - acc: 0.8360\n",
      "Epoch 23/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3367 - acc: 0.8390\n",
      "Epoch 24/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3362 - acc: 0.8390\n",
      "Epoch 25/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3349 - acc: 0.8377\n",
      "Epoch 26/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3348 - acc: 0.8226\n",
      "Epoch 27/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3334 - acc: 0.8377\n",
      "Epoch 28/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3336 - acc: 0.8373\n",
      "Epoch 29/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3324 - acc: 0.8384\n",
      "Epoch 30/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3334 - acc: 0.8346\n",
      "Epoch 31/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3319 - acc: 0.8370\n",
      "Epoch 32/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3307 - acc: 0.8411\n",
      "Epoch 33/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3312 - acc: 0.8363\n",
      "Epoch 34/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3305 - acc: 0.8394\n",
      "Epoch 35/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3308 - acc: 0.8377\n",
      "Epoch 36/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3301 - acc: 0.8363\n",
      "Epoch 37/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3290 - acc: 0.8342\n",
      "Epoch 38/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3290 - acc: 0.8370\n",
      "Epoch 39/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3291 - acc: 0.8384\n",
      "Epoch 40/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3287 - acc: 0.8384\n",
      "Epoch 41/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3282 - acc: 0.8363\n",
      "Epoch 42/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3272 - acc: 0.8366\n",
      "Epoch 43/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3282 - acc: 0.8373\n",
      "Epoch 44/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3265 - acc: 0.8353\n",
      "Epoch 45/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3272 - acc: 0.8387\n",
      "Epoch 46/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3270 - acc: 0.8387\n",
      "Epoch 47/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3287 - acc: 0.8425\n",
      "Epoch 48/50\n",
      "92/92 [==============================] - 0s 3ms/step - loss: 0.3265 - acc: 0.8377\n",
      "Epoch 49/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3265 - acc: 0.8336\n",
      "Epoch 50/50\n",
      "92/92 [==============================] - 0s 2ms/step - loss: 0.3269 - acc: 0.8325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f1c6158cfd0>,\n",
       "             param_grid={'nodes_dense': [8, 64, 120, 240],\n",
       "                         'nodes_lstm': [8, 64, 120, 240]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit lstm_gs \n",
    "lstm_gs.fit(X_train_lstm,y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d30ec272-ffce-4699-b65c-94300a24925f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.311814Z",
     "iopub.status.busy": "2021-08-27T04:18:17.311666Z",
     "iopub.status.idle": "2021-08-27T04:18:17.316401Z",
     "shell.execute_reply": "2021-08-27T04:18:17.315354Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.311797Z"
    },
    "id": "d30ec272-ffce-4699-b65c-94300a24925f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gs_results(gs):\n",
    "    return pd.DataFrame(gs.cv_results_)[['params','mean_test_score']].sort_values(by='mean_test_score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3fc8bd60-6822-499c-88e6-6e3b98623b00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.317233Z",
     "iopub.status.busy": "2021-08-27T04:18:17.317068Z",
     "iopub.status.idle": "2021-08-27T04:18:17.330166Z",
     "shell.execute_reply": "2021-08-27T04:18:17.329376Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.317217Z"
    },
    "id": "3fc8bd60-6822-499c-88e6-6e3b98623b00",
    "outputId": "e07c75fa-815a-486a-b9c5-7e56e8ffeda9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'nodes_dense': 8, 'nodes_lstm': 64}</td>\n",
       "      <td>0.825334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'nodes_dense': 64, 'nodes_lstm': 120}</td>\n",
       "      <td>0.825334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'nodes_dense': 120, 'nodes_lstm': 240}</td>\n",
       "      <td>0.823280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'nodes_dense': 64, 'nodes_lstm': 64}</td>\n",
       "      <td>0.823279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'nodes_dense': 240, 'nodes_lstm': 120}</td>\n",
       "      <td>0.822251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'nodes_dense': 8, 'nodes_lstm': 120}</td>\n",
       "      <td>0.821910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'nodes_dense': 64, 'nodes_lstm': 8}</td>\n",
       "      <td>0.821222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'nodes_dense': 8, 'nodes_lstm': 240}</td>\n",
       "      <td>0.819852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'nodes_dense': 240, 'nodes_lstm': 240}</td>\n",
       "      <td>0.819170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'nodes_dense': 240, 'nodes_lstm': 64}</td>\n",
       "      <td>0.819168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'nodes_dense': 64, 'nodes_lstm': 240}</td>\n",
       "      <td>0.819167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'nodes_dense': 8, 'nodes_lstm': 8}</td>\n",
       "      <td>0.818822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'nodes_dense': 240, 'nodes_lstm': 8}</td>\n",
       "      <td>0.817795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'nodes_dense': 120, 'nodes_lstm': 120}</td>\n",
       "      <td>0.816772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'nodes_dense': 120, 'nodes_lstm': 8}</td>\n",
       "      <td>0.816769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'nodes_dense': 120, 'nodes_lstm': 64}</td>\n",
       "      <td>0.815399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score\n",
       "1      {'nodes_dense': 8, 'nodes_lstm': 64}         0.825334\n",
       "6    {'nodes_dense': 64, 'nodes_lstm': 120}         0.825334\n",
       "11  {'nodes_dense': 120, 'nodes_lstm': 240}         0.823280\n",
       "5     {'nodes_dense': 64, 'nodes_lstm': 64}         0.823279\n",
       "14  {'nodes_dense': 240, 'nodes_lstm': 120}         0.822251\n",
       "2     {'nodes_dense': 8, 'nodes_lstm': 120}         0.821910\n",
       "4      {'nodes_dense': 64, 'nodes_lstm': 8}         0.821222\n",
       "3     {'nodes_dense': 8, 'nodes_lstm': 240}         0.819852\n",
       "15  {'nodes_dense': 240, 'nodes_lstm': 240}         0.819170\n",
       "13   {'nodes_dense': 240, 'nodes_lstm': 64}         0.819168\n",
       "7    {'nodes_dense': 64, 'nodes_lstm': 240}         0.819167\n",
       "0       {'nodes_dense': 8, 'nodes_lstm': 8}         0.818822\n",
       "12    {'nodes_dense': 240, 'nodes_lstm': 8}         0.817795\n",
       "10  {'nodes_dense': 120, 'nodes_lstm': 120}         0.816772\n",
       "8     {'nodes_dense': 120, 'nodes_lstm': 8}         0.816769\n",
       "9    {'nodes_dense': 120, 'nodes_lstm': 64}         0.815399"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_results(lstm_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ae04f414-f28a-4c9f-8ad1-d3ddd8c6d22d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.331081Z",
     "iopub.status.busy": "2021-08-27T04:18:17.330937Z",
     "iopub.status.idle": "2021-08-27T04:18:17.335897Z",
     "shell.execute_reply": "2021-08-27T04:18:17.335366Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.331065Z"
    },
    "id": "ae04f414-f28a-4c9f-8ad1-d3ddd8c6d22d",
    "outputId": "a955e354-76f0-4bf1-dad9-f38b67eb0bf5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes_dense': 8, 'nodes_lstm': 64}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "468b5f7e-9de8-4277-8b73-3d95aa0235b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.336618Z",
     "iopub.status.busy": "2021-08-27T04:18:17.336494Z",
     "iopub.status.idle": "2021-08-27T04:18:17.742249Z",
     "shell.execute_reply": "2021-08-27T04:18:17.741487Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.336604Z"
    },
    "id": "468b5f7e-9de8-4277-8b73-3d95aa0235b9",
    "outputId": "7fb97f48-4e49-43c1-8ce7-c4f435c58e74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 1ms/step - loss: 0.3227 - acc: 0.8404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8404109477996826"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_gs.score(X_train_lstm,y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d8a96780-39f0-435c-9284-cb64e3ac3d95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.743226Z",
     "iopub.status.busy": "2021-08-27T04:18:17.743074Z",
     "iopub.status.idle": "2021-08-27T04:18:17.921348Z",
     "shell.execute_reply": "2021-08-27T04:18:17.919984Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.743210Z"
    },
    "id": "d8a96780-39f0-435c-9284-cb64e3ac3d95",
    "outputId": "6f3628fb-2e09-4a83-d656-e9d59be43f5c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 0s 993us/step - loss: 0.3227 - acc: 0.8404\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4864 - acc: 0.8044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8404109477996826, 0.804377555847168)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_gs.score(X_train_lstm,y_train_nn), lstm_gs.score(X_test_lstm,y_test_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "156216b5-9e07-438d-9cfb-0b3639fcfaf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T12:02:14.602737Z",
     "iopub.status.busy": "2021-08-27T12:02:14.602543Z",
     "iopub.status.idle": "2021-08-27T12:02:14.773815Z",
     "shell.execute_reply": "2021-08-27T12:02:14.773119Z",
     "shell.execute_reply.started": "2021-08-27T12:02:14.602720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_211\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_203 (LSTM)              (None, 64)                19200     \n",
      "_________________________________________________________________\n",
      "dense_634 (Dense)            (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "dense_635 (Dense)            (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 19,747\n",
      "Trainable params: 19,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# best lstm model \n",
    "# model network \n",
    "\n",
    "best_lstm = Sequential()\n",
    "best_lstm.add(LSTM(64,input_shape=(1,10)))\n",
    "best_lstm.add(Dense(8,activation='relu'))\n",
    "best_lstm.add(Dense(3,activation='softmax'))\n",
    "\n",
    "\n",
    "# compile model \n",
    "best_lstm.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "best_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "20bc635e-9382-41ab-a8ee-eda8e1760268",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T12:02:35.121975Z",
     "iopub.status.busy": "2021-08-27T12:02:35.121778Z",
     "iopub.status.idle": "2021-08-27T12:02:59.879823Z",
     "shell.execute_reply": "2021-08-27T12:02:59.879100Z",
     "shell.execute_reply.started": "2021-08-27T12:02:35.121957Z"
    },
    "id": "2a78b401-3bdd-4719-b5d7-dd6a7329a7bc",
    "outputId": "5563b0cb-28ec-4850-ed57-de8a6f336b5d",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "92/92 - 1s - loss: 0.9133 - acc: 0.7216 - val_loss: 0.6856 - val_acc: 0.7620\n",
      "Epoch 2/100\n",
      "92/92 - 0s - loss: 0.5379 - acc: 0.7997 - val_loss: 0.5066 - val_acc: 0.7633\n",
      "Epoch 3/100\n",
      "92/92 - 0s - loss: 0.4129 - acc: 0.8103 - val_loss: 0.5223 - val_acc: 0.7756\n",
      "Epoch 4/100\n",
      "92/92 - 0s - loss: 0.3920 - acc: 0.8127 - val_loss: 0.5428 - val_acc: 0.7565\n",
      "Epoch 5/100\n",
      "92/92 - 0s - loss: 0.3815 - acc: 0.8192 - val_loss: 0.5553 - val_acc: 0.7606\n",
      "Epoch 6/100\n",
      "92/92 - 0s - loss: 0.3772 - acc: 0.8158 - val_loss: 0.5575 - val_acc: 0.7743\n",
      "Epoch 7/100\n",
      "92/92 - 0s - loss: 0.3732 - acc: 0.8127 - val_loss: 0.5550 - val_acc: 0.7784\n",
      "Epoch 8/100\n",
      "92/92 - 0s - loss: 0.3721 - acc: 0.8151 - val_loss: 0.5604 - val_acc: 0.7538\n",
      "Epoch 9/100\n",
      "92/92 - 0s - loss: 0.3688 - acc: 0.8151 - val_loss: 0.5613 - val_acc: 0.7565\n",
      "Epoch 10/100\n",
      "92/92 - 0s - loss: 0.3669 - acc: 0.8202 - val_loss: 0.5608 - val_acc: 0.7565\n",
      "Epoch 11/100\n",
      "92/92 - 0s - loss: 0.3634 - acc: 0.8226 - val_loss: 0.5680 - val_acc: 0.7606\n",
      "Epoch 12/100\n",
      "92/92 - 0s - loss: 0.3646 - acc: 0.8130 - val_loss: 0.5569 - val_acc: 0.7743\n",
      "Epoch 13/100\n",
      "92/92 - 0s - loss: 0.3597 - acc: 0.8216 - val_loss: 0.5511 - val_acc: 0.7756\n",
      "Epoch 14/100\n",
      "92/92 - 0s - loss: 0.3585 - acc: 0.8161 - val_loss: 0.5460 - val_acc: 0.7934\n",
      "Epoch 15/100\n",
      "92/92 - 0s - loss: 0.3571 - acc: 0.8301 - val_loss: 0.5447 - val_acc: 0.7907\n",
      "Epoch 16/100\n",
      "92/92 - 0s - loss: 0.3545 - acc: 0.8360 - val_loss: 0.5368 - val_acc: 0.7880\n",
      "Epoch 17/100\n",
      "92/92 - 0s - loss: 0.3528 - acc: 0.8312 - val_loss: 0.5397 - val_acc: 0.7921\n",
      "Epoch 18/100\n",
      "92/92 - 0s - loss: 0.3506 - acc: 0.8295 - val_loss: 0.5337 - val_acc: 0.7948\n",
      "Epoch 19/100\n",
      "92/92 - 0s - loss: 0.3480 - acc: 0.8339 - val_loss: 0.5328 - val_acc: 0.7948\n",
      "Epoch 20/100\n",
      "92/92 - 0s - loss: 0.3471 - acc: 0.8346 - val_loss: 0.5278 - val_acc: 0.7880\n",
      "Epoch 21/100\n",
      "92/92 - 0s - loss: 0.3451 - acc: 0.8342 - val_loss: 0.5203 - val_acc: 0.7907\n",
      "Epoch 22/100\n",
      "92/92 - 0s - loss: 0.3434 - acc: 0.8356 - val_loss: 0.5261 - val_acc: 0.7948\n",
      "Epoch 23/100\n",
      "92/92 - 0s - loss: 0.3432 - acc: 0.8301 - val_loss: 0.5210 - val_acc: 0.7962\n",
      "Epoch 24/100\n",
      "92/92 - 0s - loss: 0.3416 - acc: 0.8336 - val_loss: 0.5226 - val_acc: 0.7934\n",
      "Epoch 25/100\n",
      "92/92 - 0s - loss: 0.3409 - acc: 0.8356 - val_loss: 0.5221 - val_acc: 0.7948\n",
      "Epoch 26/100\n",
      "92/92 - 0s - loss: 0.3395 - acc: 0.8353 - val_loss: 0.5302 - val_acc: 0.7743\n",
      "Epoch 27/100\n",
      "92/92 - 0s - loss: 0.3393 - acc: 0.8298 - val_loss: 0.5177 - val_acc: 0.7975\n",
      "Epoch 28/100\n",
      "92/92 - 0s - loss: 0.3375 - acc: 0.8394 - val_loss: 0.5200 - val_acc: 0.7921\n",
      "Epoch 29/100\n",
      "92/92 - 0s - loss: 0.3377 - acc: 0.8377 - val_loss: 0.5169 - val_acc: 0.7962\n",
      "Epoch 30/100\n",
      "92/92 - 0s - loss: 0.3364 - acc: 0.8342 - val_loss: 0.5199 - val_acc: 0.7770\n",
      "Epoch 31/100\n",
      "92/92 - 0s - loss: 0.3359 - acc: 0.8353 - val_loss: 0.5199 - val_acc: 0.7784\n",
      "Epoch 32/100\n",
      "92/92 - 0s - loss: 0.3348 - acc: 0.8384 - val_loss: 0.5152 - val_acc: 0.7975\n",
      "Epoch 33/100\n",
      "92/92 - 0s - loss: 0.3348 - acc: 0.8336 - val_loss: 0.5199 - val_acc: 0.7852\n",
      "Epoch 34/100\n",
      "92/92 - 0s - loss: 0.3333 - acc: 0.8356 - val_loss: 0.5171 - val_acc: 0.7798\n",
      "Epoch 35/100\n",
      "92/92 - 0s - loss: 0.3339 - acc: 0.8322 - val_loss: 0.5117 - val_acc: 0.7962\n",
      "Epoch 36/100\n",
      "92/92 - 0s - loss: 0.3325 - acc: 0.8411 - val_loss: 0.5133 - val_acc: 0.7921\n",
      "Epoch 37/100\n",
      "92/92 - 0s - loss: 0.3321 - acc: 0.8390 - val_loss: 0.5136 - val_acc: 0.7948\n",
      "Epoch 38/100\n",
      "92/92 - 0s - loss: 0.3322 - acc: 0.8373 - val_loss: 0.5088 - val_acc: 0.7921\n",
      "Epoch 39/100\n",
      "92/92 - 0s - loss: 0.3319 - acc: 0.8397 - val_loss: 0.5158 - val_acc: 0.7921\n",
      "Epoch 40/100\n",
      "92/92 - 0s - loss: 0.3310 - acc: 0.8411 - val_loss: 0.5134 - val_acc: 0.7743\n",
      "Epoch 41/100\n",
      "92/92 - 0s - loss: 0.3316 - acc: 0.8360 - val_loss: 0.5125 - val_acc: 0.7893\n",
      "Epoch 42/100\n",
      "92/92 - 0s - loss: 0.3304 - acc: 0.8356 - val_loss: 0.5074 - val_acc: 0.7975\n",
      "Epoch 43/100\n",
      "92/92 - 0s - loss: 0.3297 - acc: 0.8394 - val_loss: 0.5100 - val_acc: 0.7825\n",
      "Epoch 44/100\n",
      "92/92 - 0s - loss: 0.3298 - acc: 0.8421 - val_loss: 0.5029 - val_acc: 0.7962\n",
      "Epoch 45/100\n",
      "92/92 - 0s - loss: 0.3306 - acc: 0.8366 - val_loss: 0.5020 - val_acc: 0.8030\n",
      "Epoch 46/100\n",
      "92/92 - 0s - loss: 0.3316 - acc: 0.8380 - val_loss: 0.5013 - val_acc: 0.7975\n",
      "Epoch 47/100\n",
      "92/92 - 0s - loss: 0.3304 - acc: 0.8312 - val_loss: 0.5119 - val_acc: 0.8003\n",
      "Epoch 48/100\n",
      "92/92 - 0s - loss: 0.3288 - acc: 0.8397 - val_loss: 0.5052 - val_acc: 0.7962\n",
      "Epoch 49/100\n",
      "92/92 - 0s - loss: 0.3296 - acc: 0.8342 - val_loss: 0.5091 - val_acc: 0.7962\n",
      "Epoch 50/100\n",
      "92/92 - 0s - loss: 0.3285 - acc: 0.8428 - val_loss: 0.5048 - val_acc: 0.7962\n",
      "Epoch 51/100\n",
      "92/92 - 0s - loss: 0.3277 - acc: 0.8411 - val_loss: 0.5077 - val_acc: 0.7852\n",
      "Epoch 52/100\n",
      "92/92 - 0s - loss: 0.3283 - acc: 0.8384 - val_loss: 0.4998 - val_acc: 0.7934\n",
      "Epoch 53/100\n",
      "92/92 - 0s - loss: 0.3286 - acc: 0.8291 - val_loss: 0.5050 - val_acc: 0.7948\n",
      "Epoch 54/100\n",
      "92/92 - 0s - loss: 0.3290 - acc: 0.8363 - val_loss: 0.5002 - val_acc: 0.7962\n",
      "Epoch 55/100\n",
      "92/92 - 0s - loss: 0.3275 - acc: 0.8360 - val_loss: 0.5039 - val_acc: 0.7962\n",
      "Epoch 56/100\n",
      "92/92 - 0s - loss: 0.3274 - acc: 0.8418 - val_loss: 0.5005 - val_acc: 0.7962\n",
      "Epoch 57/100\n",
      "92/92 - 0s - loss: 0.3270 - acc: 0.8401 - val_loss: 0.4990 - val_acc: 0.7975\n",
      "Epoch 58/100\n",
      "92/92 - 0s - loss: 0.3265 - acc: 0.8384 - val_loss: 0.5048 - val_acc: 0.7962\n",
      "Epoch 59/100\n",
      "92/92 - 0s - loss: 0.3260 - acc: 0.8418 - val_loss: 0.5061 - val_acc: 0.7962\n",
      "Epoch 60/100\n",
      "92/92 - 0s - loss: 0.3275 - acc: 0.8315 - val_loss: 0.5050 - val_acc: 0.7798\n",
      "Epoch 61/100\n",
      "92/92 - 0s - loss: 0.3260 - acc: 0.8432 - val_loss: 0.5015 - val_acc: 0.7852\n",
      "Epoch 62/100\n",
      "92/92 - 0s - loss: 0.3269 - acc: 0.8346 - val_loss: 0.5001 - val_acc: 0.7975\n",
      "Epoch 63/100\n",
      "92/92 - 0s - loss: 0.3273 - acc: 0.8370 - val_loss: 0.4972 - val_acc: 0.7784\n",
      "Epoch 64/100\n",
      "92/92 - 0s - loss: 0.3272 - acc: 0.8384 - val_loss: 0.4995 - val_acc: 0.7948\n",
      "Epoch 65/100\n",
      "92/92 - 0s - loss: 0.3256 - acc: 0.8349 - val_loss: 0.5002 - val_acc: 0.7962\n",
      "Epoch 66/100\n",
      "92/92 - 0s - loss: 0.3260 - acc: 0.8377 - val_loss: 0.4961 - val_acc: 0.7948\n",
      "Epoch 67/100\n",
      "92/92 - 0s - loss: 0.3255 - acc: 0.8387 - val_loss: 0.4963 - val_acc: 0.7989\n",
      "Epoch 68/100\n",
      "92/92 - 0s - loss: 0.3249 - acc: 0.8322 - val_loss: 0.4983 - val_acc: 0.7948\n",
      "Epoch 69/100\n",
      "92/92 - 0s - loss: 0.3262 - acc: 0.8377 - val_loss: 0.4997 - val_acc: 0.7811\n",
      "Epoch 70/100\n",
      "92/92 - 0s - loss: 0.3245 - acc: 0.8404 - val_loss: 0.4985 - val_acc: 0.7934\n",
      "Epoch 71/100\n",
      "92/92 - 0s - loss: 0.3247 - acc: 0.8349 - val_loss: 0.4944 - val_acc: 0.7975\n",
      "Epoch 72/100\n",
      "92/92 - 0s - loss: 0.3239 - acc: 0.8397 - val_loss: 0.4949 - val_acc: 0.7948\n",
      "Epoch 73/100\n",
      "92/92 - 0s - loss: 0.3241 - acc: 0.8435 - val_loss: 0.4999 - val_acc: 0.7770\n",
      "Epoch 74/100\n",
      "92/92 - 0s - loss: 0.3245 - acc: 0.8305 - val_loss: 0.4956 - val_acc: 0.8016\n",
      "Epoch 75/100\n",
      "92/92 - 0s - loss: 0.3248 - acc: 0.8414 - val_loss: 0.4950 - val_acc: 0.7975\n",
      "Epoch 76/100\n",
      "92/92 - 0s - loss: 0.3237 - acc: 0.8332 - val_loss: 0.4938 - val_acc: 0.7989\n",
      "Epoch 77/100\n",
      "92/92 - 0s - loss: 0.3231 - acc: 0.8428 - val_loss: 0.4975 - val_acc: 0.8003\n",
      "Epoch 78/100\n",
      "92/92 - 0s - loss: 0.3232 - acc: 0.8425 - val_loss: 0.4975 - val_acc: 0.7962\n",
      "Epoch 79/100\n",
      "92/92 - 0s - loss: 0.3239 - acc: 0.8438 - val_loss: 0.5024 - val_acc: 0.7784\n",
      "Epoch 80/100\n",
      "92/92 - 0s - loss: 0.3236 - acc: 0.8394 - val_loss: 0.4983 - val_acc: 0.7825\n",
      "Epoch 81/100\n",
      "92/92 - 0s - loss: 0.3215 - acc: 0.8390 - val_loss: 0.4909 - val_acc: 0.7989\n",
      "Epoch 82/100\n",
      "92/92 - 0s - loss: 0.3227 - acc: 0.8418 - val_loss: 0.4908 - val_acc: 0.8030\n",
      "Epoch 83/100\n",
      "92/92 - 0s - loss: 0.3230 - acc: 0.8401 - val_loss: 0.4914 - val_acc: 0.8030\n",
      "Epoch 84/100\n",
      "92/92 - 0s - loss: 0.3222 - acc: 0.8366 - val_loss: 0.4901 - val_acc: 0.7989\n",
      "Epoch 85/100\n",
      "92/92 - 0s - loss: 0.3222 - acc: 0.8432 - val_loss: 0.4957 - val_acc: 0.8057\n",
      "Epoch 86/100\n",
      "92/92 - 0s - loss: 0.3216 - acc: 0.8377 - val_loss: 0.5012 - val_acc: 0.7852\n",
      "Epoch 87/100\n",
      "92/92 - 0s - loss: 0.3216 - acc: 0.8377 - val_loss: 0.4937 - val_acc: 0.8003\n",
      "Epoch 88/100\n",
      "92/92 - 0s - loss: 0.3223 - acc: 0.8339 - val_loss: 0.4933 - val_acc: 0.8003\n",
      "Epoch 89/100\n",
      "92/92 - 0s - loss: 0.3211 - acc: 0.8404 - val_loss: 0.5011 - val_acc: 0.7989\n",
      "Epoch 90/100\n",
      "92/92 - 0s - loss: 0.3214 - acc: 0.8408 - val_loss: 0.4959 - val_acc: 0.8003\n",
      "Epoch 91/100\n",
      "92/92 - 0s - loss: 0.3206 - acc: 0.8397 - val_loss: 0.4906 - val_acc: 0.7975\n",
      "Epoch 92/100\n",
      "92/92 - 0s - loss: 0.3214 - acc: 0.8390 - val_loss: 0.4924 - val_acc: 0.8044\n",
      "Epoch 93/100\n",
      "92/92 - 0s - loss: 0.3206 - acc: 0.8421 - val_loss: 0.4933 - val_acc: 0.7975\n",
      "Epoch 94/100\n",
      "92/92 - 0s - loss: 0.3206 - acc: 0.8445 - val_loss: 0.4967 - val_acc: 0.8016\n",
      "Epoch 95/100\n",
      "92/92 - 0s - loss: 0.3209 - acc: 0.8414 - val_loss: 0.4916 - val_acc: 0.8016\n",
      "Epoch 96/100\n",
      "92/92 - 0s - loss: 0.3199 - acc: 0.8390 - val_loss: 0.4916 - val_acc: 0.8044\n",
      "Epoch 97/100\n",
      "92/92 - 0s - loss: 0.3207 - acc: 0.8449 - val_loss: 0.4926 - val_acc: 0.8003\n",
      "Epoch 98/100\n",
      "92/92 - 0s - loss: 0.3207 - acc: 0.8394 - val_loss: 0.4914 - val_acc: 0.7852\n",
      "Epoch 99/100\n",
      "92/92 - 0s - loss: 0.3195 - acc: 0.8390 - val_loss: 0.4940 - val_acc: 0.7989\n",
      "Epoch 100/100\n",
      "92/92 - 0s - loss: 0.3202 - acc: 0.8425 - val_loss: 0.4945 - val_acc: 0.7989\n"
     ]
    }
   ],
   "source": [
    "# fit model \n",
    "hist_best_lstm = best_lstm.fit(X_train_lstm,y_train_nn,\n",
    "                     validation_data=(X_test_lstm,y_test_nn),\n",
    "                  epochs=100,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6b70b2e0-f612-4bba-9d27-b9ce8cac791e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T12:54:26.159086Z",
     "iopub.status.busy": "2021-08-27T12:54:26.158818Z",
     "iopub.status.idle": "2021-08-27T12:54:26.163299Z",
     "shell.execute_reply": "2021-08-27T12:54:26.162246Z",
     "shell.execute_reply.started": "2021-08-27T12:54:26.159068Z"
    },
    "id": "fe2e7f29-0d2e-4522-bb18-a0c3ea697e28",
    "outputId": "26533696-4388-4f12-833b-40af2e7d5cdb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_acc(best_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-C9CNIblT7U-",
   "metadata": {
    "id": "-C9CNIblT7U-"
   },
   "source": [
    "### Randomized Search \n",
    "\n",
    "adding another dense layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "Rc6YdV-pT_hX",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.922344Z",
     "iopub.status.busy": "2021-08-27T04:18:17.922208Z",
     "iopub.status.idle": "2021-08-27T04:18:17.926291Z",
     "shell.execute_reply": "2021-08-27T04:18:17.925033Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.922328Z"
    },
    "id": "Rc6YdV-pT_hX"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "Vn7cqepgUd4n",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.926902Z",
     "iopub.status.busy": "2021-08-27T04:18:17.926775Z",
     "iopub.status.idle": "2021-08-27T04:18:17.929881Z",
     "shell.execute_reply": "2021-08-27T04:18:17.929044Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.926888Z"
    },
    "id": "Vn7cqepgUd4n"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ns9Ugdh47WW",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.930704Z",
     "iopub.status.busy": "2021-08-27T04:18:17.930572Z",
     "iopub.status.idle": "2021-08-27T04:18:17.935762Z",
     "shell.execute_reply": "2021-08-27T04:18:17.934989Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.930689Z"
    },
    "id": "1ns9Ugdh47WW"
   },
   "outputs": [],
   "source": [
    "# function to make models \n",
    "def model_func_lstm2(nodes_lstm,nodes_dense1,nodes_dense2):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nodes_lstm,input_shape=(1,10)))\n",
    "    model.add(Dense(nodes_dense1,activation='relu'))\n",
    "    model.add(Dense(nodes_dense2,activation='relu'))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model \n",
    "\n",
    "# wrapper \n",
    "lstm_modeler = KerasClassifier(build_fn=model_func_lstm2,epochs=50,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "v2MB74NAUOVm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:18:17.936766Z",
     "iopub.status.busy": "2021-08-27T04:18:17.936587Z",
     "iopub.status.idle": "2021-08-27T04:30:15.143785Z",
     "shell.execute_reply": "2021-08-27T04:30:15.143048Z",
     "shell.execute_reply.started": "2021-08-27T04:18:17.936749Z"
    },
    "id": "v2MB74NAUOVm",
    "outputId": "06648ac3-235c-4c7c-e080-1011d19dbfa9",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n",
      "[CV] nodes_dense1=59, nodes_dense2=22, nodes_lstm=79 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. nodes_dense1=59, nodes_dense2=22, nodes_lstm=79, total=   7.1s\n",
      "[CV] nodes_dense1=59, nodes_dense2=22, nodes_lstm=79 .................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. nodes_dense1=59, nodes_dense2=22, nodes_lstm=79, total=   6.9s\n",
      "[CV] nodes_dense1=68, nodes_dense2=28, nodes_lstm=90 .................\n",
      "[CV] .. nodes_dense1=68, nodes_dense2=28, nodes_lstm=90, total=   6.9s\n",
      "[CV] nodes_dense1=68, nodes_dense2=28, nodes_lstm=90 .................\n",
      "[CV] .. nodes_dense1=68, nodes_dense2=28, nodes_lstm=90, total=   6.4s\n",
      "[CV] nodes_dense1=94, nodes_dense2=82, nodes_lstm=82 .................\n",
      "[CV] .. nodes_dense1=94, nodes_dense2=82, nodes_lstm=82, total=   6.8s\n",
      "[CV] nodes_dense1=94, nodes_dense2=82, nodes_lstm=82 .................\n",
      "[CV] .. nodes_dense1=94, nodes_dense2=82, nodes_lstm=82, total=   6.6s\n",
      "[CV] nodes_dense1=95, nodes_dense2=31, nodes_lstm=10 .................\n",
      "[CV] .. nodes_dense1=95, nodes_dense2=31, nodes_lstm=10, total=   5.5s\n",
      "[CV] nodes_dense1=95, nodes_dense2=31, nodes_lstm=10 .................\n",
      "[CV] .. nodes_dense1=95, nodes_dense2=31, nodes_lstm=10, total=   5.9s\n",
      "[CV] nodes_dense1=29, nodes_dense2=60, nodes_lstm=9 ..................\n",
      "[CV] ... nodes_dense1=29, nodes_dense2=60, nodes_lstm=9, total=   5.8s\n",
      "[CV] nodes_dense1=29, nodes_dense2=60, nodes_lstm=9 ..................\n",
      "[CV] ... nodes_dense1=29, nodes_dense2=60, nodes_lstm=9, total=   5.7s\n",
      "[CV] nodes_dense1=95, nodes_dense2=37, nodes_lstm=45 .................\n",
      "[CV] .. nodes_dense1=95, nodes_dense2=37, nodes_lstm=45, total=   6.2s\n",
      "[CV] nodes_dense1=95, nodes_dense2=37, nodes_lstm=45 .................\n",
      "[CV] .. nodes_dense1=95, nodes_dense2=37, nodes_lstm=45, total=   6.1s\n",
      "[CV] nodes_dense1=9, nodes_dense2=71, nodes_lstm=67 ..................\n",
      "[CV] ... nodes_dense1=9, nodes_dense2=71, nodes_lstm=67, total=   6.5s\n",
      "[CV] nodes_dense1=9, nodes_dense2=71, nodes_lstm=67 ..................\n",
      "[CV] ... nodes_dense1=9, nodes_dense2=71, nodes_lstm=67, total=   6.3s\n",
      "[CV] nodes_dense1=28, nodes_dense2=40, nodes_lstm=83 .................\n",
      "[CV] .. nodes_dense1=28, nodes_dense2=40, nodes_lstm=83, total=   6.1s\n",
      "[CV] nodes_dense1=28, nodes_dense2=40, nodes_lstm=83 .................\n",
      "[CV] .. nodes_dense1=28, nodes_dense2=40, nodes_lstm=83, total=   6.6s\n",
      "[CV] nodes_dense1=65, nodes_dense2=29, nodes_lstm=96 .................\n",
      "[CV] .. nodes_dense1=65, nodes_dense2=29, nodes_lstm=96, total=   7.3s\n",
      "[CV] nodes_dense1=65, nodes_dense2=29, nodes_lstm=96 .................\n",
      "[CV] .. nodes_dense1=65, nodes_dense2=29, nodes_lstm=96, total=   6.7s\n",
      "[CV] nodes_dense1=56, nodes_dense2=98, nodes_lstm=66 .................\n",
      "[CV] .. nodes_dense1=56, nodes_dense2=98, nodes_lstm=66, total=   6.2s\n",
      "[CV] nodes_dense1=56, nodes_dense2=98, nodes_lstm=66 .................\n",
      "[CV] .. nodes_dense1=56, nodes_dense2=98, nodes_lstm=66, total=   6.3s\n",
      "[CV] nodes_dense1=49, nodes_dense2=99, nodes_lstm=67 .................\n",
      "[CV] .. nodes_dense1=49, nodes_dense2=99, nodes_lstm=67, total=   6.8s\n",
      "[CV] nodes_dense1=49, nodes_dense2=99, nodes_lstm=67 .................\n",
      "[CV] .. nodes_dense1=49, nodes_dense2=99, nodes_lstm=67, total=   6.4s\n",
      "[CV] nodes_dense1=87, nodes_dense2=22, nodes_lstm=69 .................\n",
      "[CV] .. nodes_dense1=87, nodes_dense2=22, nodes_lstm=69, total=   6.8s\n",
      "[CV] nodes_dense1=87, nodes_dense2=22, nodes_lstm=69 .................\n",
      "[CV] .. nodes_dense1=87, nodes_dense2=22, nodes_lstm=69, total=   6.0s\n",
      "[CV] nodes_dense1=69, nodes_dense2=54, nodes_lstm=69 .................\n",
      "[CV] .. nodes_dense1=69, nodes_dense2=54, nodes_lstm=69, total=   6.2s\n",
      "[CV] nodes_dense1=69, nodes_dense2=54, nodes_lstm=69 .................\n",
      "[CV] .. nodes_dense1=69, nodes_dense2=54, nodes_lstm=69, total=   6.2s\n",
      "[CV] nodes_dense1=58, nodes_dense2=62, nodes_lstm=71 .................\n",
      "[CV] .. nodes_dense1=58, nodes_dense2=62, nodes_lstm=71, total=   6.7s\n",
      "[CV] nodes_dense1=58, nodes_dense2=62, nodes_lstm=71 .................\n",
      "[CV] .. nodes_dense1=58, nodes_dense2=62, nodes_lstm=71, total=   6.3s\n",
      "[CV] nodes_dense1=10, nodes_dense2=58, nodes_lstm=14 .................\n",
      "[CV] .. nodes_dense1=10, nodes_dense2=58, nodes_lstm=14, total=   6.0s\n",
      "[CV] nodes_dense1=10, nodes_dense2=58, nodes_lstm=14 .................\n",
      "[CV] .. nodes_dense1=10, nodes_dense2=58, nodes_lstm=14, total=   6.0s\n",
      "[CV] nodes_dense1=28, nodes_dense2=80, nodes_lstm=46 .................\n",
      "[CV] .. nodes_dense1=28, nodes_dense2=80, nodes_lstm=46, total=   6.4s\n",
      "[CV] nodes_dense1=28, nodes_dense2=80, nodes_lstm=46 .................\n",
      "[CV] .. nodes_dense1=28, nodes_dense2=80, nodes_lstm=46, total=   7.3s\n",
      "[CV] nodes_dense1=25, nodes_dense2=11, nodes_lstm=96 .................\n",
      "[CV] .. nodes_dense1=25, nodes_dense2=11, nodes_lstm=96, total=   6.6s\n",
      "[CV] nodes_dense1=25, nodes_dense2=11, nodes_lstm=96 .................\n",
      "[CV] .. nodes_dense1=25, nodes_dense2=11, nodes_lstm=96, total=   7.2s\n",
      "[CV] nodes_dense1=67, nodes_dense2=21, nodes_lstm=16 .................\n",
      "[CV] .. nodes_dense1=67, nodes_dense2=21, nodes_lstm=16, total=   5.8s\n",
      "[CV] nodes_dense1=67, nodes_dense2=21, nodes_lstm=16 .................\n",
      "[CV] .. nodes_dense1=67, nodes_dense2=21, nodes_lstm=16, total=   5.8s\n",
      "[CV] nodes_dense1=97, nodes_dense2=60, nodes_lstm=9 ..................\n",
      "[CV] ... nodes_dense1=97, nodes_dense2=60, nodes_lstm=9, total=   7.1s\n",
      "[CV] nodes_dense1=97, nodes_dense2=60, nodes_lstm=9 ..................\n",
      "[CV] ... nodes_dense1=97, nodes_dense2=60, nodes_lstm=9, total=   6.5s\n",
      "[CV] nodes_dense1=91, nodes_dense2=99, nodes_lstm=67 .................\n",
      "[CV] .. nodes_dense1=91, nodes_dense2=99, nodes_lstm=67, total=   7.2s\n",
      "[CV] nodes_dense1=91, nodes_dense2=99, nodes_lstm=67 .................\n",
      "[CV] .. nodes_dense1=91, nodes_dense2=99, nodes_lstm=67, total=   6.9s\n",
      "[CV] nodes_dense1=78, nodes_dense2=51, nodes_lstm=15 .................\n",
      "[CV] .. nodes_dense1=78, nodes_dense2=51, nodes_lstm=15, total=   6.4s\n",
      "[CV] nodes_dense1=78, nodes_dense2=51, nodes_lstm=15 .................\n",
      "[CV] .. nodes_dense1=78, nodes_dense2=51, nodes_lstm=15, total=   6.2s\n",
      "[CV] nodes_dense1=54, nodes_dense2=42, nodes_lstm=85 .................\n",
      "[CV] .. nodes_dense1=54, nodes_dense2=42, nodes_lstm=85, total=   6.8s\n",
      "[CV] nodes_dense1=54, nodes_dense2=42, nodes_lstm=85 .................\n",
      "[CV] .. nodes_dense1=54, nodes_dense2=42, nodes_lstm=85, total=   6.6s\n",
      "[CV] nodes_dense1=88, nodes_dense2=43, nodes_lstm=57 .................\n",
      "[CV] .. nodes_dense1=88, nodes_dense2=43, nodes_lstm=57, total=   6.4s\n",
      "[CV] nodes_dense1=88, nodes_dense2=43, nodes_lstm=57 .................\n",
      "[CV] .. nodes_dense1=88, nodes_dense2=43, nodes_lstm=57, total=   6.7s\n",
      "[CV] nodes_dense1=11, nodes_dense2=9, nodes_lstm=13 ..................\n",
      "[CV] ... nodes_dense1=11, nodes_dense2=9, nodes_lstm=13, total=   6.4s\n",
      "[CV] nodes_dense1=11, nodes_dense2=9, nodes_lstm=13 ..................\n",
      "[CV] ... nodes_dense1=11, nodes_dense2=9, nodes_lstm=13, total=   6.4s\n",
      "[CV] nodes_dense1=61, nodes_dense2=11, nodes_lstm=61 .................\n",
      "[CV] .. nodes_dense1=61, nodes_dense2=11, nodes_lstm=61, total=   6.3s\n",
      "[CV] nodes_dense1=61, nodes_dense2=11, nodes_lstm=61 .................\n",
      "[CV] .. nodes_dense1=61, nodes_dense2=11, nodes_lstm=61, total=   6.5s\n",
      "[CV] nodes_dense1=70, nodes_dense2=25, nodes_lstm=97 .................\n",
      "[CV] .. nodes_dense1=70, nodes_dense2=25, nodes_lstm=97, total=   6.9s\n",
      "[CV] nodes_dense1=70, nodes_dense2=25, nodes_lstm=97 .................\n",
      "[CV] .. nodes_dense1=70, nodes_dense2=25, nodes_lstm=97, total=   7.7s\n",
      "[CV] nodes_dense1=51, nodes_dense2=41, nodes_lstm=81 .................\n",
      "[CV] .. nodes_dense1=51, nodes_dense2=41, nodes_lstm=81, total=   8.8s\n",
      "[CV] nodes_dense1=51, nodes_dense2=41, nodes_lstm=81 .................\n",
      "[CV] .. nodes_dense1=51, nodes_dense2=41, nodes_lstm=81, total=   8.4s\n",
      "[CV] nodes_dense1=69, nodes_dense2=21, nodes_lstm=55 .................\n",
      "[CV] .. nodes_dense1=69, nodes_dense2=21, nodes_lstm=55, total=   7.6s\n",
      "[CV] nodes_dense1=69, nodes_dense2=21, nodes_lstm=55 .................\n",
      "[CV] .. nodes_dense1=69, nodes_dense2=21, nodes_lstm=55, total=   6.4s\n",
      "[CV] nodes_dense1=22, nodes_dense2=79, nodes_lstm=85 .................\n",
      "[CV] .. nodes_dense1=22, nodes_dense2=79, nodes_lstm=85, total=   6.7s\n",
      "[CV] nodes_dense1=22, nodes_dense2=79, nodes_lstm=85 .................\n",
      "[CV] .. nodes_dense1=22, nodes_dense2=79, nodes_lstm=85, total=   6.3s\n",
      "[CV] nodes_dense1=94, nodes_dense2=69, nodes_lstm=47 .................\n",
      "[CV] .. nodes_dense1=94, nodes_dense2=69, nodes_lstm=47, total=   6.4s\n",
      "[CV] nodes_dense1=94, nodes_dense2=69, nodes_lstm=47 .................\n",
      "[CV] .. nodes_dense1=94, nodes_dense2=69, nodes_lstm=47, total=   6.2s\n",
      "[CV] nodes_dense1=92, nodes_dense2=87, nodes_lstm=89 .................\n",
      "[CV] .. nodes_dense1=92, nodes_dense2=87, nodes_lstm=89, total=   6.5s\n",
      "[CV] nodes_dense1=92, nodes_dense2=87, nodes_lstm=89 .................\n",
      "[CV] .. nodes_dense1=92, nodes_dense2=87, nodes_lstm=89, total=   6.9s\n",
      "[CV] nodes_dense1=60, nodes_dense2=31, nodes_lstm=33 .................\n",
      "[CV] .. nodes_dense1=60, nodes_dense2=31, nodes_lstm=33, total=   6.5s\n",
      "[CV] nodes_dense1=60, nodes_dense2=31, nodes_lstm=33 .................\n",
      "[CV] .. nodes_dense1=60, nodes_dense2=31, nodes_lstm=33, total=   7.5s\n",
      "[CV] nodes_dense1=96, nodes_dense2=67, nodes_lstm=48 .................\n",
      "[CV] .. nodes_dense1=96, nodes_dense2=67, nodes_lstm=48, total=   8.5s\n",
      "[CV] nodes_dense1=96, nodes_dense2=67, nodes_lstm=48 .................\n",
      "[CV] .. nodes_dense1=96, nodes_dense2=67, nodes_lstm=48, total=   8.1s\n",
      "[CV] nodes_dense1=36, nodes_dense2=22, nodes_lstm=52 .................\n",
      "[CV] .. nodes_dense1=36, nodes_dense2=22, nodes_lstm=52, total=   9.1s\n",
      "[CV] nodes_dense1=36, nodes_dense2=22, nodes_lstm=52 .................\n",
      "[CV] .. nodes_dense1=36, nodes_dense2=22, nodes_lstm=52, total=   8.2s\n",
      "[CV] nodes_dense1=72, nodes_dense2=96, nodes_lstm=78 .................\n",
      "[CV] .. nodes_dense1=72, nodes_dense2=96, nodes_lstm=78, total=   8.0s\n",
      "[CV] nodes_dense1=72, nodes_dense2=96, nodes_lstm=78 .................\n",
      "[CV] .. nodes_dense1=72, nodes_dense2=96, nodes_lstm=78, total=   8.3s\n",
      "[CV] nodes_dense1=16, nodes_dense2=95, nodes_lstm=8 ..................\n",
      "[CV] ... nodes_dense1=16, nodes_dense2=95, nodes_lstm=8, total=   7.7s\n",
      "[CV] nodes_dense1=16, nodes_dense2=95, nodes_lstm=8 ..................\n",
      "[CV] ... nodes_dense1=16, nodes_dense2=95, nodes_lstm=8, total=   7.3s\n",
      "[CV] nodes_dense1=15, nodes_dense2=95, nodes_lstm=70 .................\n",
      "[CV] .. nodes_dense1=15, nodes_dense2=95, nodes_lstm=70, total=   9.2s\n",
      "[CV] nodes_dense1=15, nodes_dense2=95, nodes_lstm=70 .................\n",
      "[CV] .. nodes_dense1=15, nodes_dense2=95, nodes_lstm=70, total=   8.5s\n",
      "[CV] nodes_dense1=18, nodes_dense2=88, nodes_lstm=15 .................\n",
      "[CV] .. nodes_dense1=18, nodes_dense2=88, nodes_lstm=15, total=   8.3s\n",
      "[CV] nodes_dense1=18, nodes_dense2=88, nodes_lstm=15 .................\n",
      "[CV] .. nodes_dense1=18, nodes_dense2=88, nodes_lstm=15, total=   7.5s\n",
      "[CV] nodes_dense1=42, nodes_dense2=42, nodes_lstm=40 .................\n",
      "[CV] .. nodes_dense1=42, nodes_dense2=42, nodes_lstm=40, total=   8.8s\n",
      "[CV] nodes_dense1=42, nodes_dense2=42, nodes_lstm=40 .................\n",
      "[CV] .. nodes_dense1=42, nodes_dense2=42, nodes_lstm=40, total=   8.4s\n",
      "[CV] nodes_dense1=12, nodes_dense2=48, nodes_lstm=35 .................\n",
      "[CV] .. nodes_dense1=12, nodes_dense2=48, nodes_lstm=35, total=   8.0s\n",
      "[CV] nodes_dense1=12, nodes_dense2=48, nodes_lstm=35 .................\n",
      "[CV] .. nodes_dense1=12, nodes_dense2=48, nodes_lstm=35, total=   7.6s\n",
      "[CV] nodes_dense1=14, nodes_dense2=80, nodes_lstm=79 .................\n",
      "[CV] .. nodes_dense1=14, nodes_dense2=80, nodes_lstm=79, total=  11.7s\n",
      "[CV] nodes_dense1=14, nodes_dense2=80, nodes_lstm=79 .................\n",
      "[CV] .. nodes_dense1=14, nodes_dense2=80, nodes_lstm=79, total=   9.0s\n",
      "[CV] nodes_dense1=19, nodes_dense2=41, nodes_lstm=40 .................\n",
      "[CV] .. nodes_dense1=19, nodes_dense2=41, nodes_lstm=40, total=   8.2s\n",
      "[CV] nodes_dense1=19, nodes_dense2=41, nodes_lstm=40 .................\n",
      "[CV] .. nodes_dense1=19, nodes_dense2=41, nodes_lstm=40, total=   8.3s\n",
      "[CV] nodes_dense1=55, nodes_dense2=30, nodes_lstm=69 .................\n",
      "[CV] .. nodes_dense1=55, nodes_dense2=30, nodes_lstm=69, total=   8.2s\n",
      "[CV] nodes_dense1=55, nodes_dense2=30, nodes_lstm=69 .................\n",
      "[CV] .. nodes_dense1=55, nodes_dense2=30, nodes_lstm=69, total=   8.0s\n",
      "[CV] nodes_dense1=95, nodes_dense2=44, nodes_lstm=51 .................\n",
      "[CV] .. nodes_dense1=95, nodes_dense2=44, nodes_lstm=51, total=   8.3s\n",
      "[CV] nodes_dense1=95, nodes_dense2=44, nodes_lstm=51 .................\n",
      "[CV] .. nodes_dense1=95, nodes_dense2=44, nodes_lstm=51, total=   8.8s\n",
      "[CV] nodes_dense1=93, nodes_dense2=98, nodes_lstm=42 .................\n",
      "[CV] .. nodes_dense1=93, nodes_dense2=98, nodes_lstm=42, total=   8.2s\n",
      "[CV] nodes_dense1=93, nodes_dense2=98, nodes_lstm=42 .................\n",
      "[CV] .. nodes_dense1=93, nodes_dense2=98, nodes_lstm=42, total=   8.3s\n",
      "[CV] nodes_dense1=72, nodes_dense2=54, nodes_lstm=85 .................\n",
      "[CV] .. nodes_dense1=72, nodes_dense2=54, nodes_lstm=85, total=   8.5s\n",
      "[CV] nodes_dense1=72, nodes_dense2=54, nodes_lstm=85 .................\n",
      "[CV] .. nodes_dense1=72, nodes_dense2=54, nodes_lstm=85, total=   7.4s\n",
      "[CV] nodes_dense1=10, nodes_dense2=8, nodes_lstm=12 ..................\n",
      "[CV] ... nodes_dense1=10, nodes_dense2=8, nodes_lstm=12, total=   6.5s\n",
      "[CV] nodes_dense1=10, nodes_dense2=8, nodes_lstm=12 ..................\n",
      "[CV] ... nodes_dense1=10, nodes_dense2=8, nodes_lstm=12, total=   5.8s\n",
      "[CV] nodes_dense1=97, nodes_dense2=21, nodes_lstm=34 .................\n",
      "[CV] .. nodes_dense1=97, nodes_dense2=21, nodes_lstm=34, total=   6.1s\n",
      "[CV] nodes_dense1=97, nodes_dense2=21, nodes_lstm=34 .................\n",
      "[CV] .. nodes_dense1=97, nodes_dense2=21, nodes_lstm=34, total=   6.1s\n",
      "[CV] nodes_dense1=16, nodes_dense2=86, nodes_lstm=22 .................\n",
      "[CV] .. nodes_dense1=16, nodes_dense2=86, nodes_lstm=22, total=   6.9s\n",
      "[CV] nodes_dense1=16, nodes_dense2=86, nodes_lstm=22 .................\n",
      "[CV] .. nodes_dense1=16, nodes_dense2=86, nodes_lstm=22, total=   6.4s\n",
      "[CV] nodes_dense1=97, nodes_dense2=49, nodes_lstm=84 .................\n",
      "[CV] .. nodes_dense1=97, nodes_dense2=49, nodes_lstm=84, total=   6.4s\n",
      "[CV] nodes_dense1=97, nodes_dense2=49, nodes_lstm=84 .................\n",
      "[CV] .. nodes_dense1=97, nodes_dense2=49, nodes_lstm=84, total=   6.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 11.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f1c603dcfa0>,\n",
       "                   n_iter=50,\n",
       "                   param_distributions={'nodes_dense1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1c603d7910>,\n",
       "                                        'nodes_dense2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1c603d7cd0>,\n",
       "                                        'nodes_lstm': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1c603d7820>},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params  \n",
    "params_rs_lstm1 = {\n",
    "    'nodes_lstm': randint(8,100),\n",
    "    'nodes_dense1': randint(8,100),\n",
    "    'nodes_dense2':randint(8,100)\n",
    "}\n",
    "#instantiate randomized search\n",
    "rs_lstm_1 = RandomizedSearchCV(lstm_modeler,params_rs_lstm1,n_iter=50,random_state=42,verbose=2,cv=2)\n",
    "\n",
    "# fit \n",
    "rs_lstm_1.fit(X_train_lstm,y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "l8VxSP0xYHiy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:30:15.144873Z",
     "iopub.status.busy": "2021-08-27T04:30:15.144712Z",
     "iopub.status.idle": "2021-08-27T04:30:15.564818Z",
     "shell.execute_reply": "2021-08-27T04:30:15.564149Z",
     "shell.execute_reply.started": "2021-08-27T04:30:15.144856Z"
    },
    "id": "l8VxSP0xYHiy",
    "outputId": "bb439238-3693-4834-dac5-bbb3afb4ccf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8438355922698975 0.7811217308044434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>{'nodes_dense1': 14, 'nodes_dense2': 80, 'nodes_lstm': 79}</td>\n",
       "      <td>0.819178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'nodes_dense1': 28, 'nodes_dense2': 80, 'nodes_lstm': 46}</td>\n",
       "      <td>0.816438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'nodes_dense1': 49, 'nodes_dense2': 99, 'nodes_lstm': 67}</td>\n",
       "      <td>0.816438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'nodes_dense1': 29, 'nodes_dense2': 60, 'nodes_lstm': 9}</td>\n",
       "      <td>0.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'nodes_dense1': 97, 'nodes_dense2': 60, 'nodes_lstm': 9}</td>\n",
       "      <td>0.815069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>{'nodes_dense1': 95, 'nodes_dense2': 44, 'nodes_lstm': 51}</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'nodes_dense1': 60, 'nodes_dense2': 31, 'nodes_lstm': 33}</td>\n",
       "      <td>0.815068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'nodes_dense1': 72, 'nodes_dense2': 96, 'nodes_lstm': 78}</td>\n",
       "      <td>0.814384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'nodes_dense1': 68, 'nodes_dense2': 28, 'nodes_lstm': 90}</td>\n",
       "      <td>0.814041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'nodes_dense1': 36, 'nodes_dense2': 22, 'nodes_lstm': 52}</td>\n",
       "      <td>0.814041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        params  \\\n",
       "40  {'nodes_dense1': 14, 'nodes_dense2': 80, 'nodes_lstm': 79}   \n",
       "15  {'nodes_dense1': 28, 'nodes_dense2': 80, 'nodes_lstm': 46}   \n",
       "10  {'nodes_dense1': 49, 'nodes_dense2': 99, 'nodes_lstm': 67}   \n",
       "4    {'nodes_dense1': 29, 'nodes_dense2': 60, 'nodes_lstm': 9}   \n",
       "18   {'nodes_dense1': 97, 'nodes_dense2': 60, 'nodes_lstm': 9}   \n",
       "43  {'nodes_dense1': 95, 'nodes_dense2': 44, 'nodes_lstm': 51}   \n",
       "31  {'nodes_dense1': 60, 'nodes_dense2': 31, 'nodes_lstm': 33}   \n",
       "34  {'nodes_dense1': 72, 'nodes_dense2': 96, 'nodes_lstm': 78}   \n",
       "1   {'nodes_dense1': 68, 'nodes_dense2': 28, 'nodes_lstm': 90}   \n",
       "33  {'nodes_dense1': 36, 'nodes_dense2': 22, 'nodes_lstm': 52}   \n",
       "\n",
       "    mean_test_score  \n",
       "40         0.819178  \n",
       "15         0.816438  \n",
       "10         0.816438  \n",
       "4          0.815753  \n",
       "18         0.815069  \n",
       "43         0.815068  \n",
       "31         0.815068  \n",
       "34         0.814384  \n",
       "1          0.814041  \n",
       "33         0.814041  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth',None)\n",
    "print(rs_lstm_1.score(X_train_lstm,y_train_nn), rs_lstm_1.score(X_test_lstm,y_test_nn))\n",
    "gs_results(rs_lstm_1).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "Gmn82V7bc-Ms",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:30:15.565763Z",
     "iopub.status.busy": "2021-08-27T04:30:15.565599Z",
     "iopub.status.idle": "2021-08-27T04:30:15.570897Z",
     "shell.execute_reply": "2021-08-27T04:30:15.570159Z",
     "shell.execute_reply.started": "2021-08-27T04:30:15.565746Z"
    },
    "id": "Gmn82V7bc-Ms"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes_dense1': 14, 'nodes_dense2': 80, 'nodes_lstm': 79}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_lstm_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "P4u9LJofc64f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:30:15.571740Z",
     "iopub.status.busy": "2021-08-27T04:30:15.571609Z",
     "iopub.status.idle": "2021-08-27T04:30:15.728936Z",
     "shell.execute_reply": "2021-08-27T04:30:15.728210Z",
     "shell.execute_reply.started": "2021-08-27T04:30:15.571724Z"
    },
    "id": "P4u9LJofc64f",
    "outputId": "4cabbb38-6ca4-485f-fdae-3e725318a82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8438355922698975 0.7811217308044434\n"
     ]
    }
   ],
   "source": [
    "print(rs_lstm_1.score(X_train_lstm,y_train_nn), rs_lstm_1.score(X_test_lstm,y_test_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XGg4w50kdM4I",
   "metadata": {
    "id": "XGg4w50kdM4I"
   },
   "source": [
    "### 3 dense layers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WzKRwJY4ew7d",
   "metadata": {
    "id": "WzKRwJY4ew7d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "iG0ISteUYH6_",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-27T04:30:15.729823Z",
     "iopub.status.busy": "2021-08-27T04:30:15.729693Z",
     "iopub.status.idle": "2021-08-27T04:30:15.736066Z",
     "shell.execute_reply": "2021-08-27T04:30:15.735208Z",
     "shell.execute_reply.started": "2021-08-27T04:30:15.729808Z"
    },
    "id": "iG0ISteUYH6_"
   },
   "outputs": [],
   "source": [
    "def model_func_lstm_3(nodes_lstm,nodes_dense_1,nodes_dense_2,nodes_dense_3):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(nodes_lstm,input_shape=(1,10)))\n",
    "    model.add(Dense(nodes_dense_1,activation='relu'))\n",
    "    model.add(Dense(nodes_dense_2,activation='relu'))\n",
    "    model.add(Dense(nodes_dense_3,activation='relu'))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "    return model \n",
    "\n",
    "# wrapper \n",
    "lstm_modeler3 = KerasClassifier(build_fn=model_func_lstm_3,epochs=50,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fwDML5xTexWp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:30:15.737305Z",
     "iopub.status.busy": "2021-08-27T04:30:15.737014Z",
     "iopub.status.idle": "2021-08-27T04:36:14.362220Z",
     "shell.execute_reply": "2021-08-27T04:36:14.361210Z",
     "shell.execute_reply.started": "2021-08-27T04:30:15.737206Z"
    },
    "id": "fwDML5xTexWp",
    "outputId": "f3ab83d2-9219-4412-d5c5-60c271a65ce9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f1c2db5ccd0>,\n",
       "                   n_iter=25,\n",
       "                   param_distributions={'nodes_dense_1': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1c2db5c8b0>,\n",
       "                                        'nodes_dense_2': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1c2db5cac0>,\n",
       "                                        'nodes_dense_3': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1c2db5cdc0>,\n",
       "                                        'nodes_lstm': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f1c2db5c550>},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# params to search over \n",
    "params_rs_lstm_3 = {\n",
    "    'nodes_lstm':randint(8,100),\n",
    "    'nodes_dense_1':randint(8,100),\n",
    "    'nodes_dense_2': randint(8,100),\n",
    "    'nodes_dense_3': randint(8,100),\n",
    "}\n",
    "\n",
    "# instantiate grid search \n",
    "lstm_rs_3 = RandomizedSearchCV(lstm_modeler3,params_rs_lstm_3,cv=2,verbose=1,n_iter=25,random_state=42,)\n",
    "\n",
    "# fit \n",
    "lstm_rs_3.fit(X_train_lstm,y_train_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3ZvVoeqMexWo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2021-08-27T04:36:14.363241Z",
     "iopub.status.busy": "2021-08-27T04:36:14.363088Z",
     "iopub.status.idle": "2021-08-27T04:36:14.831991Z",
     "shell.execute_reply": "2021-08-27T04:36:14.831242Z",
     "shell.execute_reply.started": "2021-08-27T04:36:14.363225Z"
    },
    "id": "3ZvVoeqMexWo",
    "outputId": "410f6fb8-224f-44b4-eebe-271d6dacf11c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8458904027938843 0.803009569644928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'nodes_dense_1': 62, 'nodes_dense_2': 71, 'nodes_dense_3': 10, 'nodes_lstm': 58}</td>\n",
       "      <td>0.820548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'nodes_dense_1': 28, 'nodes_dense_2': 90, 'nodes_dense_3': 94, 'nodes_lstm': 82}</td>\n",
       "      <td>0.815753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'nodes_dense_1': 22, 'nodes_dense_2': 79, 'nodes_dense_3': 85, 'nodes_lstm': 94}</td>\n",
       "      <td>0.815411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'nodes_dense_1': 98, 'nodes_dense_2': 66, 'nodes_dense_3': 49, 'nodes_lstm': 99}</td>\n",
       "      <td>0.813699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'nodes_dense_1': 67, 'nodes_dense_2': 87, 'nodes_dense_3': 22, 'nodes_lstm': 69}</td>\n",
       "      <td>0.813014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'nodes_dense_1': 9, 'nodes_dense_2': 91, 'nodes_dense_3': 99, 'nodes_lstm': 67}</td>\n",
       "      <td>0.813014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'nodes_dense_1': 29, 'nodes_dense_2': 60, 'nodes_dense_3': 9, 'nodes_lstm': 95}</td>\n",
       "      <td>0.813014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'nodes_dense_1': 82, 'nodes_dense_2': 95, 'nodes_dense_3': 31, 'nodes_lstm': 10}</td>\n",
       "      <td>0.812671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'nodes_dense_1': 78, 'nodes_dense_2': 51, 'nodes_dense_3': 15, 'nodes_lstm': 54}</td>\n",
       "      <td>0.812671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'nodes_dense_1': 21, 'nodes_dense_2': 16, 'nodes_dense_3': 97, 'nodes_lstm': 60}</td>\n",
       "      <td>0.810616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'nodes_dense_1': 25, 'nodes_dense_2': 11, 'nodes_dense_3': 96, 'nodes_lstm': 67}</td>\n",
       "      <td>0.809932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'nodes_dense_1': 69, 'nodes_dense_2': 47, 'nodes_dense_3': 92, 'nodes_lstm': 87}</td>\n",
       "      <td>0.809931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'nodes_dense_1': 65, 'nodes_dense_2': 29, 'nodes_dense_3': 96, 'nodes_lstm': 56}</td>\n",
       "      <td>0.809931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'nodes_dense_1': 25, 'nodes_dense_2': 97, 'nodes_dense_3': 51, 'nodes_lstm': 41}</td>\n",
       "      <td>0.809931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'nodes_dense_1': 67, 'nodes_dense_2': 28, 'nodes_dense_3': 40, 'nodes_lstm': 83}</td>\n",
       "      <td>0.809589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'nodes_dense_1': 61, 'nodes_dense_2': 11, 'nodes_dense_3': 61, 'nodes_lstm': 70}</td>\n",
       "      <td>0.808904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'nodes_dense_1': 96, 'nodes_dense_2': 67, 'nodes_dense_3': 48, 'nodes_lstm': 36}</td>\n",
       "      <td>0.808904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'nodes_dense_1': 59, 'nodes_dense_2': 22, 'nodes_dense_3': 79, 'nodes_lstm': 68}</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'nodes_dense_1': 57, 'nodes_dense_2': 11, 'nodes_dense_3': 9, 'nodes_lstm': 13}</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'nodes_dense_1': 81, 'nodes_dense_2': 69, 'nodes_dense_3': 21, 'nodes_lstm': 55}</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'nodes_dense_1': 42, 'nodes_dense_2': 85, 'nodes_dense_3': 88, 'nodes_lstm': 43}</td>\n",
       "      <td>0.806507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'nodes_dense_1': 14, 'nodes_dense_2': 28, 'nodes_dense_3': 80, 'nodes_lstm': 46}</td>\n",
       "      <td>0.806507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'nodes_dense_1': 69, 'nodes_dense_2': 54, 'nodes_dense_3': 69, 'nodes_lstm': 58}</td>\n",
       "      <td>0.805137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'nodes_dense_1': 89, 'nodes_dense_2': 60, 'nodes_dense_3': 31, 'nodes_lstm': 33}</td>\n",
       "      <td>0.805137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'nodes_dense_1': 37, 'nodes_dense_2': 45, 'nodes_dense_3': 9, 'nodes_lstm': 71}</td>\n",
       "      <td>0.803767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               params  \\\n",
       "10  {'nodes_dense_1': 62, 'nodes_dense_2': 71, 'nodes_dense_3': 10, 'nodes_lstm': 58}   \n",
       "1   {'nodes_dense_1': 28, 'nodes_dense_2': 90, 'nodes_dense_3': 94, 'nodes_lstm': 82}   \n",
       "21  {'nodes_dense_1': 22, 'nodes_dense_2': 79, 'nodes_dense_3': 85, 'nodes_lstm': 94}   \n",
       "7   {'nodes_dense_1': 98, 'nodes_dense_2': 66, 'nodes_dense_3': 49, 'nodes_lstm': 99}   \n",
       "8   {'nodes_dense_1': 67, 'nodes_dense_2': 87, 'nodes_dense_3': 22, 'nodes_lstm': 69}   \n",
       "14   {'nodes_dense_1': 9, 'nodes_dense_2': 91, 'nodes_dense_3': 99, 'nodes_lstm': 67}   \n",
       "3    {'nodes_dense_1': 29, 'nodes_dense_2': 60, 'nodes_dense_3': 9, 'nodes_lstm': 95}   \n",
       "2   {'nodes_dense_1': 82, 'nodes_dense_2': 95, 'nodes_dense_3': 31, 'nodes_lstm': 10}   \n",
       "15  {'nodes_dense_1': 78, 'nodes_dense_2': 51, 'nodes_dense_3': 15, 'nodes_lstm': 54}   \n",
       "13  {'nodes_dense_1': 21, 'nodes_dense_2': 16, 'nodes_dense_3': 97, 'nodes_lstm': 60}   \n",
       "12  {'nodes_dense_1': 25, 'nodes_dense_2': 11, 'nodes_dense_3': 96, 'nodes_lstm': 67}   \n",
       "22  {'nodes_dense_1': 69, 'nodes_dense_2': 47, 'nodes_dense_3': 92, 'nodes_lstm': 87}   \n",
       "6   {'nodes_dense_1': 65, 'nodes_dense_2': 29, 'nodes_dense_3': 96, 'nodes_lstm': 56}   \n",
       "19  {'nodes_dense_1': 25, 'nodes_dense_2': 97, 'nodes_dense_3': 51, 'nodes_lstm': 41}   \n",
       "5   {'nodes_dense_1': 67, 'nodes_dense_2': 28, 'nodes_dense_3': 40, 'nodes_lstm': 83}   \n",
       "18  {'nodes_dense_1': 61, 'nodes_dense_2': 11, 'nodes_dense_3': 61, 'nodes_lstm': 70}   \n",
       "24  {'nodes_dense_1': 96, 'nodes_dense_2': 67, 'nodes_dense_3': 48, 'nodes_lstm': 36}   \n",
       "0   {'nodes_dense_1': 59, 'nodes_dense_2': 22, 'nodes_dense_3': 79, 'nodes_lstm': 68}   \n",
       "17   {'nodes_dense_1': 57, 'nodes_dense_2': 11, 'nodes_dense_3': 9, 'nodes_lstm': 13}   \n",
       "20  {'nodes_dense_1': 81, 'nodes_dense_2': 69, 'nodes_dense_3': 21, 'nodes_lstm': 55}   \n",
       "16  {'nodes_dense_1': 42, 'nodes_dense_2': 85, 'nodes_dense_3': 88, 'nodes_lstm': 43}   \n",
       "11  {'nodes_dense_1': 14, 'nodes_dense_2': 28, 'nodes_dense_3': 80, 'nodes_lstm': 46}   \n",
       "9   {'nodes_dense_1': 69, 'nodes_dense_2': 54, 'nodes_dense_3': 69, 'nodes_lstm': 58}   \n",
       "23  {'nodes_dense_1': 89, 'nodes_dense_2': 60, 'nodes_dense_3': 31, 'nodes_lstm': 33}   \n",
       "4    {'nodes_dense_1': 37, 'nodes_dense_2': 45, 'nodes_dense_3': 9, 'nodes_lstm': 71}   \n",
       "\n",
       "    mean_test_score  \n",
       "10         0.820548  \n",
       "1          0.815753  \n",
       "21         0.815411  \n",
       "7          0.813699  \n",
       "8          0.813014  \n",
       "14         0.813014  \n",
       "3          0.813014  \n",
       "2          0.812671  \n",
       "15         0.812671  \n",
       "13         0.810616  \n",
       "12         0.809932  \n",
       "22         0.809931  \n",
       "6          0.809931  \n",
       "19         0.809931  \n",
       "5          0.809589  \n",
       "18         0.808904  \n",
       "24         0.808904  \n",
       "0          0.808219  \n",
       "17         0.808219  \n",
       "20         0.808219  \n",
       "16         0.806507  \n",
       "11         0.806507  \n",
       "9          0.805137  \n",
       "23         0.805137  \n",
       "4          0.803767  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth',None)\n",
    "print(lstm_rs_3.score(X_train_lstm,y_train_nn), lstm_rs_3.score(X_test_lstm,y_test_nn))\n",
    "gs_results(lstm_rs_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673be9c-f44c-4428-8283-3d6a8a508ca9",
   "metadata": {
    "id": "e673be9c-f44c-4428-8283-3d6a8a508ca9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3f1227-4cce-42a9-915a-7026728625d3",
   "metadata": {
    "id": "2c3f1227-4cce-42a9-915a-7026728625d3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f938c71-d992-421b-b199-aacc0971b838",
   "metadata": {
    "id": "5f938c71-d992-421b-b199-aacc0971b838"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587e77a-b363-4791-b6da-ca3180824e38",
   "metadata": {
    "id": "3587e77a-b363-4791-b6da-ca3180824e38"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65751508-4fc8-4c2d-8f45-6feced8d348d",
   "metadata": {
    "id": "65751508-4fc8-4c2d-8f45-6feced8d348d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81aac4f-17fa-448c-a66b-f672db6a0046",
   "metadata": {
    "id": "a81aac4f-17fa-448c-a66b-f672db6a0046"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0848bb-a691-43ef-bae9-82288b90e25b",
   "metadata": {
    "id": "3b0848bb-a691-43ef-bae9-82288b90e25b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715d96e-4882-47e7-8567-ba9f9f64be22",
   "metadata": {
    "id": "1715d96e-4882-47e7-8567-ba9f9f64be22"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad75d5-f099-4816-8e43-de9f138f3567",
   "metadata": {
    "id": "b2ad75d5-f099-4816-8e43-de9f138f3567"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a999f-7ac7-4bb8-9b23-f0d2d901b179",
   "metadata": {
    "id": "007a999f-7ac7-4bb8-9b23-f0d2d901b179"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371abde4-ef09-4163-94f3-3408f6694c0a",
   "metadata": {
    "id": "371abde4-ef09-4163-94f3-3408f6694c0a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3b42e-e7eb-4d18-ae68-af929fdb4013",
   "metadata": {
    "id": "6fe3b42e-e7eb-4d18-ae68-af929fdb4013"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881cba2-00c7-466e-b283-29b4b84829d0",
   "metadata": {
    "id": "a881cba2-00c7-466e-b283-29b4b84829d0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beaaadb-882a-49b3-a85c-a4816f246749",
   "metadata": {
    "id": "4beaaadb-882a-49b3-a85c-a4816f246749"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114942e-7135-4e09-8836-4add3251e942",
   "metadata": {
    "id": "c114942e-7135-4e09-8836-4add3251e942"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a04a74c6-83c1-4b95-9745-af1e5abfda2f",
   "metadata": {
    "id": "a04a74c6-83c1-4b95-9745-af1e5abfda2f"
   },
   "source": [
    "## OTHER MODELS? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2ca1a1-be0d-468d-b157-eb2567417c74",
   "metadata": {
    "id": "ed2ca1a1-be0d-468d-b157-eb2567417c74"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QTDBIp9c708A",
   "metadata": {
    "id": "QTDBIp9c708A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2_T7z6vQ71WB",
   "metadata": {
    "id": "2_T7z6vQ71WB"
   },
   "source": [
    "# Predictions \n",
    "\n",
    "- fit best model \n",
    "- get predictions \n",
    "- measure success? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1de835-e363-4acd-ba13-3566234e5be0",
   "metadata": {
    "id": "5f1de835-e363-4acd-ba13-3566234e5be0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "aa7ec2be-829d-4651-9617-9e8f2d9ce065"
   ],
   "name": "clf_models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
