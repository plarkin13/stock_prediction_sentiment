{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting API for NYT\n",
    "\n",
    "import sys\n",
    "try:\n",
    "    days = int(sys.argv[1])\n",
    "except:\n",
    "    days = int(input('Please enter the number of days you would like to crawl: '))\n",
    "\n",
    "\n",
    "subs= ['AskHistorians', 'MaliciousCompliance']\n",
    "# Set API base url (no key needed)\n",
    "base_url =  'https://api.pushshift.io/reddit/'\n",
    "\n",
    "# Function to make an individual Pushshift API request\n",
    "# Returns dictionary of the .json API response\n",
    "def request_posts(subreddit, days_ago, base_url=base_url, \n",
    "                  endpoint='search/submission/', is_video='is_video=false'):\n",
    "    try:    \n",
    "        response = requests.get(f'{base_url}{endpoint}?subreddit={subreddit}&{is_video}&before={days_ago}d&after={days_ago+1}d&size=1000')\n",
    "        assert response.status_code == 200\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Function to make n requests of 100 posts from n days\n",
    "# Returns dataframe of API responses from a subreddit\n",
    "def make_requests(subreddit, days_of_data):\n",
    "    all_results = []\n",
    "    if subreddit == 'MaliciousCompliance':\n",
    "        for i in range(1, days_of_data*5):\n",
    "            try:\n",
    "                entry = request_posts(subreddit,i)\n",
    "                all_results.append(pd.DataFrame(entry.json()['data']))\n",
    "            except:\n",
    "                pass\n",
    "            if i % 100 == 0:\n",
    "                print(f'{i} of {days_of_data*5} requests completed')\n",
    "            time.sleep(1.0)\n",
    "    else:\n",
    "        for i in range(1, days_of_data):\n",
    "            try:\n",
    "                entry = request_posts(subreddit,i)\n",
    "                all_results.append(pd.DataFrame(entry.json()['data']))\n",
    "            except:\n",
    "                pass\n",
    "            if i % 100 == 0:\n",
    "                print(f'{i} of {days_of_data} requests completed')\n",
    "            time.sleep(1.0)\n",
    "        \n",
    "    return pd.concat(all_results)\n",
    "\n",
    "# Function to make n requests of 100 posts from n days over m subreddits\n",
    "# Returns dataframe of API responses from all subreddits\n",
    "def request_all_subs(list_of_subreddits, days_of_data):\n",
    "    all_results = []\n",
    "    for sub in list_of_subreddits:\n",
    "        print(f'Querying {sub}...')\n",
    "        sub_df = make_requests(sub,days_of_data)\n",
    "        all_results.append(sub_df)\n",
    "    return pd.concat(all_results)\n",
    "\n",
    "# Executes all requests for n days of data across the subreddits list and writes results to a .csv\n",
    "def main(days=days):\n",
    "    df = request_all_subs(subs,days)\n",
    "    df.to_csv('./data/subreddit_data.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f762bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pynytimes\n",
    "\n",
    "from pynytimes import NYTAPI\n",
    "nyt = NYTAPI(\"Your API key\", parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685a929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "from pynytimes import NYTAPI\n",
    "\n",
    "pip install --upgrade pynytimes\n",
    "\n",
    "\n",
    "# Make sure to set parse dates to True so that the dates\n",
    "# are parsed into datetime.datetime or datetime.date objects\n",
    "nyt = NYTAPI(\n",
    "    key=\"t8vriKxFjaET2Qo7jSVKTsBYVXSeGw0h\",  # Get your API Key at https://developer.nytimes.com\n",
    "    parse_dates=True,\n",
    ")\n",
    "\n",
    "# Search articles about President Biden\n",
    "#biden = nyt.article_search(\"biden\")\n",
    "\n",
    "# You can optionally define the dates between which you want the articles to be\n",
    "biz_sent = nyt.article_search(\n",
    "    query=\"stock\", \n",
    "    results = 5,\n",
    "    dates={\"start\": date(2011, 1, 1), \"end\": date(2013, 12, 31)},\n",
    "    options = {\n",
    "        \"sort\": \"oldest\",\n",
    "        \"sources\": [\n",
    "            \"New York Times\",\n",
    "            \"AP\",\n",
    "            \"Reuters\",\n",
    "            \"International Herald Tribune\"\n",
    "        ],\n",
    "        \"news_desk\": [\n",
    "            \"Business\"\n",
    "        ],\n",
    "        \"type_of_material\": [\n",
    "            \"News Analysis\", \"Summary\", \"Text\" ,\"News\", \"List\", \"Interview\", \"Article\"\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Optionally you can also define\n",
    "# biden = nyt.article_search(\n",
    "#     \"biden\",\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
